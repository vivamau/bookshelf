<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:ibooks="http://apple.com/ibooks/html-extensions" lang="it-IT" xml:lang="it-IT" class="calibre">
  <head>
    <title>FILE 20 – Supremacy – Capitolo</title>
    <meta content="urn:uuid:35484d83-cd47-4b21-bd76-ea9d55abc8bb" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body epub:type="bodymatter" class="calibre2">
		<section epub:type="chapter" role="doc-chapter" class="calibre">
			<h2 class="capitolo" id="h2-0001"><span class="smallcaps1">15. scacco matto</span></h2>
			<p class="testo" id="p_0001">Dieci anni fa, dire a qualcuno che stavi costruendo sistemi di <span class="smallcaps">ai</span> di livello umano sarebbe stato considerato folle quanto raccontare di voler essere ibernato. Ma, come tanti sogni coltivati dagli innovatori tecnologici – per esempio, quello di avere tutte le informazioni del mondo in tasca, su un dispositivo chiamato smartphone –, alla fine la gente ha cominciato a prendere sul serio anche questo. Per il momento l’<span class="smallcaps">agi</span> esiste solo nel campo della teoria, ma molti scienziati in ambito <span class="smallcaps">ai</span> si aspettano ormai che raggiungeremo una soglia di intelligenza simile a quella umana nei prossimi dieci o cinquant’anni, e anche una fetta sempre più ampia dell’opinione pubblica comincia a credere in quelle idee un tempo marginali che hanno guidato Demis Hassabis e Sam Altman. Grazie alla loro perseveranza e alla loro rivalità, non è più fantascienza.</p>
			<p class="testo" id="p_0002">Ma la definizione sfocata di <span class="smallcaps">agi</span> ha anche reso più facile oscurare le motivazioni che i suoi creatori cercavano di bilanciare mentre realizzavano sistemi sempre più potenti. I benefici sarebbero stati distribuiti all’umanità, ma in cima alla lista ci sarebbero state Microsoft, Google e altri giganti tecnologici. Anche Mark Zuckerberg ha finito per unirsi al gioco dell’<span class="smallcaps">agi</span>. All’inizio del 2024, pubblicò un video dicendo che l’obiettivo a lungo termine di Meta era «costruire un’intelligenza generale» affinché tutti nel mondo ne potessero beneficiare. Dopo di che, dichiarò che l’azienda aveva un vantaggio perché poteva addestrare i suoi modelli sui post, i commenti e le immagini accumulati negli ultimi vent’anni. Poco importava che Zuckerberg stesse per sfruttare ancora una volta i dati personali di miliardi di persone: intendeva anche addestrare l’<span class="smallcaps">ai</span> su contenuti che è risaputo siano tossici, specie per gli utenti fuori dagli Stati Uniti. «Abbiamo sviluppato la capacità di farlo su una scala che potrebbe essere superiore a quella di qualsiasi altra azienda», confidò al sito web The Verge.</p>
			<p class="testo" id="p_0003">Le visioni ambigue erano fondamentali nell’alimentare l’hype. Per chi stava cercando di realizzare l’<span class="smallcaps">agi</span>, la vaghezza di certi parametri serviva ad aggirare la contraddizione insita nel costruire qualcosa che avrebbe potuto spazzare via l’umanità. E questo implicava anche che, quando Sam Altman parlava di 100.000 miliardi di dollari da distribuire tra tutti gli abitanti del pianeta, nessuno gli chiedesse di spiegare come avrebbe fatto. Mentre si intratteneva con i leader mondiali all’incontro annuale del World Economic Forum a Davos, nel gennaio del 2024, iniziò a ridimensionare le aspettative sull’<span class="smallcaps">agi</span>. «Cambierà il mondo – e il mondo del lavoro – molto meno di quanto pensiamo», disse. Una visione ben più cauta e realistica rispetto a quella delineata solo un anno prima. Ma nessuno, nell’élite del business e della politica presente a Davos, fece una piega. Continuavano a prendere Altman in parola, affascinati da questo imprenditore serio e compito della Silicon Valley.</p>
			<p class="testo" id="p_0004">«Una cosa che Sam fa davvero bene è rilasciare dichiarazioni appena credibili che fanno parlare la gente», dice un ex dirigente di Open<span class="smallcaps">ai</span>. «Per Open<span class="smallcaps">ai</span>, è davvero utile che venga percepita come un’azienda globale in grado di diffondere prosperità, soprattutto con i regolatori. Ma se vai a vedere cosa stanno costruendo, è solo un modello linguistico.» La capacità di Altman di generare entusiasmo intorno all’<span class="smallcaps">ai</span> e alla sua visione di prosperità gli aveva permesso, esattamente come era accaduto a Hassabis, di imbastire una narrazione capace di vita propria.</p>
			<p class="testo" id="p_0005">Gli obiettivi vaghi dell’<span class="smallcaps">agi</span> rendevano anche più complicato definirne i confini etici. Basta paragonarla alla diffusione dell’elettricità nel primo Novecento, quando era evidente come questa nuova, scoppiettante innovazione potesse causare danni fisici alle persone a causa di scosse o ustioni. Con l’<span class="smallcaps">ai</span>, i danni sono più difficili da identificare e i confini etici più nebulosi. Si collocano in un mondo digitale fatto di dati, privacy e decisioni algoritmiche, e questo rende più agevole, per le aziende, spingersi pian piano oltre questi limiti, alla ricerca del profitto.</p>
			<p class="testo" id="p_0006">E, senza ulteriori dettagli sugli intenti dell’<span class="smallcaps">agi</span>, sarebbe stato sempre più difficile per innovatori come Altman e Hassabis resistere alla tentazione di gravitare verso i centri di potere. Rafforzando Google e Microsoft con il loro lavoro, erano destinati a replicare una dinamica antica. L’invenzione della stampa nel <span class="smallcaps">xv</span> secolo aveva portato a un’esplosione di conoscenza, ma aveva anche conferito nuovi poteri a chiunque potesse permettersi di produrre opuscoli e libri per plasmare l’opinione pubblica. E se da un lato le ferrovie avevano incrementato il commercio, dall’altro avevano anche ampliato l’influenza politica dei magnati del settore, permettendo alle loro aziende di agire come monopoli e sfruttare i lavoratori. A fronte di tutta la prosperità e la comodità che alcune delle più grandi innovazioni del mondo hanno portato, queste hanno anche dato origine a nuovi regimi che hanno comportato trasformazioni sociali non esclusivamente positive.</p>
			<p class="testo" id="p_0007">Nel 2024, Open<span class="smallcaps">ai</span> era sulla buona strada per diventare una delle aziende con il valore più alto al mondo. Stava raccogliendo fondi da nuovi investitori con una valutazione di 100 miliardi di dollari. A detta di Altman, inoltre, generava entrate a un ritmo di 1,3 miliardi di dollari l’anno. Gran parte di quel denaro proveniva da entrate condivise con Microsoft e dalla concessione ad altre aziende dell’accesso alla sua tecnologia. Gli abbonamenti mensili a Chat<span class="smallcaps">gpt</span> da 20 dollari al mese per i consumatori generavano circa 200 milioni di dollari l’anno, e lo stesso Chat<span class="smallcaps">gpt</span> fungeva sia da vetrina del prodotto sia da strumento per raccogliere un maggior numero di dati con cui addestrare modelli più avanzati. I suoi stessi utenti erano parte del prodotto, com’è ormai la norma per chiunque utilizzi internet da oltre un decennio.</p>
			<p class="testo" id="p_0008">Hassabis si trovava al centro della sua bolla in DeepMind, azienda che per anni si era considerata moralmente e tecnicamente superiore al resto del settore <span class="smallcaps">ai</span>, ma che adesso si ritrovava a dover recuperare il terreno perduto. Dopo che gli errori della divisione sanitaria avevano danneggiato la sua reputazione pubblica, DeepMind aveva gradualmente smantellato l’unità di «<span class="smallcaps">ai</span> applicata» e rinunciato a cercare di usare l’<span class="smallcaps">ai</span> per trovare soluzioni ai problemi più complessi del mondo reale. Gran parte della sua ricerca si concentrava sulla ricostruzione simulata di aspetti della vita fisica, dai giochi alle proteine. Ma quell’approccio iniziava a sembrare miope di fronte alla strategia di Open<span class="smallcaps">ai</span>, che abbracciando il caos di internet portava a strumenti di <span class="smallcaps">ai</span> più potenti. Persino alcuni elementi dello stesso team di DeepMind cominciarono a dubitare che la loro missione di «risolvere l’intelligenza» attraverso simulazioni e giochi fosse una buona idea. «La vita non è un cubo di Rubik», borbotta un ex dirigente di DeepMind, alludendo al motto dell’azienda. «Molto semplicemente, non puoi risolvere tutto.»</p>
			<p class="testo" id="p_0009">Dopo il lancio di Chat<span class="smallcaps">gpt</span>, DeepMind fu costretta a lanciarsi nella costruzione di una versione ancora migliore per Google. Hassabis aveva preso il controllo della nuova realtà frutto della fusione di Google e DeepMind e aveva iniziato a supervisionare lo sviluppo di un grande modello linguistico chiamato Gemini, un assistente <span class="smallcaps">ai</span> che utilizzava tecniche provenienti da AlphaGo per eccellere nella strategia e nella pianificazione. Gemini poteva elaborare testi, «vedere» immagini e ragionare, cosa che lo rendeva più abile di quel Bard lanciato in fretta e furia da Google solo per commettere una serie di errori imbarazzanti. Ma l’azienda era così ansiosa di superare Open<span class="smallcaps">ai</span> e Microsoft che accelerò anche il lancio di Gemini, esagerandone le competenze.</p>
			<p class="testo" id="p_0010">Poco prima del Natale 2023, Google pubblicò su YouTube un video sbalorditivo per mostrare di cosa fosse capace Gemini. Il filmato iniziava con una schermata nera e rumori di sottofondo: fruscio di fogli, clic di penne e borbottii, mentre una voce maschile diceva: «Va bene, ci siamo: proviamo un po’ questo Gemini». Un segnale acustico a suggerire un’intelligenza artificiale in ascolto. Poi compariva una mano che faceva scivolare un foglio su un tavolo. «Dimmi cosa vedi», diceva la voce. E la pronta risposta della voce robotica di Gemini: «Vedo che stai posando un foglio di carta sul tavolo». Quando le mani prendevano a disegnare, Gemini sembrava seguire il movimento, tanto da azzardare: «Vedo una linea ondulata… Mi sembra un uccello». Poi una serie di siparietti simpatici e sorprendenti in cui il nuovo modello di <span class="smallcaps">ai</span> di Google sembrava in grado di identificare un’anatra disegnata sul foglio e una partita a carta-forbici-sasso, il tutto in tempo reale.</p>
			<p class="testo" id="p_0011">Solo che niente di tutto questo era reale. I rumori di sottofondo, l’uomo che diceva: «Proviamo un po’ questo Gemini» non erano che una messinscena, perché Gemini era in grado di identificare quelle cose solo tramite fotografie o testo. Google aveva semplicemente montato tutto in un video e finto che il suo strumento potesse «parlare» e identificare azioni nel mondo reale mentre queste accadevano. Aveva persino modificato i prompt nel video per far sembrare Gemini più potente. Nella sua disperata rincorsa, Google non stava solo lanciando un software pieno di bug, ma stava anche ingannando gli utenti.</p>
			<p class="testo" id="p_0012">Al tempo stesso, aumentava il grado di riservatezza. Hassabis aveva detto al suo staff di smettere di pubblicare articoli di ricerca senza un permesso speciale: proprio come Open<span class="smallcaps">ai</span>, anche DeepMind stava dunque tirando le tende sul proprio lavoro.</p>
			<p class="testo" id="p_0013">L’effetto a catena non risparmiò nemmeno Anthropic, l’azienda votata all’<span class="smallcaps">ai</span> sicura nata in seguito alla scissione da Open<span class="smallcaps">ai</span>. Il suo obiettivo era fare ricerca sull’<span class="smallcaps">ai</span> in modo da «mettere la sicurezza in primo piano», ma non poteva studiare i modelli di <span class="smallcaps">ai</span> più grandi di Open<span class="smallcaps">ai</span> e Google perché erano opachi. Così, Anthropic cominciò a costruire i propri modelli, nella convinzione che fosse l’unico modo per permettere ai suoi ricercatori di esaminarne le problematiche in materia di sicurezza. Era un po’ come lamentarsi di non poter studiare le armi nucleari più potenti al mondo e decidere che la strategia migliore fosse costruirne altre. Il team di Anthropic era ben consapevole dell’ironia della situazione e, secondo quanto riportato da un articolo del «New York Times», alcuni dipendenti avevano <em class="calibre3">L’invenzione della bomba atomica</em> sulla scrivania e si paragonavano a novelli Oppenheimer, credendo che ci fosse una possibilità concreta che un’<span class="smallcaps">ai</span> fuori controllo distruggesse l’umanità nel giro di un decennio.</p>
			<p class="testo" id="p_0014">Nel frattempo, Anthropic stava sviluppando un prodotto sempre più avanzato. Vendeva Claude Pro, un chatbot «friendly», ai consumatori per 20 dollari al mese e una versione aziendale alle imprese. Inoltre, stava per raccogliere miliardi di dollari da Google e Amazon. Invece di abbandonare la corsa verso <span class="smallcaps">ai</span> più potenti, Anthropic si stava lasciando coinvolgere dalle pressioni commerciali a rilasciare modelli via via più grandi e rischiosi.</p>
			<p class="testo" id="p_0015">Mentre Hassabis veniva sempre più fagocitato nelle profondità di una grande azienda tecnologica, Altman portava Open<span class="smallcaps">ai</span> verso una direzione ancora più commerciale. A metà novembre 2023, confermò che Open<span class="smallcaps">ai</span> era al lavoro su <span class="smallcaps">gpt</span>-5 e stava raccogliendo ulteriori fondi. I costi elevati dell’addestramento facevano sì che l’azienda fosse ancora in perdita, pur trovandosi proiettata verso la redditività.</p>
			<p class="testo" id="p_0016">Poi, sempre nel novembre del 2023, un messaggio da parte di Ilya Sutskever gli fece franare la terra sotto i piedi. Altman era a Las Vegas per il Gran Premio di Formula 1 quando ricevette quel messaggio: Sutskever gli chiedeva un colloquio per il mezzogiorno del giorno seguente, secondo quanto riportato dal «Wall Street Journal». Quando Altman si collegò alla videochiamata su Google Meet, si ritrovò davanti l’intero consiglio di amministrazione, tranne Brockman, che ne era il presidente. Senza entrare troppo nel merito, Sutskever comunicò ad Altman che era licenziato e che la notizia sarebbe stata resa pubblica a breve. Pochi minuti dopo il termine della riunione, Altman si vide negato l’accesso dal proprio computer.</p>
			<p class="testo" id="p_0017">Era sbigottito. Era il volto di Open<span class="smallcaps">ai</span>. Aveva rappresentato l’azienda davanti a decine di leader mondiali, aveva supervisionato l’aumento del valore di mercato di Open<span class="smallcaps">ai</span> a quasi 90 miliardi di dollari e lanciato il prodotto tecnologico più virale della storia. E adesso lo scaricavano?</p>
			<p class="testo" id="p_0018">Mentre Altman cercava di riprendersi dalla notizia, Brockman ricevette un messaggio in cui gli si chiedeva di partecipare a una videochiamata. Si ritrovò davanti gli stessi membri del consiglio di amministrazione: Sutskever, il <span class="smallcaps">ceo</span> di Quora Adam D’Angelo, l’imprenditrice nel campo della robotica Tasha McCauley e l’accademica Helen Toner. Dei sei membri del consiglio, Altman, Brockman e Sutskever erano i soli dipendenti di Open<span class="smallcaps">ai</span>; gli altri tre erano direttori indipendenti, in carica da due o tre anni.</p>
			<p class="testo" id="p_0019">Brockman veniva rimosso dalla carica di presidente, ma il consiglio voleva che rimanesse nell’azienda. Microsoft fu subito informata dell’accaduto e, pochi minuti dopo, pubblicarono un post sul blog che annunciava il licenziamento di Altman. Brockman si dimise immediatamente, e tre dei ricercatori più importanti di Open<span class="smallcaps">ai</span> seguirono il suo esempio.</p>
			<p class="testo" id="p_0020">La notizia colpì l’industria tecnologica come una bomba atomica, lasciando tutti sotto shock. Tra i licenziamenti di amministratori delegati, questo fu tanto brutale quanto la rimozione di Steve Jobs da Apple, e la macchina del gossip della Silicon Valley andò subito in tilt nel tentativo di capire cosa avesse spinto Sutskever a voltare le spalle ad Altman. Open<span class="smallcaps">ai</span> era forse sull’orlo dell’<span class="smallcaps">agi</span>? «Che cos’ha visto Ilya?» ci si chiedeva su Twitter. Il consiglio era stato criptico nelle sue spiegazioni, limitandosi a dire solo che Altman «non era stato sempre trasparente nelle sue comunicazioni».</p>
			<p class="testo" id="p_0021">Alcuni appiopparono a Sutskever e al consiglio un epiteto: <em class="calibre3">decels</em>, ovvero «decelerazionisti». La nuova spaccatura emersa nel settore dell’<span class="smallcaps">ai</span> era tra chi voleva accelerarne lo sviluppo e chi voleva rallentarlo. Al momento della stesura di questo libro, i fondatori di start-up nel campo dell’<span class="smallcaps">ai</span> si definivano su X (quello che fino a poco tempo prima era Twitter) come «(e/acc)», abbreviazione di <em class="calibre3">effective accelerationism</em> («accelerazionismo efficace»). Si trattava di una risposta all’altruismo efficace e, come movimento, mirava a risolvere i problemi dell’umanità costruendo e implementando l’<span class="smallcaps">ai</span> il più rapidamente possibile.</p>
			<p class="testo" id="p_0022">Per Nadella non faceva differenza. Era furioso. Aveva stanziato 13 miliardi di dollari in Open<span class="smallcaps">ai</span> soprattutto per la leadership visionaria di Altman e per la sua capacità di attrarre talenti, e quella partnership stava per mandare i profitti di Microsoft alle stelle. Circa diciottomila tra aziende e sviluppatori stavano usando i servizi <span class="smallcaps">ai</span> di Microsoft su Azure, e ora molti di loro si chiedevano se fosse il caso di passare alla concorrenza. Le azioni di Microsoft iniziarono a scendere alla chiusura del mercato il venerdì sera e quasi certamente sarebbero scese ancora il lunedì, alla riapertura. Nadella doveva agire.</p>
			<p class="testo" id="p_0023">Quel venerdì sera, a San Francisco, Altman parlò con Brockman della possibilità di avviare una nuova azienda nel campo dell’<span class="smallcaps">ai</span>. Il suo telefono squillava di continuo, con messaggi da investitori, colleghi e giornalisti che cercavano di capire cosa stesse succedendo, ma lui era concentrato con una determinazione chirurgica su un unico obiettivo: tirarsi fuori da quella situazione. Accolse decine di dipendenti di Open<span class="smallcaps">ai</span> e colleghi nella sua casa a Russian Hill per discutere di un nuovo progetto.</p>
			<p class="testo" id="p_0024">Nadella non voleva che questo accadesse. Sapeva che se Altman avesse avviato una nuova azienda gli investitori avrebbero fatto la fila, senza alcuna garanzia per Microsoft di ottenere una posizione dominante. Così, inaugurò il fine settimana con una serie di telefonate, conducendo personalmente le trattative con il consiglio di Open<span class="smallcaps">ai</span> per riportare Altman a bordo.</p>
			<p class="testo" id="p_0025">Il team dirigente di Altman fece pressione sul consiglio perché lo riassumesse, mettendolo in guardia sul fatto che, in caso contrario, Open<span class="smallcaps">ai</span> sarebbe crollata. «Il che sarebbe coerente con la missione», rispose Helen Toner. I dirigenti di Open<span class="smallcaps">ai</span> rimasero sbalorditi. In qualche modo, tuttavia, la risposta aveva una sua logica. La missione di Open<span class="smallcaps">ai</span> era creare l’<span class="smallcaps">agi</span> «a beneficio dell’umanità», e Toner e gli altri membri del consiglio erano del parere che fosse proprio Altman a compromettere l’obiettivo. Nei mesi precedenti, dietro le quinte, avevano covato una certa irritazione per come sembrava che stesse costruendo un vasto impero <span class="smallcaps">ai</span> parallelo, al di fuori di Open<span class="smallcaps">ai</span>. Altman aveva parlato con l’ex designer di Apple Jony Ive riguardo all’idea di realizzare un «iPhone dell’<span class="smallcaps">ai</span>» e stava cercando di raccogliere decine di miliardi di dollari da fondi sovrani del Medio Oriente per avviare un’azienda che producesse chip per l’<span class="smallcaps">ai</span>.</p>
			<p class="testo" id="p_0026">E poi c’era Worldcoin, la rete basata su criptovalute che Altman aveva fondato con l’obiettivo di fornire a ogni abitante della Terra un’identità digitale tramite la scansione dell’iride. L’obiettivo dichiarato di Altman era quello di identificare meglio gli esseri umani reali quando internet sarebbe stato invaso da bot e di distribuire i «miliardi di miliardi» di dollari generati dalla ricchezza dell’<span class="smallcaps">agi</span>; agli occhi dei detrattori, però, sembrava più un’enorme operazione di raccolta dati su larga scala.</p>
			<p class="testo" id="p_0027">All’interno di Open<span class="smallcaps">ai</span> si era aperta una frattura culturale tra Altman e Sutskever riguardo alla velocità con cui l’azienda stava commercializzando la propria tecnologia. Sutskever era sempre più coinvolto nella supervisione della sicurezza dell’<span class="smallcaps">ai</span> all’interno dell’azienda e le sue preoccupazioni non erano poi così diverse da quelle di Dario Amodei prima di lui. In particolare, non gli era piaciuto il lancio del <span class="smallcaps">gpt</span> Store, avvenuto solo poche settimane prima, che consentiva a qualsiasi sviluppatore di software la possibilità di creare versioni personalizzate di Chat<span class="smallcaps">gpt</span> e di monetizzarle.</p>
			<p class="testo" id="p_0028">McCauley e Toner, due dei tre membri indipendenti del consiglio, condividevano le preoccupazioni di Sutskever e avevano legami con organizzazioni di altruismo efficace. L’Open Philanthropy di Dustin Moskovitz, per esempio, aveva finanziato un gruppo di ricerca sull’<span class="smallcaps">ai</span> che McCauley aveva cofondato e nel quale Toner lavorava come analista senior di ricerca. Poche settimane prima di votare per l’allontanamento di Altman, il nome di Toner era apparso in un documento di ricerca che accusava Open<span class="smallcaps">ai</span> di «tagli e scorciatoie rischiosi» nella sua corsa verso il lancio di Chat<span class="smallcaps">gpt</span>. Inoltre, il paper lodava il nuovo rivale dell’azienda, Anthropic, per la decisione di ritardare il lancio del suo chatbot, Claude, al fine di evitare di «gettare benzina sul fuoco dell’hype sull’<span class="smallcaps">ai</span>».</p>
			<p class="testo" id="p_0029">Il documento aveva mandato Altman su tutte le furie. Convocata Toner, le aveva detto che quel suo scritto era pericoloso per Open<span class="smallcaps">ai</span>, considerando soprattutto che la Federal Trade Commission stava indagando sull’azienda. A luglio, infatti, la <span class="smallcaps">ftc</span> aveva avviato un’inchiesta per verificare se Open<span class="smallcaps">ai</span> avesse violato le leggi sulla protezione dei consumatori nel modo in cui aveva sviluppato Chat<span class="smallcaps">gpt</span>, chiedendo dettagli su come l’azienda intendesse affrontare i rischi creati dai suoi modelli di <span class="smallcaps">ai</span>. L’inchiesta era la più grande minaccia regolatoria che Altman avesse dovuto gestire fino ad allora.</p>
			<p class="testo" id="p_0030">Determinato a rimuovere Toner dal consiglio, ne aveva parlato con Sutskever e gli altri leader di Open<span class="smallcaps">ai</span>. Alla fine, però, Sutskever si era schierato con gli altri membri del consiglio per estromettere Altman. Chiamato a spiegarsi con i leader e gli investitori di Open<span class="smallcaps">ai</span>, il consiglio non fornì un motivo preciso per il licenziamento di Altman, chiamando in causa una crescente sfiducia nei confronti del carismatico imprenditore che aveva sviluppato un seguito quasi religioso tra i collaboratori, tendeva a raccontare versioni diverse a persone diverse e sembrava sempre ottenere ciò che voleva. I membri del consiglio erano arrivati al punto di sentirsi costretti a verificare la maggior parte delle cose che Altman diceva loro, circostanza che lo rendeva poco affidabile ai loro occhi, e temevano che le sue varie iniziative esterne potessero finire per sfruttare la tecnologia di Open<span class="smallcaps">ai</span>.</p>
			<p class="testo" id="p_0031">Nel prosieguo del weekend, tra i dipendenti di Open<span class="smallcaps">ai</span> montò una rivolta di massa. Nel suo solito stile tutto in minuscolo, Altman twittò: «adoro gli impiegati di Open<span class="smallcaps">ai</span>», e decine di dipendenti lo ritwittarono con emoji a forma di cuore. In quella ribellione, Microsoft vide una possibile leva per riportare Altman in azienda. Minacciò anche il consiglio di Open<span class="smallcaps">ai</span> di ritirare i suoi preziosissimi crediti per il cloud, fondamentali per l’addestramento dei modelli di <span class="smallcaps">ai</span>. Una grande fetta dei 13 miliardi di dollari che Microsoft si era impegnata a investire in Open<span class="smallcaps">ai</span> erano sotto forma di questi crediti, ma fino a quel momento Microsoft ne aveva erogati solo una parte.</p>
			<p class="testo" id="p_0032">Altman aveva posto alcune condizioni per tornare: Open<span class="smallcaps">ai</span> avrebbe dovuto cambiare il suo modello di governance, a cominciare dalle dimissioni del consiglio di amministrazione, e lui avrebbe dovuto essere scagionato da qualsiasi accusa di cattiva condotta. Ma il consiglio rimase fermo sulla sua posizione e assunse un nuovo <span class="smallcaps">ceo</span> per Open<span class="smallcaps">ai</span>, Emmet Shear, ex capo della piattaforma di streaming di videogiochi Twitch. Sui social, gli appassionati e gli imprenditori di <span class="smallcaps">ai</span> lo etichettarono subito come un <em class="calibre3">decel</em>. Quando indisse una riunione d’emergenza con tutti i dipendenti per domenica, molti di questi si rifiutarono di partecipare. Alcuni gli mandarono persino un’emoji con il dito medio su Slack, la piattaforma interna di messaggistica.</p>
			<p class="testo" id="p_0033">Anche Sutskever iniziava ad avere qualche dubbio. Durante il fine settimana aveva avuto diverse conversazioni intense con i leader di Open<span class="smallcaps">ai</span> e, a un certo punto, un colloquio emotivamente carico con la moglie di Brockman. Sutskever aveva celebrato il matrimonio civile della coppia negli uffici di Open<span class="smallcaps">ai</span>, quattro anni prima, e, secondo quanto riportato dal «Wall Street Journal», ora, in quegli stessi uffici, Anna Brockman lo stava supplicando, tra le lacrime, perché cambiasse idea sul licenziamento di Altman.</p>
			<p class="testo" id="p_0034">Nel frattempo, Nadella stava spingendo sul suo piano di riserva. Se Altman non fosse riuscito a riprendere il controllo di Open<span class="smallcaps">ai</span>, Microsoft avrebbe dovuto integrarlo pienamente nella propria struttura aziendale prima di lunedì mattina. Ci riuscì giusto in tempo. Lunedì mattina presto, Nadella twittò che Altman, Brockman e qualsiasi dipendente di Open<span class="smallcaps">ai</span> lo avesse desiderato, sarebbero diventati parte di un nuovo team di ricerca avanzata sull’<span class="smallcaps">ai</span> presso Microsoft. In risposta, le azioni dell’azienda salirono immediatamente. Ma si trattava solo di un piano B. Nadella voleva comunque Altman di nuovo al timone di Open<span class="smallcaps">ai</span>. Ospitare il team di Altman in Microsoft sarebbe stato costoso per molti aspetti. Avrebbe dovuto livellare gli stipendi di centinaia di nuovi dipendenti, molti dei quali guadagnavano milioni di dollari l’anno, e Microsoft si sarebbe assunta molti più rischi. Fino a quel momento, era stata Open<span class="smallcaps">ai</span> a sostenere tutta la pressione reputazionale e legale per aver lanciato strumenti come Chat<span class="smallcaps">gpt</span> e DALL-E 2 (cosa che, in quanto start-up, poteva permettersi di fare). Ma Microsoft non poteva, e nemmeno Altman, se fosse stato assunto dall’azienda madre. Tornando a una partnership meno invasiva, Microsoft avrebbe ottenuto tutto il prestigio senza doverne pagare le conseguenze in termini di responsabilità.</p>
			<p class="testo" id="p_0035">Ora tutti stavano spingendo affinché i membri del consiglio di Open<span class="smallcaps">ai</span> ossessionati dalla sicurezza si dimettessero e, entro la fine di lunedì, quasi tutti i 770 dipendenti di Open<span class="smallcaps">ai</span> avevano firmato una lettera in cui minacciavano di passare a Microsoft insieme ad Altman, a meno che i membri del consiglio non si fossero fatti da parte. «Microsoft ci ha assicurato che ci sono posti per tutti», recitava la lettera.</p>
			<p class="testo" id="p_0036">Ma era un enorme bluff. Pochissimi dipendenti di Open<span class="smallcaps">ai</span> volevano lavorare per Microsoft, un’azienda vecchio stile dove la gente rimaneva per decenni indossando pantaloni color kaki. Né la minaccia era unicamente dettata dalla lealtà verso Altman. Il problema più grande era che il licenziamento di Altman aveva mandato in fumo la possibilità, per molti dipendenti di Open<span class="smallcaps">ai</span> – specie quelli di lunga data –, di diventare milionari. L’azienda era a poche settimane dalla vendita delle azioni dei dipendenti a un grande investitore che avrebbe valutato Open<span class="smallcaps">ai</span> circa 86 miliardi di dollari. Con le azioni di Open<span class="smallcaps">ai</span> improvvisamente valutate a zero, quella grande liquidazione per il personale sarebbe svanita nel nulla, se Altman non fosse tornato.</p>
			<p class="testo" id="p_0037">A quel punto, Sutskever aveva ormai cambiato idea e figurava tra i firmatari. «Non ho mai voluto danneggiare Open<span class="smallcaps">ai</span>», scrisse su Twitter quel giorno, prendendo di sorpresa la stampa tecnologica al termine di un fine settimana a dir poco frenetico. «Farò tutto il possibile per riunire l’azienda», disse, aggiungendo che «rimpiangeva profondamente» il proprio operato. Altman ritwittò il post aggiungendo tre cuori.</p>
			<p class="testo" id="p_0038">Il drammatico allontanamento di Altman non avrebbe dovuto sorprendere nessuno, in realtà. «Il consiglio può licenziarmi», aveva affermato lui stesso pochi mesi prima, in un panel durante una conferenza. «Penso sia una cosa importante.» Open<span class="smallcaps">ai</span> era ancora governata da un consiglio senza scopo di lucro, con l’umanità come principale beneficiario. Per questo motivo, l’accordo operativo dell’azienda invitava i finanziatori a considerare i propri investimenti «nello spirito di una donazione, con la consapevolezza del fatto che potrebbe essere difficile sapere quale ruolo avrà il denaro in un mondo post-<span class="smallcaps">agi</span>».</p>
			<p class="testo" id="p_0039">Altman aveva scommesso di poter avere il meglio di entrambi i mondi, gestendo un’impresa con la missione filantropica di salvare l’umanità. Come aveva scritto dieci anni prima, i fondatori di start-up di maggior successo «creano qualcosa di simile a una religione». Quello che non aveva previsto era quanto le persone ci avrebbero creduto.</p>
			<p class="testo" id="p_0040">Il movimento dell’altruismo efficace era così potente da aver spinto persone come Sam Bankman-Fried e Dustin Moskovitz a donare miliardi di dollari. Aveva convinto centinaia di studenti universitari a cambiare le proprie scelte professionali. E poteva persuadere quattro membri del consiglio a scaricare l’amministratore delegato più popolare al mondo. Altman credeva che il suo consiglio di amministrazione avrebbe apprezzato il valore commerciale che aveva creato. Solo che non era andata così. Il consiglio era stato pensato per tutelare lo statuto di Open<span class="smallcaps">ai</span>, e scelse l’umanità.</p>
			<p class="testo" id="p_0041">Tuttavia, con quasi tutto il personale sul punto di andarsene, il consiglio non aveva più un’azienda da governare. Microsoft, inoltre, era pronta a proseguire tutto il lavoro di Altman: aveva copie del codice sorgente dei principali sistemi di Open<span class="smallcaps">ai</span> e diritti più ampi sulla sua proprietà intellettuale.</p>
			<p class="testo" id="p_0042">Cinque giorni dopo la rimozione di Altman, Open<span class="smallcaps">ai</span> annunciò la formazione di un nuovo consiglio. Sarebbe stato presieduto da Larry Summers, ex segretario al Tesoro degli Stati Uniti, e Bret Taylor, ex capo della compagnia di software aziendali Salesforce, noto anche per essere la voce più equilibrata nel consiglio di Twitter al momento dell’acquisizione da parte di Elon Musk. Entrambi avevano fatto parte di diversi consigli aziendali. Non scrivevano articoli accademici che criticavano le aziende per aver preso scorciatoie. Sapevano come soddisfare le esigenze di investitori come Microsoft. Helen Toner e Tasha McCauley, le due donne che sembravano aver sollevato le maggiori obiezioni contro Altman, furono costrette a dimettersi. Microsoft ottenne un seggio come osservatore nel consiglio, il che significava che Nadella non sarebbe più stato colto di sorpresa. Era riuscito a trasformare un problema in un’opportunità.</p>
			<p class="testo" id="p_0043">Ma i drammatici eventi del novembre 2023 distrussero anche il miraggio di responsabilità che Altman sosteneva di avere sopra di sé. Aveva elogiato pubblicamente il fatto che un consiglio d’amministrazione potesse licenziarlo, quando, in realtà, alla prova dei fatti non era stato così, a giudicare dal trattamento riservato a Toner e a McCauley. Queste ultime furono anche il bersaglio delle critiche più accese sui social, mentre i colleghi maschi, Sutskever e D’Angelo, conservarono in gran parte la propria reputazione e i propri ruoli. D’Angelo rimase nel consiglio e, pur rinunciando al seggio, Sutskever mantenne una posizione di leadership in Open<span class="smallcaps">ai</span>.</p>
			<p class="testo" id="p_0044">Quanto accaduto a Open<span class="smallcaps">ai</span> era esattamente ciò che Google aveva cercato per anni di evitare con DeepMind. Concedere un potere reale a un consiglio indipendente significava permettergli di usarlo e, potenzialmente, di mandare in rovina l’azienda. Nella loro corsa verso l’<span class="smallcaps">agi</span>, sia Altman sia Hassabis avevano sperimentato strutture di governance che tentavano di bilanciare gli interessi dell’umanità con la ricerca del profitto. Ma i loro sforzi erano regolarmente falliti. Tra rivalità meschine, rischi competitivi e sete di potere, il grande capitale aveva avuto la meglio.</p>
			<p class="testo" id="p_0045">Alcuni ritengono che tutto il dramma intorno al licenziamento di Altman abbia rafforzato la tesi a favore dell’<span class="smallcaps">ai</span> open-source, che consentirebbe a chiunque di modificarne o migliorarne il codice. Benché questo approccio offra alcuni vantaggi – come una maggiore trasparenza e un controllo etico più democratico –, il dibattito sulla sua sicurezza ed equità rimane aperto. L’open-source non è una garanzia contro gli abusi e potrebbe non avere la qualità dei sistemi chiusi. Anche il termine stesso è soggetto a interpretazioni. Meta, per esempio, promuove i suoi modelli di <span class="smallcaps">ai</span> come open-source, pur imponendo restrizioni che non si allineano completamente con la definizione. «L’open-source può in realtà contribuire a concentrare il potere», afferma Meredith Whittaker, fondatrice dell’Open Research Group di Google. «Lo abbiamo visto con Android.» Google stabilisce di fatto gli standard di Android e ne determina l’evoluzione, creando un’asimmetria di potere che rende difficile per altre aziende apportare modifiche al sistema operativo mobile usato da 3,6 miliardi di persone nel mondo.</p>
			<p class="testo" id="p_0046">Mentre Altman si adattava alla nuova direzione più allineata agli interessi aziendali di Open<span class="smallcaps">ai</span> sotto Microsoft, Hassabis era ancora impegnato nella sua missione volta a svelare i misteri dell’universo tramite l’<span class="smallcaps">ai</span>. Ora racconta di essere l’unico in DeepMind a lavorare su questo fronte, portando avanti ricerche di meccanica quantistica fino a tarda notte, e nelle prime ore del mattino, a casa, sul suo computer. «È ciò che faccio nel tempo libero, per quanto limitato», dice, definendolo il suo «hobby». Quando DeepMind sarà più vicina all’<span class="smallcaps">agi</span>, allora inizierà a condurre gli esperimenti necessari per decifrare i segreti dell’universo, aggiunge. Per il momento, tuttavia, quelle ambizioni personali che un tempo lo avevano spinto verso l’<span class="smallcaps">agi</span> sono relegate al ruolo di passatempo notturno. È troppo impegnato a dirigere l’intera divisione <span class="smallcaps">ai</span> di Google, passata da un gruppo di circa quattrocento ricercatori a oltre cinquemila.</p>
			<p class="testo" id="p_0047">«Le cose evolvono con la missione e la tecnologia», spiega. «Bisogna sempre aggiornare le strutture di governance, ma penso che quelle attuali siano davvero valide.»</p>
			<p class="testo" id="p_0048">Hassabis non è turbato dai tentativi falliti di creare consigli e comitati di supervisione per monitorare il suo lavoro. «Abbiamo fatto una svolta verso una serie di consigli interni», afferma, riferendosi a vari «comitati di revisione» composti da dirigenti di Google. «Probabilmente avevamo una visione un po’ troppo idealistica, dieci anni fa, quando abbiamo iniziato a pensarci.»</p>
			<p class="testo" id="p_0049">Per quanto nobili fossero le loro intenzioni e per quanto Hassabis e Altman avessero cercato di prendere le distanze dall’influenza commerciale, ora si trovavano di fatto alla guida di due delle più grandi aziende del mondo. Altman era al timone di alcuni dei progetti più strategici di Microsoft, posizione che lo metteva in corsa per diventare un giorno il <span class="smallcaps">ceo</span> dell’azienda, se lo avesse voluto. Lo stesso si diceva di Hassabis. Alcuni dipendenti (o ex) di Google ipotizzavano che un giorno potesse sostituire Pichai come <span class="smallcaps">ceo</span> di Alphabet.</p>
			<p class="testo" id="p_0050">«Demis, da Londra, sta guidando il progetto più importante di Google. Nessuno avrebbe mai immaginato che sarebbe andata a finire così», afferma un ex dirigente del colosso. «Forse è sempre stato questo, il suo piano.»</p>
			<p class="testo" id="p_0051">«I vincitori, nei prossimi anni, non saranno i laboratori di ricerca», dice un ex scienziato di Open<span class="smallcaps">ai</span>. «Saranno le aziende che costruiscono prodotti, perché l’<span class="smallcaps">ai</span> non riguarda più la ricerca.»</p>
			<p class="testo" id="p_0052">La storia delle graffette raccontata da Nick Bostrom – quella in cui una superintelligenza artificiale distrugge la civiltà convertendo tutte le risorse del mondo in minuscoli pezzi di metallo – potrà anche sembrare fantascienza, ma sotto molti aspetti è un’allegoria della stessa Silicon Valley. Negli ultimi vent’anni, alcune aziende sono cresciute fino a diventare colossi, perseguendo i propri obiettivi con un’ossessione patologica, spazzando via i concorrenti più piccoli per accrescere la propria quota di mercato. Invece di «funzioni di fitness», le aziende tecnologiche usano espressioni come «stella polare» per descrivere questi obiettivi. Per anni, la stella polare di Facebook è stata l’aumento del numero di utenti attivi giornalieri, un parametro che ha guidato le decisioni di Mark Zuckerberg e del suo gruppo dirigente. Ma l’ossessione per la crescita costante ha portato con sé una serie di problemi sociali, dall’aggravarsi dei disturbi legati all’immagine corporea tra gli adolescenti su Instagram all’accentuarsi della polarizzazione politica tra gli utenti di Facebook.</p>
			<p class="testo" id="p_0053">Quando i tecnologi immaginavano cosa avrebbe potuto fare una superintelligenza fuori controllo, quello che guardavano in realtà era un riflesso di loro stessi in un mondo in cui alle aziende fosse stato consentito di diventare monopoli globali inarrestabili. A sviluppare la tecnologia più trasformativa della storia recente erano pochi individui che, incapaci di resistere alla tentazione di vincere a ogni costo, avrebbero finito per ignorarne gli effetti reali. I veri pericoli non provenivano tanto dall’<span class="smallcaps">ai</span> in sé, quanto dalle bizze imprevedibili degli umani che la governavano.</p>
			<p class="testo" id="p_0054">Nel mondo degli scacchi circola un detto famoso: le tattiche fanno vincere le partite, la strategia fa vincere i tornei. Sia Altman sia Hassabis hanno adottato tattiche innovative nella loro corsa alla creazione dell’<span class="smallcaps">agi</span> e, man mano che questa corsa si trasformava in una gara serrata, si sono avvicinati sempre di più ai probabili vincitori del torneo: Microsoft e Google. Nel momento in cui i sogni di entrambi hanno finito per rafforzare i due colossi aziendali, anche le loro posizioni si sono consolidate. Google e Microsoft sono in prima linea nella corsa alla supremazia dell’<span class="smallcaps">ai</span>, guidate dallo scacchista nerd di Londra e dal guru delle start-up di St. Louis. E, che ci piaccia o no, saremo tutti costretti a seguirli nel loro viaggio.</p>
		</section>
	</body>
</html>
