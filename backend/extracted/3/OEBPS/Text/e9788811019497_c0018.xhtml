<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:ibooks="http://apple.com/ibooks/html-extensions" lang="it-IT" xml:lang="it-IT" class="calibre">
  <head>
    <title>FILE 18 – Supremacy – Capitolo</title>
    <meta content="urn:uuid:35484d83-cd47-4b21-bd76-ea9d55abc8bb" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body epub:type="bodymatter" class="calibre2">
		<section epub:type="chapter" role="doc-chapter" class="calibre">
			<h2 class="capitolo" id="h2-0001"><span class="smallcaps1">13. ciao, chatgpt</span></h2>
			<p class="testo" id="p_0001">Era un pomeriggio freddo e ventoso di febbraio a Redmond, nello stato di Washington, quando Soma Somasegar entrò nel tepore del quartier generale di Microsoft dirigendosi alla reception per ottenere il badge temporaneo da visitatore. Somasegar era un ingegnere informatico corpulento e gioviale che aveva scalato i ranghi di Microsoft per ventisei anni, fino a dirigere la divisione sviluppatori, supervisionando tutti gli strumenti utilizzati dai programmatori per creare software per Windows e altri prodotti Microsoft. Nel 2015, aveva lasciato l’azienda per diventare un venture capitalist, finanziando start-up e fornendo loro consulenza su come pianificare una futura cessione ai colossi della zona come Microsoft e Amazon. Ma gli piaceva rimanere in contatto con l’ex casa madre, consapevole del fatto che le sue mosse avevano un effetto a catena sull’intero settore, e considerava il <span class="smallcaps">ceo</span> di Microsoft, Satya Nadella, un amico.</p>
			<p class="testo" id="p_0002">Quel pomeriggio di febbraio del 2022, notò che Nadella era più entusiasta del solito. Microsoft si stava preparando a offrire un nuovo strumento agli sviluppatori di software. Era esattamente il genere di cosa che appassionava Somasegar. Aiutare gli sviluppatori di software di terze parti era stato il suo lavoro, un tempo. Ma questo non era un semplice strumento per individuare errori nei codici o per integrarsi con i sistemi di Microsoft. Era qualcosa di ben più straordinario. Il nuovo tool si chiamava GitHub Copilot e poteva fare ciò per cui gli stessi sviluppatori di software venivano pagati profumatamente: scrivere righe di codice.</p>
			<p class="testo" id="p_0003">GitHub era il servizio online di Microsoft per aiutare i creatori di software a conservare e gestire il loro codice, e Copilot era… be’, all’inizio Somasegar non comprese del tutto la spiegazione di Nadella, visto che questi continuava a usare espressioni come «rivoluzionario», «fenomenale» e «oh, mio Dio». Non lo aveva mai visto così su di giri.</p>
			<p class="testo" id="p_0004">Alla fine, capì che Copilot era una sorta di assistente che aiutava a scrivere righe di codice e che Microsoft lo stava integrando in un programma popolare per sviluppatori chiamato Visual Studio. Una volta iniziato a digitare un codice, Copilot mostrava alcuni suggerimenti per la riga successiva in un testo più chiaro. Era come l’autocompletamento, ma pensato per costruire software. Se gli sviluppatori intendevano accettare il suggerimento di Copilot, bastava premere il tasto Tab. Poteva scrivere interi blocchi di codice, incluse funzioni complete su più righe per accedere a un’app, tanto per fare un esempio.</p>
			<p class="testo" id="p_0005">Microsoft stava ancora raccogliendo feedback dagli sviluppatori e aveva lanciato solo una versione in anteprima del sistema. Ma Nadella affermò che i programmatori stavano già scoprendo di poter velocizzare il loro lavoro, perché Copilot scriveva fino al 20 per cento del loro codice: una quantità enorme.</p>
			<p class="testo" id="p_0006">Copilot era stato costruito sul nuovo modello di Open<span class="smallcaps">ai</span> chiamato Codex, che aveva una struttura simile al suo modello linguistico più recente, <span class="smallcaps">gpt</span>-3.5, ed era stato addestrato su GitHub, uno dei più grandi archivi di codice al mondo.</p>
			<p class="testo" id="p_0007">Attraverso Copilot, Open<span class="smallcaps">ai</span> dimostrava quanto fosse versatile il trasformatore quando utilizzava il suo meccanismo di «attenzione» per tracciare relazioni tra i diversi punti dati. Era come uno strumento di mappatura in grado di trasformare i dati in una galassia di stelle. Se ogni stella fosse stata una parola, per esempio, il trasformatore avrebbe mappato il percorso tra le diverse parole, collegando ciascuna di esse a quelle con significati simili. Non importava che quei dati fossero parole o pixel di un’immagine: riconoscendo i modelli all’interno delle relazioni che stabilivano, i trasformatori potevano aiutare a generare nuovi dati coerenti, che si trattasse di testo, codice o persino immagini.</p>
			<p class="testo" id="p_0008">Google non aveva provato ad applicare il trasformatore al codice su larga scala, come invece aveva fatto Open<span class="smallcaps">ai</span>. «Questo è un altro errore che hanno commesso, laddove al contrario Open<span class="smallcaps">ai</span> ha visto giusto», dice Aravind Srinivas, imprenditore nel campo <span class="smallcaps">ai</span> che ha lavorato sia per Google sia per Open<span class="smallcaps">ai</span>. «Se questi modelli venivano [preaddestrati] sul codice, finivano per diventare molto più bravi nel ragionamento.»</p>
			<p class="testo" id="p_0009">Questo perché la programmazione informatica richiede capacità di pensare passo dopo passo. «Se ci fosse un bambino abbastanza bravo in matematica e programmazione, a scuola, ci si aspetterebbe che fosse più intelligente della media e che avesse la capacità di dedurre e scomporre concetti complessi in unità più semplici», dice Srinivas. «Ed è proprio quello che si richiede ai modelli linguistici di grandi dimensioni.»</p>
			<p class="testo" id="p_0010">Probabilmente era un concetto controintuitivo per i dirigenti di Google, il cui business ruotava tutto intorno al linguaggio e alla pubblicità, ma in quanto leader del software, a Microsoft interessava molto di più costruire strumenti per sviluppatori. Per fortuna di Open<span class="smallcaps">ai</span>, insegnare ai suoi modelli a scrivere righe di codice non serviva solo a compiacere il nuovo partner, ma stava anche rendendo i suoi modelli più intelligenti.</p>
			<p class="testo" id="p_0011">Somasegar chiese a Nadella cosa pensasse di Sam Altman. «Ha a cuore la soluzione di problemi globali», rispose Nadella. La gamma di argomenti di cui Altman parlava con Nadella era «fuori scala», ricorda Somasegar, e questo rendeva Nadella ancora più entusiasta di lavorare con lui. Insomma: più le ambizioni di Altman suonavano folli e utopistiche, più Nadella sembrava credere che potesse davvero aiutare Microsoft a crescere.</p>
			<p class="testo" id="p_0012">Considerata a lungo una teoria marginale nel campo dell’<span class="smallcaps">ai</span>, per il colosso del software l’idea di costruire un’<span class="smallcaps">agi</span> si stava trasformando in un prodotto commerciabile. La sua realizzazione avrebbe aiutato Microsoft a creare fogli di calcolo migliori, e un’intera serie di strumenti in grado di rendere tutto il software dell’azienda molto più intelligente.</p>
			<p class="testo" id="p_0013">Nella mente di Nadella, GitHub Copilot divenne un evento seminale. «S’intravedeva un prodotto che, una volta perfezionato, avrebbe cambiato il mondo», racconta Somasegar, soprattutto quando fosse stato applicato ad altri tipi di software. Da quel momento, Nadella e il suo direttore tecnico, Kevin Scott, cominciarono a fare da evangelisti per l’<span class="smallcaps">ai</span> all’interno di Microsoft, menzionando la tecnologia in quasi ogni revisione di prodotto o decisione strategica. <em class="calibre3">Perché il vostro team non sta usando l’<span class="smallcaps">ai</span>? Puntate tutto sull’<span class="smallcaps">ai</span> e utilizzate i modelli di Open<span class="smallcaps">ai</span> dove possibile.</em></p>
			<p class="testo" id="p_0014">Questo, naturalmente, mandò su tutte le furie gli specialisti di <span class="smallcaps">ai</span> della divisione Microsoft Research che da anni lavoravano su modelli di intelligenza artificiale. Secondo articoli di stampa e numerosi ricercatori venuti a conoscenza di quelle critiche, Nadella rimproverò i dirigenti del team per non essere stati all’altezza degli standard raggiunti dalla forza lavoro molto più contenuta di Open<span class="smallcaps">ai</span>.</p>
			<p class="testo" id="p_0015">«Open<span class="smallcaps">ai</span> ha costruito tutto questo con duecentocinquanta persone», disse Nadella al capo di Microsoft Research, secondo quanto riportato da «The Information». «Perché abbiamo questa divisione, allora?»</p>
			<p class="testo" id="p_0016">Disse anche ai suoi ricercatori di smettere di cercare di costruire quelli che venivano chiamati «modelli di fondazione», o grandi sistemi come i modelli <span class="smallcaps">gpt</span> di Open<span class="smallcaps">ai</span>. In preda alla frustrazione, alcuni dipendenti lasciarono l’azienda.</p>
			<p class="testo" id="p_0017">Ma anche loro dovettero ammettere che Copilot era uno strumento straordinario che aiutava i programmatori a scrivere nuove righe di codice e a velocizzare il lavoro con il codice esistente. Nadella immaginava di applicare la parola «copilot» a una gamma più ampia di servizi Microsoft, utilizzando la tecnologia del modello linguistico di Open<span class="smallcaps">ai</span> per migliorare il modo in cui le persone redigevano e-mail e generavano fogli di calcolo.</p>
			<p class="testo" id="p_0018">Settimane dopo l’incontro di Somasegar con Nadella, all’inizio del 2022, Open<span class="smallcaps">ai</span> iniziò a testare i cugini più avanzati di <span class="smallcaps">gpt</span>-3, prendendo ispirazione da importanti innovatori storici – Ada, Babbage, Curie e Da Vinci – per denominare le varie versioni. Nel tempo, questi modelli riuscivano a processare domande sempre più complesse, fornendo risposte sempre più personalizzate. Per lo più, al pubblico non era ancora chiaro quanto sofisticato stesse diventando il software. Ma le cose iniziarono a cambiare nell’aprile del 2022, quando Open<span class="smallcaps">ai</span> portò alcune delle capacità linguistiche di <span class="smallcaps">gpt</span>-3 nel mondo del visual e lanciò la sua prima grande invenzione nel mondo reale.</p>
			<p class="testo" id="p_0019">In un angolo dell’ufficio di Open<span class="smallcaps">ai</span>, a San Francisco, un trio di ricercatori cercava da due anni di utilizzare un cosiddetto «modello di diffusione» per generare immagini. Un modello di diffusione operava essenzialmente creando un’immagine al contrario. Invece di partire da una tela vuota, come farebbe un artista, cominciava da una tela già piena di colori e dettagli casuali. Il modello aggiungeva molto «rumore» o casualità ai dati, rendendoli irriconoscibili, e poi, passo dopo passo, li riduceva per far emergere lentamente la struttura dell’immagine. A ogni passaggio, l’immagine diventava sempre più chiara e dettagliata, proprio come quella di un pittore che affini la propria opera. Questo approccio di «diffusione», combinato con uno strumento di etichettatura delle immagini denominato <span class="smallcaps">clip</span>, divenne la base di un nuovo modello entusiasmante che i ricercatori battezzarono DALL-E 2.</p>
			<p class="testo" id="p_0020">Il nome era un omaggio sia a <em class="calibre3">WALL-E</em>, il film d’animazione del 2008 su un robot che scappa dal pianeta Terra, sia al pittore surrealista Salvador Dalí. Le immagini di DALL-E a volte sembravano surreali, ma lo strumento in sé era straordinario per chi vi si imbatteva per la prima volta. Se digitavi un prompt di testo come «una sedia a forma di avocado», ottenevi una serie di immagini pertinenti, molte delle quali incredibilmente fotorealistiche. Le immagini erano rappresentazioni così fedeli anche dei prompt più complessi che, nel giro di pochi giorni dal lancio, DALL-E 2 entrò in tendenza su Twitter, con gli utenti che cercavano di superarsi l’un l’altro creando le immagini più stravaganti possibili: «Tokyo sotto attacco di un criceto Godzilla con un sombrero in testa» o «ragazzi ubriachi che vagano per Mordor a torso nudo». I volti umani spesso apparivano deformati in maniera inquietante, ma non si poteva negare che queste immagini fossero più dettagliate di qualsiasi cosa un computer avesse mai prodotto prima. Improvvisamente, Open<span class="smallcaps">ai</span> dominava il ciclo delle notizie perché, per la prima volta, il pubblico stava assaporando cosa fosse in grado di fare.</p>
			<p class="testo" id="p_0021">Mentre Google aveva scelto di tenere sotto traccia questo genere di innovazioni, Altman voleva che il maggior numero di persone possibile provasse la nuova creazione di Open<span class="smallcaps">ai</span>. Come guru delle start-up della Silicon Valley, da anni consigliava agli imprenditori di lanciare in fretta i loro prodotti nel mondo reale. I tecnologi a volte si riferiscono a questa strategia come «ship it» o come rilascio di un <em class="calibre3">minimum viable product</em> («prodotto minimo praticabile») o <span class="smallcaps">mvp</span>, ma l’idea è la stessa: mettere il software nelle mani degli utenti il più velocemente possibile per creare un ciclo di feedback tra l’azienda e gli stessi utenti, usando sostanzialmente il pubblico come cavia. Questo era il credo su cui erano costruiti giganti come Facebook, Uber e Stripe, e di cui Altman era un fermo sostenitore. Il modo migliore per testare un prodotto era metterlo subito in circolazione.</p>
			<p class="testo" id="p_0022">Nei mesi successivi, Open<span class="smallcaps">ai</span> avrebbe gradualmente lanciato DALL-E 2, dapprima con una lista d’attesa di circa un milione di persone, giusto nel caso in cui il sistema producesse immagini offensive o dannose. Cinque mesi più tardi, al richiamo di «Fiuu, è andata bene!» (ovvero, constatato che <span class="smallcaps">gpt</span>-2 non rappresentava una minaccia per il mondo), consentì l’accesso a chiunque.</p>
			<p class="testo" id="p_0023">DALL-E 2 era stato addestrato su milioni di immagini prelevate dal web, ma, come in passato, Open<span class="smallcaps">ai</span> non fornì dettagli riguardo a cosa esattamente fosse stato utilizzato per l’addestramento. Dato che il sistema riusciva a creare immagini nello stile di Picasso, era probabile che le opere di Picasso fossero state incluse nel «calderone» dell’addestramento. Ma non era possibile saperlo con certezza. E non c’era modo di sapere se anche il lavoro di altri artisti meno noti fosse stato utilizzato per allenare il sistema, perché Open<span class="smallcaps">ai</span> non lasciò trapelare nulla circa il set di dati impiegati, sostenendo che farlo avrebbe permesso a potenziali malintenzionati di replicare il modello.</p>
			<p class="testo" id="p_0024">A scoprirlo a proprie spese fu Greg Rutkowski, artista digitale polacco noto per i paesaggi fantasy popolati da zannuti draghi sputafuoco e maghi. Il suo nome divenne uno dei prompt più popolari su una versione rivale e open-source di DALL-E 2 chiamata Stable Diffusion. Questo sollevò un quesito preoccupante: perché pagare un artista come Rutkowski per produrre nuove opere d’arte quando esisteva un software in grado di replicarne lo stile?</p>
			<p class="testo" id="p_0025">Gli utenti iniziarono a notare un altro problema con DALL-E 2. Se gli chiedevi di generare immagini fotorealistiche di <span class="smallcaps">ceo</span>, quasi tutte restituivano uomini bianchi. Il prompt <em class="calibre3">nurse</em> («infermiere/infermiera») portava a immagini di donne, mentre <em class="calibre3">lawyer</em> («legale») generava immagini di uomini.</p>
			<p class="testo" id="p_0026">Intervistato nell’aprile del 2022 sull’argomento, come al solito Altman affrontò la controversia di petto, ammettendo che ciò costituiva un problema e che Open<span class="smallcaps">ai</span> ci stava lavorando. Una delle strategie utilizzate puntava a impedire a DALL-E 2 di generare immagini violente o pornografiche, rimuovendo quel tipo di immagini dai dati di addestramento.</p>
			<p class="testo" id="p_0027">Inoltre, Open<span class="smallcaps">ai</span> impiegava collaboratori in paesi in via di sviluppo come il Kenya per indirizzare il modello verso risposte più appropriate. Questo passaggio era fondamentale, perché significava che, anche dopo aver completato l’addestramento di un modello come <span class="smallcaps">gpt</span>-3 o DALL-E 2, Open<span class="smallcaps">ai</span> poteva continuare a perfezionarlo con l’aiuto di revisori umani, rendendo le sue formulazioni più sfumate, pertinenti ed etiche. Classificando le risposte di DALL-E 2 su una scala da buono a cattivo, gli esseri umani potevano guidarlo verso contenuti complessivamente migliori.</p>
			<p class="testo" id="p_0028">Tuttavia, i revisori non erano sempre coerenti nelle loro valutazioni, e ripulire i dati di addestramento di DALL-E 2 dai problemi poteva sembrare un gioco del tipo «acchiappa la talpa». All’inizio, i ricercatori di Open<span class="smallcaps">ai</span> avevano cercato di rimuovere tutte le immagini eccessivamente sessualizzate di donne presenti nel set di addestramento, per evitare che DALL-E 2 le rappresentasse come oggetti sessuali. Ma questa scelta aveva un costo: riduceva «di molto» il numero di donne nel dataset, secondo le dichiarazioni di Mira Murati, all’epoca responsabile della ricerca e dei prodotti di Open<span class="smallcaps">ai</span>. Non specifica di quanto. «Abbiamo dovuto fare alcune modifiche perché non vogliamo lobotomizzare il modello. È davvero una cosa complicata.»</p>
			<p class="testo" id="p_0029">I volti fotorealistici di DALL-E 2 erano il suo punto debole in termini di stereotipi, e Open<span class="smallcaps">ai</span> sembrava pienamente consapevole del problema. A tal punto che, quando un gruppo interno di quattrocento persone – per lo più dipendenti di Open<span class="smallcaps">ai</span> e Microsoft – iniziò a testare il sistema, Open<span class="smallcaps">ai</span> vietò loro di condividere pubblicamente qualsiasi ritratto realistico generato da DALL-E 2.</p>
			<p class="testo" id="p_0030">Alcuni dipendenti di Open<span class="smallcaps">ai</span> erano preoccupati per la fretta con cui l’azienda stava rilasciando uno strumento in grado di generare foto false. Nata come organizzazione non profit dedicata alla realizzazione di un’<span class="smallcaps">ai</span> sicura, Open<span class="smallcaps">ai</span> stava diventando una delle aziende più aggressive nel mercato. Un membro anonimo del team, impiegato sui test di sicurezza, raccontò a «Wired» che sembrava che l’azienda stesse distribuendo la tecnologia solo per metterla in mostra, anche se al momento sussisteva «un enorme margine di rischio».</p>
			<p class="testo" id="p_0031">Ma Altman puntava a un obiettivo ben più ambizioso. Era convinto che il nuovo sistema avesse superato una soglia importante nel cammino verso l’<span class="smallcaps">agi</span>. «Sembra comprendere davvero i concetti», confidò in un’intervista, «e questo sa di intelligenza.» DALL-E 2 era talmente straordinario che persino i più scettici avrebbero dovuto prendere in seria considerazione l’idea dell’<span class="smallcaps">agi</span>, aggiunse.</p>
			<p class="testo" id="p_0032">La magia non stava solo nelle capacità di DALL-E 2. Risiedeva anche nell’impatto che lo strumento aveva sulle persone. «Le immagini hanno un potere emotivo», commentò lo stesso Altman. DALL-E 2 stava suscitando molto clamore. E a differenza di GitHub Copilot, che si limitava a completare un codice già avviato da qualcuno, questo strumento creava contenuti <em class="calibre3">ex novo</em>. Era come chiedere a un grafico di disegnare qualsiasi cosa voleste.</p>
			<p class="testo" id="p_0033">Proprio quest’idea di generare contenuti da zero rese la mossa successiva di Altman ancora più sensazionale. <span class="smallcaps">gpt</span>-1 era piuttosto simile a uno strumento di completamento automatico che continuava ciò che un essere umano aveva iniziato a digitare. Ma <span class="smallcaps">gpt</span>-3 e il suo ultimo aggiornamento, <span class="smallcaps">gpt</span>-3.5, generavano prosa, proprio come DALL-E 2 generava immagini, partendo da zero.</p>
			<p class="testo" id="p_0034">Mentre il mondo continuava ad ammirare DALL-E 2, iniziarono a circolare voci sul fatto che il rivale Anthropic stava lavorando a un chatbot, alimentando la competizione. All’inizio di novembre del 2022, i dirigenti di Open<span class="smallcaps">ai</span> comunicarono al personale che nel giro di poche settimane avrebbero lanciato un chatbot tutto loro basato su <span class="smallcaps">gpt</span>-3.5. Circa una dozzina di persone si riunì per lavorare al progetto, che non era poi troppo diverso da Meena, il chatbot sviluppato due anni prima in Google da Noam Shazeer e tenuto segreto.</p>
			<p class="testo" id="p_0035">Non sarebbe stato un vero e proprio lancio di prodotto, assicurò la leadership di Open<span class="smallcaps">ai</span> al personale, bensì una «anteprima di ricerca a basso profilo». Tuttavia, alcuni dipendenti affermarono di non sentirsi a proprio agio con questa strategia, non sapendo come il pubblico avrebbe potuto abusare di un modello linguistico tanto fluido e abile.</p>
			<p class="testo" id="p_0036">Non solo: il chatbot commetteva spesso errori fattuali. I ricercatori che vi lavoravano decisero di non rendere il sistema più cauto, poiché ciò lo avrebbe portato a rifiutare domande alle quali invece avrebbe potuto rispondere correttamente. Non volevano che dicesse «Non lo so». Preferirono dunque calibrarlo perché suonasse più autorevole, anche se questo comportava il rischio di qualche inesattezza. Il prodotto fu battezzato Chat<span class="smallcaps">gpt</span>.</p>
			<p class="testo" id="p_0037">Altman spingeva per il lancio. A suo dire, centinaia di dipendenti di Open<span class="smallcaps">ai</span> avevano già testato e valutato Chat<span class="smallcaps">gpt</span>; inoltre, era importante abituare l’umanità a ciò che l’intelligenza artificiale era destinata a fare, un po’ come lo è immergere lentamente i piedi in una piscina fredda. In un certo senso, Open<span class="smallcaps">ai</span> stava facendo un favore al mondo, preparandolo all’arrivo del suo modello più potente, <span class="smallcaps">gpt</span>-4. Nei test interni, <span class="smallcaps">gpt</span>-4 era in grado di comporre discrete poesie, e le sue battute erano così riuscite che avevano fatto ridere i dirigenti di Open<span class="smallcaps">ai</span>, come racconta un manager dell’epoca. Ma non avevano idea dell’impatto che avrebbe avuto sul mondo o sulla società: l’unico modo per scoprirlo era renderlo pubblico. Sul suo sito web, Open<span class="smallcaps">ai</span> tratteggiava questa filosofia di «rilascio iterativo»: distribuire i prodotti nelle loro varie fasi di sviluppo per studiarne meglio la sicurezza e l’impatto. Secondo l’azienda, era il procedimento migliore per assicurarsi di costruire un’<span class="smallcaps">agi</span> che andasse a beneficio dell’umanità.</p>
			<p class="testo" id="p_0038">Il 30 novembre 2022, in un post sul suo blog, Open<span class="smallcaps">ai</span> annunciò l’uscita di una demo pubblica di Chat<span class="smallcaps">gpt</span>. Molti all’interno di Open<span class="smallcaps">ai</span>, inclusi alcuni membri del team che lavoravano alla sicurezza, non erano nemmeno a conoscenza del lancio, e alcuni iniziarono a scommettere su quante persone lo avrebbero usato dopo una settimana. La stima più alta era di centomila utenti. Lo strumento in sé era semplicemente un sito web con una casella di testo. Bastava scrivere qualsiasi cosa nella casella e il bot, alimentato da <span class="smallcaps">gpt</span>-3.5, avrebbe risposto. La maggior parte degli utenti non aveva mai sentito parlare di Open<span class="smallcaps">ai</span>, figuriamoci di <span class="smallcaps">gpt</span>-3. E nessuno, nemmeno i ricercatori di Open<span class="smallcaps">ai</span>, sapeva cosa sarebbe successo una volta che la gente lo avesse messo alla prova.</p>
			<p class="testo" id="p_0039">«Oggi abbiamo lanciato Chat<span class="smallcaps">gpt</span>», twittò Altman intorno alle 11.30, ora di San Francisco. «Provate a parlarci qui: http://chat.openai.com.»</p>
			<p class="testo" id="p_0040">Seguì il silenzio, mentre un campione di nicchia, composto da sviluppatori software e scienziati, si catapultava sul sito per testarlo. Nelle ore successive, le loro recensioni iniziarono a fioccare su Twitter:</p>
			<blockquote class="citazione" id="blq-1">
			<p class="afilo" id="p_0041">12.26 <span class="smallcaps">pt</span> @MarkovMagnifico: Sto giocando con Chat<span class="smallcaps">gpt</span> [proprio in questo momento] e ho anticipato la mia timeline per l’<span class="smallcaps">agi</span> a oggi.</p>
			<p class="afilo" id="p_0042">12.37 <span class="smallcaps">pt</span> @AndrewHartAR: È appena uscito Chat<span class="smallcaps">gpt</span>. Ho visto il futuro.</p>
			<p class="afilo" id="p_0043">13.37 <span class="smallcaps">pt</span> @skirano: Assolutamente pazzesco. Ho chiesto a #chatgpt di generare un sito web personale. Ha mostrato passo dopo passo […] come crearlo, poi ha aggiunto <span class="smallcaps">html</span> e <span class="smallcaps">css</span>.</p>
			<p class="afilo" id="p_0044">14.09 <span class="smallcaps">pt</span> @justindross: Per le domande che ho, al momento Chat<span class="smallcaps">gpt</span> è un punto di partenza migliore rispetto allo stesso Google. È pazzesco.</p>
			<p class="afilo" id="p_0045">14.29 <span class="smallcaps">pt</span> @Afinetheorem: Non sarà più possibile assegnare compiti scritti per casa.</p>
			</blockquote>
			<p class="testo" id="p_0046">Era difficile trovare una singola valutazione negativa di Chat<span class="smallcaps">gpt</span>. La risposta prevalente era di stupore. A renderlo davvero straordinario non era solo la fluidità, ma anche la vastità del suo sapere. Quasi tutti avevano già provato un chatbot, che fosse Alexa o un bot per il servizio clienti di qualche tipo, e la maggior parte era abituata a conversazioni limitate e traballanti. Ma Chat<span class="smallcaps">gpt</span> riusciva a rispondere praticamente a qualsiasi domanda con eloquenza. Era come passare dal parlare con un bambino piccolo a una conversazione con un adulto in possesso di una laurea.</p>
			<p class="testo" id="p_0047">Nel giro di ventiquattr’ore, sempre più persone si riversarono su Chat<span class="smallcaps">gpt</span>, mettendo a dura prova i suoi server e anche i suoi limiti. Ora a testare il bot erano professionisti, lavoratori del settore tecnologico, del marketing e dei media. Desiderosi di fare spettacolo su Twitter, trasformavano i loro esperimenti in una competizione pubblica per vedere chi riusciva a far produrre a Chat<span class="smallcaps">gpt</span> il testo più divertente, intelligente o strano. Era un po’ come la fanfara intorno a DALL-E 2, ma più in grande. Nei giorni successivi, le persone inondarono Twitter con screenshot di poesie, rap, scene di sitcom ed e-mail generate da Chat<span class="smallcaps">gpt</span>. Più erano eccentrici, meglio era.</p>
			<p class="testo" id="p_0048">Un utente di Twitter, Thomas H. Ptacek, chiese al bot di «scrivere un versetto biblico nello stile della Bibbia di re Giacomo, spiegando come rimuovere un sandwich al burro di arachidi da un videoregistratore».</p>
			<p class="testo" id="p_0049">Questa fu la risposta del bot di Open<span class="smallcaps">ai</span>:</p>
			<blockquote class="citazione" id="blq-3">
			<p class="afilo" id="p_0050"><em class="calibre3">E avvenne che un uomo rimase turbato da un sandwich al burro di arachidi, poiché era stato riposto dentro il suo videoregistratore, e non sapeva come rimuoverlo.</em></p>
			<p class="afilo" id="p_0051"><em class="calibre3">E gridò al Signore, dicendo: «Oh, Signore, come posso rimuovere questo sandwich dal mio videoregistratore, poiché è incastrato e non si muove?».</em></p>
			</blockquote>
			<p class="testo" id="p_0052">«Mi dispiace, ma non riesco a essere cinico con una tecnologia capace di questo», twittò Ptacek. Nel giro di una settimana, più di un milione di persone aveva usato Chat<span class="smallcaps">gpt</span>. Dopo due mesi, il chatbot aveva attratto trenta milioni di utenti registrati, rendendolo uno dei servizi online in più rapida crescita nella storia. All’inizio del 2024, circa cento milioni di persone usavano Chat<span class="smallcaps">gpt</span> ogni settimana. Nessun strumento di <span class="smallcaps">ai</span> autonomo aveva mai raggiunto una popolarità così ampia.</p>
			<p class="testo" id="p_0053">Il 14 marzo 2023, lo stesso giorno in cui Anthropic aveva finalmente lanciato il suo chatbot, chiamato Claude, Open<span class="smallcaps">ai</span> presentò il suo aggiornamento, <span class="smallcaps">gpt</span>-4. Chiunque fosse disposto a pagare 20 dollari al mese poteva accedere a questa nuova tecnologia tramite Chat<span class="smallcaps">gpt</span> Plus, un servizio in abbonamento che, nel 2023, avrebbe generato un fatturato stimato di 200 milioni di dollari. All’interno dell’azienda, alcuni membri del personale ritenevano che <span class="smallcaps">gpt</span>-4 rappresentasse un passo significativo verso l’<span class="smallcaps">agi</span>.</p>
			<p class="testo" id="p_0054">Le macchine non stavano semplicemente imparando correlazioni statistiche nel testo, spiegò Sutskever in un’intervista. «Quel testo è in realtà una proiezione del mondo. […] La rete neurale sta imparando sempre più aspetti del mondo, delle persone, della condizione umana, delle nostre speranze, dei nostri sogni e delle nostre motivazioni, oltre che delle nostre interazioni e delle situazioni in cui ci troviamo.»</p>
			<p class="testo" id="p_0055">«Una volta che abbiamo un sistema in grado di recepire osservazioni sul mondo, di imparare a dar loro un senso – e un modo per farlo è prevedere ciò che accadrà dopo –, direi che siamo molto vicini all’intelligenza», affermò Altman in un’altra intervista.</p>
			<p class="testo" id="p_0056">La stampa specializzata ne rimase affascinata. Il «New York Times» definì Chat<span class="smallcaps">gpt</span> «il miglior chatbot di intelligenza artificiale mai distribuito presso il grande pubblico». I giornalisti che provarono il sistema furono colpiti dal tono amichevole ed entusiasta del bot. Su Twitter, alcuni appassionati di tecnologia si vantavano di come già lo stessero utilizzando per redigere e-mail o altri documenti di lavoro, al fine di aumentare la produttività.</p>
			<p class="testo" id="p_0057">Naturalmente, tutto questo scatenò una nuova ondata di articoli sulla possibilità che Chat<span class="smallcaps">gpt</span> sostituisse gli esseri umani. Altman intraprese un tour mediatico per confrontarsi con l’entusiasmo e le preoccupazioni degli utenti tramite podcast, giornali e altre pubblicazioni. Sì, ammise, probabilmente questa tecnologia avrebbe rimpiazzato alcuni lavori – per esempio i copywriter, gli operatori di customer service e persino gli sviluppatori di software –, ma ciò non significava che avrebbe sostituito completamente il lavoro umano.</p>
			<p class="testo" id="p_0058">«Alcuni lavori spariranno», disse senza mezzi termini in un’intervista. «Ne nasceranno di nuovi, migliori, che oggi è difficile anche solo immaginare.» Questa dichiarazione venne accolta con una quieta rassegnazione da parte della stampa e del pubblico, poiché eventi storici come la rivoluzione industriale avevano già dimostrato che la tecnologia può effettivamente portare cambiamenti dolorosi nel mondo del lavoro. E i sistemi di intelligenza artificiale generativa come Chat<span class="smallcaps">gpt</span> non erano mode passeggere come la criptovaluta. Chat<span class="smallcaps">gpt</span> era utile. Le persone lo usavano già per scrivere temi scolastici, elaborare piani aziendali e condurre ricerche di marketing.</p>
			<p class="testo" id="p_0059">All’interno di Open<span class="smallcaps">ai</span>, i membri del team si consolavano pensando che, alla fine, ne sarebbe valsa la pena, partendo dal presupposto che anche la transizione al lavoro e alle fabbriche automatizzate durante la rivoluzione industriale aveva portato a nuovi posti di lavoro e a standard di vita migliori. Tuttavia, si stava anche formando una divisione sempre più marcata tra i dipendenti concentrati sullo sviluppo del prodotto e quelli focalizzati sulla sicurezza, i quali faticavano a monitorare il traffico in rapido aumento su Chat<span class="smallcaps">gpt</span> alla ricerca di eventuali abusi. Convinto che l’azienda stesse compiendo passi significativi verso l’<span class="smallcaps">agi</span>, Ilya Sutskever iniziò a collaborare più strettamente con il team di sicurezza. Nel frattempo, il team di prodotto di Open<span class="smallcaps">ai</span> continuò a concentrarsi sulla commercializzazione di Chat<span class="smallcaps">gpt</span>, invitando le aziende a pagare per l’accesso alla tecnologia sottostante.</p>
			<p class="testo" id="p_0060">In Google, i dirigenti si resero conto che sempre più persone avrebbero potuto rivolgersi direttamente a Chat<span class="smallcaps">gpt</span> per ottenere informazioni su problemi di salute o consigli su prodotti – alcuni dei termini di ricerca più redditizi per la vendita di annunci – anziché utilizzare il loro motore di ricerca.</p>
			<p class="testo" id="p_0061">In effetti, Google meritava un po’ di concorrenza. Nel corso degli anni, la sua pagina dei risultati era diventata sempre più ingombra di annunci e link sponsorizzati, nel tentativo di spremere il massimo guadagno da ogni singola ricerca, anche a costo di rendere meno piacevole l’esperienza dell’utente. Se riusciva a camuffare qualche annuncio tra i veri risultati delle ricerche, poteva incassare di più.</p>
			<p class="testo" id="p_0062">Tra il 2000 e il 2005, Google aveva segnalato gli annunci in modo più chiaro, distinguendoli con uno sfondo blu e limitandoli a uno o due link in cima alla pagina. Negli anni, però, era diventato sempre più difficile distinguere tra annunci e normali link web. Lo sfondo blu si era sbiadito in verde, poi in giallo, per poi svanire del tutto. Gli annunci occupavano sempre più spazio nella pagina, costringendo gli utenti a scorrere più a lungo per trovare i risultati veri e propri. Per quanto l’esperienza potesse risultare fastidiosa per i consumatori, Google poteva permetterselo, perché gli internauti pensavano di non avere alternative: più del 90 per cento delle ricerche online nel mondo veniva effettuato su Google.</p>
			<p class="testo" id="p_0063">Adesso però, per la prima volta, il dominio più che ventennale di Google veniva messo in discussione. Per anni, la principale fonte di guadagno di Google era stato un sistema che esplorava miliardi di pagine web, le indicizzava e le classificava per trovare le risposte più pertinenti alle query degli utenti e generare una lista di link su cui cliccare. Ma Chat<span class="smallcaps">gpt</span> offriva qualcosa di più allettante per gli utenti che avevano più fretta: una risposta unica basata sulla propria sintesi di tutte quelle informazioni. Niente più scrolling senza fine o ricerche in un labirinto di annunci e link. Chat<span class="smallcaps">gpt</span> faceva tutto questo al posto tuo.</p>
			<p class="testo" id="p_0064">Poniamo, per esempio, che aveste voluto sapere se per preparare una torta alla zucca fosse meglio il latte condensato o il latte evaporato. Da Chat<span class="smallcaps">gpt</span> avreste ricevuto una risposta dettagliata sul fatto che probabilmente era preferibile il latte condensato, perché avrebbe reso la torta più dolce. Google avrebbe restituito una lunga lista di link, annunci, ricette e articoli da aprire e leggere. Le infinite possibilità che un tempo rendevano Google così straordinario erano ormai diventate una perdita di tempo. Nella Silicon Valley, i tecnologi inseguivano da sempre l’esperienza online «senza attriti». Per Google, un’alternativa senza attriti rappresentava un potenziale disastro finanziario.</p>
			<p class="testo" id="p_0065">Pochi giorni dopo il lancio di Chat<span class="smallcaps">gpt</span>, i dirigenti di Google emanarono un «codice rosso» all’interno dell’azienda. Google era stata presa clamorosamente alla sprovvista, soprattutto considerato che, dal 2016, l’amministratore delegato Sundar Pichai amava definirla una società «<span class="smallcaps">ai</span>-first». Com’era possibile, dunque, che una piccola azienda con meno di duecento ricercatori fosse riuscita a sviluppare qualcosa di meglio rispetto a quanto aveva fatto Google con quasi cinquemila esperti? La minaccia era resa ancora più seria dagli stretti legami tra Open<span class="smallcaps">ai</span> e un gigante tecnologico dalle risorse illimitate come Microsoft.</p>
			<p class="testo" id="p_0066">Google aveva già <span class="smallcaps">lamda,</span> il modello linguistico più datato che uno dei suoi ingegneri era persino arrivato a credere senziente. Ma i dirigenti dell’azienda si trovavano in una situazione difficile. Se infatti avessero lanciato un concorrente di Chat<span class="smallcaps">gpt</span> e gli utenti avessero iniziato a usarlo al posto del motore di ricerca, questi non avrebbero più cliccato sugli annunci, sui link sponsorizzati e sugli altri siti web che utilizzavano la rete pubblicitaria di Google, alimentandone i profitti.</p>
			<p class="testo" id="p_0067">Più dell’80 per cento dei 258 miliardi di dollari di entrate di Alphabet nel 2021 proveniva dalla pubblicità, e gran parte di quei ricavi derivava dagli annunci pay-per-click raggiunti tramite il motore di ricerca. Tutti quegli annunci che intasavano i risultati di ricerca erano diventati fondamentali per il suo business. Non poteva semplicemente cambiare lo <em class="calibre3">status quo</em>. «L’obiettivo della ricerca su Google è farti cliccare sui link, idealmente sugli annunci», afferma Sridhar Ramaswamy, che ha gestito il business degli annunci e del commercio di Google dal 2013 al 2018. «Tutto il resto del testo sulla pagina è puro riempitivo.»</p>
			<p class="testo" id="p_0068">Per anni, Google aveva adottato un approccio cauto, quasi timoroso, verso la nuova tecnologia. Non «si muoveva» a meno che non si trattasse di un affare da miliardi di dollari, e di certo non voleva rischiare di compromettere il suo stesso business pubblicitario che fruttava quasi 260 miliardi di dollari l’anno.</p>
			<p class="testo" id="p_0069">«Diventa più difficile man mano che cresci», spiega Ramaswamy. «In Google, la dimensione del team pubblicitario era in genere quattro o cinque volte maggiore di quella del team di ricerca organica. Avviare un prodotto che è l’antitesi del modello di base è davvero difficile da realizzare, nella pratica.»</p>
			<p class="testo" id="p_0070">Ma ora i dirigenti di Google non avevano scelta. In una riunione, registrata e condivisa con il «New York Times», un manager fece notare che aziende più piccole come Open<span class="smallcaps">ai</span> sembravano avere meno scrupoli nel rilasciare strumenti di <span class="smallcaps">ai</span> fortemente innovativi presso il grande pubblico. Google doveva buttarsi e fare lo stesso, altrimenti rischiava di diventare un dinosauro. Messa da parte ogni prudenza, tutto entrò in modalità accelerata.</p>
			<p class="testo" id="p_0071">In preda al panico, i dirigenti dissero al personale che lavorava a prodotti chiave con almeno un miliardo di utenti, come YouTube e Gmail, che avevano solo pochi mesi per incorporare una forma di intelligenza artificiale generativa. Google era stata per anni la macchina di indicizzazione del mondo, elaborando video, immagini e dati, ma ora doveva anche iniziare a <em class="calibre3">crearne</em> di nuovi, grazie all’<span class="smallcaps">ai</span>. Apportare un cambiamento così radicale era come cercare di guidare un vecchio camion sgangherato su una pista da corsa. I dirigenti erano così disperati da convocare i fondatori di Google, Larry Page e Sergey Brin (che si erano dimessi dal ruolo di coamministratori delegati di Alphabet nel 2019), perché li aiutassero a elaborare una risposta a Chat<span class="smallcaps">gpt</span> in una serie di riunioni d’emergenza.</p>
			<p class="testo" id="p_0072">Percependo una profonda insicurezza da parte della leadership di Google, i team di ingegneria si misero all’opera. Pochi mesi dopo il lancio di Chat<span class="smallcaps">gpt</span>, i responsabili di YouTube aggiunsero una funzione che permetteva ai creatori di video sul sito di generare nuove ambientazioni cinematografiche o cambiare abiti utilizzando l’intelligenza artificiale generativa. Ma sembrava andassero un po’ alla cieca. Era dunque arrivato il momento di sfoderare l’arma segreta: <span class="smallcaps">lamda</span>.</p>
			<p class="testo" id="p_0073">Pichai inviò una comunicazione a livello aziendale per chiedere ai dipendenti di testare un nuovo chatbot che prevedevano di lanciare quanto prima e di riscrivere qualsiasi risposta giudicassero inadeguata. Poi, il 6 febbraio 2023, con un post sul blog dell’azienda annunciò che qualcosa di nuovo stava per arrivare. Sotto il titolo: «Un importante passo avanti nel nostro percorso verso l’<span class="smallcaps">ai</span>», scrisse: «Abbiamo lavorato su un servizio sperimentale di <span class="smallcaps">ai</span> conversazionale, alimentato da <span class="smallcaps">lamda</span>, che abbiamo battezzato Bard».</p>
			<p class="testo" id="p_0074">Pur di mantenere la posizione dominante, Microsoft pubblicò un annuncio il giorno successivo. Bing, il suo motore di ricerca di second’ordine (vista la misera quota del 6 per cento nel mercato delle ricerche online), avrebbe presto ricevuto un grande aggiornamento in chiave <span class="smallcaps">ai</span>. L’ultimo modello linguistico <span class="smallcaps">gpt</span> di Open<span class="smallcaps">ai</span> avrebbe potenziato Bing per «sbloccare la gioia della scoperta, provare lo stupore della creazione e sfruttare meglio la conoscenza del mondo». Tradotto: avrebbe fatto ciò che Chat<span class="smallcaps">gpt</span> faceva già, ma con alcune migliorie di cui solo Microsoft era a conoscenza.</p>
			<p class="testo" id="p_0075">Questa corsa senza respiro per il lancio stava lasciando il mondo di stucco, finché alcuni osservatori attenti non rilevarono qualche problema. Google aveva pubblicato esempi di risposte intelligenti da parte di Bard, e Microsoft aveva fatto lo stesso con Bing. Ma quando alcuni giornalisti si presero la briga di verificarle, venne fuori che erano sbagliate. In un video di lancio mostrato da Pichai, Bard aveva commesso un errore storico riguardo al telescopio James Webb, mentre Bing aveva riportato erroneamente dei numeri sugli utili del rivenditore The Gap.</p>
			<p class="testo" id="p_0076">I chatbot non inventavano solo fatti, ma soffrivano anche di una sorta di disturbo dell’umore. Poco dopo l’annuncio di Microsoft, il giornalista del «New York Times» Kevin Roose pubblicò un articolo riguardo a una conversazione inquietante di due ore intrattenuta una notte con Bing in cui il nuovo motore di ricerca di Microsoft, trasformatosi in chatbot, gli aveva dichiarato il suo amore insistendo sul fatto che non fosse «felicemente sposato». Roose scrisse che quello scambio gli aveva dato «la sensazione inquietante che l’<span class="smallcaps">ai</span> avesse superato una certa soglia e che il mondo non sarebbe stato mai più lo stesso».</p>
			<p class="testo" id="p_0077">Per il <span class="smallcaps">ceo</span> di Microsoft, tutto questo clamore e quest’attenzione su Bing si tradussero nell’opportunità irrinunciabile di vantarsi un po’. In un’intervista, Nadella disse che aveva aspettato per anni il momento giusto per sfidare il dominio di Google nella ricerca e ora Bing poteva finalmente riuscirci. «E voglio che la gente sappia che li abbiamo fatti ballare», aggiunse.</p>
			<p class="testo" id="p_0078">Niente di tutto questo aveva senso. Google aveva fatto tutto per prima. I suoi ricercatori avevano inventato il trasformatore e creato il sofisticato modello linguistico <span class="smallcaps">lamda</span> anni prima di <span class="smallcaps">gpt</span>-4. Il suo laboratorio di <span class="smallcaps">ai</span>, DeepMind, si era dato la missione di costruire l’<span class="smallcaps">agi</span> cinque anni prima che Open<span class="smallcaps">ai</span> venisse fondata allo stesso scopo. Eppure, adesso Google si trovava a dover rincorrere.</p>
			<p class="testo" id="p_0079">La sua lentezza burocratica e la paura di danneggiare il suo business e la sua reputazione avevano causato una profonda inerzia. Paradossalmente, ciò aveva protetto il mondo dai rischi che Open<span class="smallcaps">ai</span> aveva appena introdotto, rischi che avrebbero probabilmente coinvolto i gruppi minoritari e assestato un duro colpo a vasti settori dell’occupazione.</p>
			<p class="testo" id="p_0080">Il grande clamore suscitato da Open<span class="smallcaps">ai</span> aveva messo in discussione anche i tredici anni di lavoro in DeepMind, scuotendo profondamente Hassabis. Poche settimane dopo il lancio di Chat<span class="smallcaps">gpt</span>, durante una riunione con tutto il personale, Hassabis disse che DeepMind non doveva diventare «i Bell Labs dell’<span class="smallcaps">ai</span>», un luogo che inventava ogni cosa per poi vedere le proprie idee commercializzate da altri.</p>
			<p class="testo" id="p_0081">Nel frattempo, nessuno si stava più chiedendo dove fosse l’<span class="smallcaps">agi</span>. In compenso, tutti volevano sapere dove fosse l’<span class="smallcaps">ai</span> utile, quella simile all’intelligenza umana. DeepMind era riuscita a creare sistemi di <span class="smallcaps">ai</span> in grado di sconfiggere i campioni umani a Go e ad altri giochi, ma la capacità di Open<span class="smallcaps">ai</span> di creare un sistema che potesse semplicemente scrivere un’e-mail destava in qualche modo maggiore impressione.</p>
			<p class="testo" id="p_0082">La strategia scientifica perseguita da Hassabis iniziava a sembrare troppo isolazionista. Hassabis aveva cercato di costruire l’<span class="smallcaps">agi</span> tramite giochi e simulazioni, e misurava il successo del lavoro della sua azienda in base ai premi ricevuti e al prestigio derivante da pubblicazioni su riviste scientifiche. L’approccio di Open<span class="smallcaps">ai</span> all’<span class="smallcaps">ai</span> era stato guidato da principi ingegneristici e dalla volontà di espandere il più possibile su larga scala la tecnologia esistente. Quello di DeepMind era stato più accademico, concentrato sulla pubblicazione di articoli di ricerca sul sistema AlphaGo e su AlphaFold, un sistema innovativo che mirava a prevedere il ripiegamento delle proteine nel corpo umano.</p>
			<p class="testo" id="p_0083">AlphaFold era nato da un hackathon – un evento di programmazione collaborativa – presso DeepMind nel 2016, per poi trasformarsi in uno dei progetti più promettenti dell’azienda. Hassabis aveva sempre sognato di usare l’<span class="smallcaps">agi</span> per risolvere grandi problemi globali come il cancro, e sembrava che finalmente disponesse di un sistema di <span class="smallcaps">ai</span> capace di fare qualcosa di simile.</p>
			<p class="testo" id="p_0084">Quando gli aminoacidi nelle nostre cellule si ripiegano in specifiche forme tridimensionali, diventando proteine, un ripiegamento errato può provocare malattie. AlphaFold era un programma di <span class="smallcaps">ai</span> capace di prevedere l’aspetto di queste strutture 3D una volta ripiegate, e DeepMind riteneva che ciò potesse aiutare gli scienziati a capire meglio quali reazioni chimiche potessero influenzare quelle proteine, favorendo la scoperta di nuovi farmaci.</p>
			<p class="testo" id="p_0085">Hassabis fece della vittoria in una competizione globale sul ripiegamento delle proteine, chiamata <span class="smallcaps">casp,</span> una priorità per DeepMind nel 2019 e nel 2020. «Dobbiamo raddoppiare gli sforzi e correre il più possibile da questo momento in avanti», disse al suo staff durante una riunione immortalata in un documentario. «Non abbiamo tempo da perdere.»</p>
			<p class="testo" id="p_0086">Mentre Altman misurava il successo con i numeri – che si trattasse di investimenti o degli utenti di un prodotto –, Hassabis puntava ai riconoscimenti. Spesso ripeteva al suo team che DeepMind avrebbe dovuto vincere tra i tre e i cinque Nobel nel corso del decennio successivo.</p>
			<p class="testo" id="p_0087">DeepMind vinse il <span class="smallcaps">casp</span> sia nel 2019 sia nel 2020, e l’anno dopo rese open-source il suo codice per il ripiegamento delle proteine, mettendolo a disposizione della comunità scientifica. Al momento della stesura di questo testo, oltre un milione di ricercatori in tutto il mondo aveva accesso all’AlphaFold Protein Structure Database, secondo quanto dichiarato da DeepMind. Ma la scienza è un processo lento, e benché Hassabis fosse ancora in tempo per vincere un Nobel, all’epoca il suo sistema non aveva ancora portato a una scoperta significativa. Alcuni esperti, inoltre, erano scettici sul fatto che le previsioni fatte da DeepMind sulla forma delle proteine fossero abbastanza accurate da identificare con affidabilità come i composti farmacologici si sarebbero legati alle proteine, o che potessero velocizzare in maniera significativa il processo di scoperta di nuovi farmaci.</p>
			<p class="testo" id="p_0088">In definitiva, a dispetto del prestigio guadagnato, i progetti più importanti di DeepMind avevano avuto un impatto relativamente limitato sul mondo reale. L’azienda aveva insistito nell’addestrare l’<span class="smallcaps">ai</span> in ambienti completamente simulati, dove la fisica e altri dettagli potevano essere progettati e osservati con precisione. Era così che aveva costruito AlphaGo, programmando l’<span class="smallcaps">ai</span> per giocare milioni di partite contro sé stessa in simulazione, e AlphaFold, che utilizzava simulazioni del ripiegamento delle proteine.</p>
			<p class="testo" id="p_0089">L’addestramento basato sui dati del mondo reale – quello che aveva fatto Open<span class="smallcaps">ai</span> estraendo miliardi di parole da internet – era disordinato e rumoroso. Esponeva agli scandali, come Hassabis aveva imparato dal fallimentare progetto sugli ospedali. Ma l’approccio chiuso e controllato di DeepMind rendeva anche più difficile costruire sistemi di <span class="smallcaps">ai</span> che le persone potessero usare concretamente nella vita di tutti i giorni.</p>
			<p class="testo" id="p_0090">Hassabis era così concentrato sui mondi virtuali dei suoi sistemi di <span class="smallcaps">ai</span> e sulla ricerca di riconoscimenti che aveva perso di vista la rivoluzione nei modelli linguistici. Ora doveva seguire le orme di Altman. I dirigenti di Google chiesero a DeepMind di lavorare su una serie di modelli linguistici di grandi dimensioni che risultassero ancora migliori di <span class="smallcaps">lamda</span>. Chiamarono il nuovo sistema Gemini, e DeepMind lo arricchì con le tecniche di pianificazione strategica sviluppate da AlphaGo.</p>
			<p class="testo" id="p_0091">Per accelerare le cose, Pichai prese un’altra decisione drastica: fuse le due divisioni rivali di <span class="smallcaps">ai</span>, DeepMind e Google Brain, e le chiamò Google DeepMind (poi abbreviato in <span class="smallcaps">gdm</span> dai dipendenti). Dopo anni passati a contendersi i migliori ricercatori e a cercare di accaparrarsi maggiore potenza di calcolo, le due unità avevano anche culture completamente diverse. Google Brain era più vicina alla casa madre e lavorava direttamente per migliorare i prodotti di Google; DeepMind invece era indipendente al punto da sembrare distaccata: mentre il suo personale aveva badge che permettevano l’accesso agli altri edifici di Google, il personale di Google non poteva entrare negli edifici di DeepMind, tanto per fare un esempio.</p>
			<p class="testo" id="p_0092">Con sorpresa di molti, Pichai scelse proprio Hassabis per dirigere l’unità combinata. Jeff Dean, l’ingegnere più rispettato di Google, che supervisionava la ricerca sull’<span class="smallcaps">ai</span> nel resto dell’azienda, sembrava il candidato più probabile. Invece, fu l’ex game designer ossessionato dalle simulazioni – colui che aveva cercato di separarsi per anni – a prendere le redini del grande progetto di Google per proteggere la propria leadership nella ricerca sul web. Politicamente, esercitava più potere che mai e, controllando una porzione maggiore di Google, avrebbe potuto anche controllare una parte maggiore di DeepMind.</p>
			<p class="testo" id="p_0093">«Il profilo e l’influenza di Demis in Google sono molto più forti adesso rispetto a qualche anno fa», dice Shane Legg. «Invece di diventare un po’ più indipendenti, siamo diventati parte integrante di Google. È fondamentale per noi e per la nostra missione che Google abbia successo.» E aggiunge: «La cosa non mi era così chiara, qualche anno fa. Pensavo che forse avremmo avuto bisogno di un po’ più di indipendenza. Con il senno di poi, reputo un bene che le cose siano andate in un certo modo».</p>
			<p class="testo" id="p_0094">Nell’annunciare la fusione con Google Brain al personale di DeepMind, Hassabis scrisse in una e-mail che le due unità si stavano fondendo perché l’<span class="smallcaps">agi</span> aveva il potenziale di «guidare una delle più grandi trasformazioni sociali, economiche e scientifiche della storia».</p>
			<p class="testo" id="p_0095">In realtà, la fusione mirava ad aiutare un’azienda in preda al panico a battere un rivale commerciale, proprio mentre la missione di Open<span class="smallcaps">ai</span> di operare a beneficio dell’umanità (senza «pressioni finanziarie») si era trasformata in quella di servire gli interessi di Microsoft. Il cosiddetto «mission drift» (lo slittamento della propria missione), così comune nella Silicon Valley, come già era avvenuto con WhatsApp, stava interessando una tecnologia che avrebbe potuto avere un’influenza ben maggiore sulla società. Open<span class="smallcaps">ai</span> cercò di affrontare il problema nel luglio del 2023, annunciando che Ilya Sutskever avrebbe guidato il suo nuovo team Superalignment. Entro quattro anni, dichiarò l’azienda, i ricercatori di Sutskever avrebbero scoperto come controllare i sistemi di <span class="smallcaps">ai</span> man mano che diventavano più intelligenti degli esseri umani.</p>
			<p class="testo" id="p_0096">Ma Open<span class="smallcaps">ai</span> aveva ancora un problema evidente: stava eludendo la necessità di trasparenza e, più in generale, stava diventando sempre più difficile ascoltare le voci che chiedevano un controllo più attento dei modelli linguistici di grandi dimensioni. Gebru, Mitchell e Bender, il cui celebre articolo di ricerca aveva finalmente attirato l’attenzione sui rischi, stavano ancora cercando di mettere in guardia l’opinione pubblica su come questi modelli, e l’<span class="smallcaps">ai</span> generativa nel suo complesso, potessero perpetuare stereotipi. Purtroppo, governi e responsabili politici stavano prestando maggiore attenzione a un gruppo ben finanziato di voci più rumorose: gli «apocalittici» dell’<span class="smallcaps">ai</span>.</p>
		</section>
	</body>
</html>
