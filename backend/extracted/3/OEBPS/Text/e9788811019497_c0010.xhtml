<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:ibooks="http://apple.com/ibooks/html-extensions" lang="it-IT" xml:lang="it-IT" class="calibre">
  <head>
    <title>FILE 10 – Supremacy – Capitolo</title>
    <meta content="urn:uuid:35484d83-cd47-4b21-bd76-ea9d55abc8bb" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body epub:type="bodymatter" class="calibre2">
		<section epub:type="chapter" role="doc-chapter" class="calibre">
			<h2 class="capitolo" id="h2-0001"><span class="smallcaps1">7. giochi e giochetti</span></h2>
			<p class="testo" id="p_0001">A pochi passi dalla stazione di King’s Cross, a Londra, dove i turisti affollavano il binario magico che porta a Hogwarts in <em class="calibre3">Harry Potter</em>, un altro tipo di magia stava prendendo vita all’interno di una serie di scintillanti grattacieli che si stagliavano nel cielo grigio con facciate di vetro e rivestimenti metallici. Tra l’uno e l’altro si snodava una piacevole passeggiata animata da parecchi frequentatori, alcuni dei quali erano ingegneri e scienziati di DeepMind intenti a recuperare i badge per poi varcare le porte di vetro di un edificio che ufficialmente apparteneva a Google, ma che riservava due interi piani al loro laboratorio segreto di <span class="smallcaps">ai</span>.</p>
			<p class="testo" id="p_0002">Nonostante tutti i vantaggi derivanti dall’essere parte di Google, incluse le capsule per il riposo, le stanze per massaggi e la palestra interna, i fondatori di DeepMind stavano ancora cercando di sottrarsi alla presa della loro società madre, Alphabet. Erano passati più di due anni dall’acquisizione, e i dirigenti del colosso tecnologico stavano ponendo Demis Hassabis, Mustafa Suleyman e Shane Legg davanti a una nuova prospettiva: invece che un’«unità autonoma», DeepMind poteva diventare una «società di Alphabet» con bilanci propri.</p>
			<p class="testo" id="p_0003">Lontani dall’implacabile mentalità improntata alla crescita che dominava la Silicon Valley, i fondatori accolsero con fiducia la proposta di Google. Intenzionato a dimostrare che DeepMind poteva camminare con le proprie gambe come impresa, Suleyman si diede da fare per comprovare il valore dei suoi sistemi di <span class="smallcaps">ai</span> nel mondo reale. Concentrò una rinnovata attenzione su una divisione che aveva avviato in precedenza, Applied, i cui ricercatori utilizzavano tecniche di apprendimento per rinforzo per affrontare problemi in settori come la sanità, l’energia e la robotica, con l’obiettivo di trasformarli in opportunità d’impresa. Un altro team di circa venti ricercatori, autodefinitosi DeepMind for Google, lavorava su progetti che contribuivano direttamente alle attività della casa madre, per esempio rendendo più efficienti i suggerimenti di YouTube o affinando gli algoritmi per la pubblicità. Stando a una fonte informata sugli accordi, Google accettò di riconoscere a DeepMind il 50 per cento dei ricavi derivanti dal valore aggiunto da queste funzionalità. Circa due terzi dei progetti vennero giudicati utili.</p>
			<p class="testo" id="p_0004">Questo lasciava a centinaia di altri ricercatori di DeepMind la libertà di continuare a studiare nuovi modi per sviluppare l’<span class="smallcaps">agi</span>. Ogni due o tre settimane, i fondatori si ritrovavano in un pub per discutere del lavoro, e le loro conversazioni finivano sempre per toccare punti di tensione ormai familiari. Suleyman voleva risolvere problemi concreti, ma temeva anche che i loro sforzi potessero finire per dar vita involontariamente a un sistema superintelligente capace di ritorcersi contro l’umanità. Cosa sarebbe successo se l’<span class="smallcaps">ai</span> fosse sfuggita dal suo contenitore e avesse cominciato a manipolare la gente? In ufficio, metteva in guardia colleghi e dirigenti circa l’impatto dell’<span class="smallcaps">agi</span> sull’economia, sostenendo che avrebbe potuto causare uno spostamento improvviso di milioni di posti di lavoro e un crollo dei redditi. E se questo avesse provocato una rivolta? «La gente marcerà su King’s Cross con i forconi, se non ci preoccupiamo di creare un sistema equo», ripeteva.</p>
			<p class="testo" id="p_0005">Hassabis si sforzava di trovare soluzioni, ma a volte queste sembravano un po’ eccentriche. Per esempio, suggerì che, visto che la loro <span class="smallcaps">ai</span> diventava più avanzata e potenzialmente pericolosa, DeepMind avrebbe potuto assumere Terence Tao, docente alla University of California di Los Angeles e da molti considerato uno dei più grandi matematici viventi. Ex bambino prodigio entrato all’università all’età di nove anni, secondo la rivista «New Scientist» Tao era una specie di «Mr. Aggiustatutto per ricercatori frustrati».</p>
			<p class="testo" id="p_0006">In alcune interviste, Tao aveva dichiarato che in fondo l’<span class="smallcaps">ai</span> non era che matematica avanzata e, con tutta probabilità, il mondo non avrebbe mai avuto una vera <span class="smallcaps">ai</span>. Vedeva questa tecnologia in modo meccanicistico e quasi in bianco e nero, proprio come Hassabis. Se l’<span class="smallcaps">ai</span> fosse sfuggita al controllo, la matematica avrebbe potuto contenerla. Hassabis non era il solo a pensarla così. Sul forum LessWrong di Yudkowsky, gli utenti avevano avviato un lungo progetto per elaborare strategie tramite cui convincere persone come Tao e altri matematici di spicco a lavorare sull’allineamento dell’<span class="smallcaps">ai</span>, ovvero il processo necessario a rendere l’<span class="smallcaps">ai</span> più conforme ai valori umani, così da impedirle di andare fuori controllo. La loro ipotesi era che per attirare luminari di quel calibro servissero cifre comprese tra i 5 e i 10 milioni di dollari.</p>
			<p class="testo" id="p_0007">Hassabis immaginava che, una volta avvicinatosi all’<span class="smallcaps">agi</span>, avrebbe smesso di spingere al massimo le prestazioni dei suoi modelli di <span class="smallcaps">ai</span> per poi invitare alcune delle menti più brillanti al mondo ad analizzare questi ultimi nei minimi dettagli, così da individuare le migliori strategie matematiche per tenerli sotto controllo. «Forse dovremmo cominciare a lanciare un appello, una sorta di “Avengers Assemble” di matematici e scienziati», dice ancora oggi Hassabis.</p>
			<p class="testo" id="p_0008">Suleyman, tuttavia, non condivideva l’approccio del cofondatore, ritenendolo troppo focalizzato sui numeri e sulla teoria. Credeva che, per essere davvero sicura, l’<span class="smallcaps">ai</span> andasse gestita dalle persone, non solo da formule matematiche. Mentre lui e Hassabis discutevano su quale fosse la migliore strategia per contenere l’<span class="smallcaps">ai</span>, arrivò un nuovo aggiornamento da parte della leadership di Google riguardo al piano per trasformare DeepMind in una «società di Alphabet». L’idea non poteva funzionare, dissero loro i dirigenti. Creare una nuova realtà non era così semplice perché, man mano che l’<span class="smallcaps">ai</span> diventava più preziosa per il business di Google, l’azienda madre aveva sempre più bisogno di DeepMind.</p>
			<p class="testo" id="p_0009">Ai fondatori, questo ennesimo cambio di rotta trasmise una sensazione di déjà-vu. Ma la dirigenza li rassicurò: non c’era motivo di preoccuparsi, perché avrebbero comunque trovato un compromesso. Ora si proponeva una terza opzione: DeepMind avrebbe potuto procedere a una sorta di scorporo parziale e avere il proprio consiglio di amministrazione incaricato di guidare lo sviluppo di un’<span class="smallcaps">ai</span> superintelligente, mentre Alphabet avrebbe mantenuto una certa quota dell’azienda. Per dimostrare che intendevano fare sul serio, i vertici di Alphabet misero tutto nero su bianco. La dirigenza firmò un protocollo d’intesa in cui s’impegnava a immettere nelle casse di DeepMind 15 miliardi di dollari in dieci anni, per consentirle di operare in maniera indipendente. Hassabis raccontò a più persone all’interno di DeepMind che la proposta era stata firmata da Sundar Pichai, il dirigente di Google che, di lì a pochi anni, sarebbe diventato <span class="smallcaps">ceo</span> di Alphabet. Questo a dimostrazione di come, finalmente, Google sembrasse intenzionata a tenere fede alle promesse.</p>
			<p class="testo" id="p_0010">Il protocollo d’intesa è un documento che delinea i termini e le condizioni di un possibile accordo commerciale. Di solito funge da punto di partenza per ulteriori negoziazioni e non è legalmente vincolante. Tuttavia, un accordo scritto ha un peso maggiore di uno verbale, e i fondatori di DeepMind erano convinti che, questa volta, l’impegno di Google a concedere loro una certa indipendenza fosse concreto. Decisero perciò di dedicarsi completamente alla riorganizzazione di DeepMind in modo da darle una struttura che, al pari di Open<span class="smallcaps">ai</span>, la rendesse più simile a un ente benefico che a un’impresa tradizionale.</p>
			<p class="testo" id="p_0011">Hassabis e Suleyman assunsero banchieri d’investimento per definire i meccanismi finanziari dello scorporo e si affidarono a due studi legali di Londra per redigere i piani giuridici necessari a ristrutturarsi come organizzazione indipendente. Inoltre, chiesero consulenza a un importante avvocato aziendale britannico che aveva gestito operazioni per colossi come Shell, Vodafone e il gigante minerario <span class="smallcaps">bhp</span> Billiton.</p>
			<p class="testo" id="p_0012">Pianificarono anche una nuova struttura di leadership: Hassabis, Legg e Suleyman avrebbero fatto parte di un consiglio operativo insieme a Larry Page, <span class="smallcaps">ceo</span> di Alphabet, al suo cofondatore, Sergey Brin, al responsabile dei prodotti di Google, Sundar Pichai, e a tre direttori commerciali indipendenti. Le decisioni sarebbero state prese a maggioranza. Elemento fondamentale del piano era l’istituzione di un consiglio fiduciario completamente indipendente, composto da sei garanti incaricati di vigilare sul rispetto della missione sociale ed etica di DeepMind. I nomi di questi garanti e le loro decisioni sarebbero stati pubblici, in modo da garantire la massima trasparenza. Avendo il compito di supervisionare una delle tecnologie più avanzate e potenzialmente pericolose al mondo, questi sei garanti dovevano essere persone di altissima levatura e degne della massima fiducia. Così, DeepMind puntò in alto, tanto da interpellare l’ex presidente Barack Obama, insieme a un ex vicepresidente degli Stati Uniti e a un ex direttore della <span class="smallcaps">cia</span>. Secondo una fonte vicina al progetto, molte tra le personalità contattate accettarono l’incarico.</p>
			<p class="testo" id="p_0013">Dopo una consultazione con esperti legali, DeepMind decise di non intraprendere la stessa strada seguita inizialmente da Sam Altman, ovvero trasformarsi in un’organizzazione senza scopo di lucro. I fondatori concepirono invece una struttura legale completamente nuova, che chiamarono «Global Interest Company» o <span class="smallcaps">gic</span>. L’idea era che DeepMind diventasse un’organizzazione simile a una divisione delle Nazioni Unite, custode trasparente e responsabile dell’<span class="smallcaps">ai</span> per il bene dell’umanità. Avrebbe concesso ad Alphabet una licenza esclusiva, in modo tale che eventuali scoperte nel campo dell’<span class="smallcaps">ai</span> utili al business della ricerca di Google confluissero nel sistema del colosso tecnologico. Tuttavia, DeepMind avrebbe destinato la maggior parte delle risorse, dei talenti e delle ricerche allo scopo di promuovere la sua missione sociale, lavorando nel campo delle scoperte farmacologiche e dei progressi nel settore sanitario, o nella lotta al cambiamento climatico. All’interno dell’azienda, il progetto veniva chiamato semplicemente <span class="smallcaps">gic</span>.</p>
			<p class="testo" id="p_0014">Eppure, mentre cercava di affrancarsi da Google, DeepMind continuava a rafforzarne il business. Proprio nel periodo in cui prometteva di aiutare DeepMind a separarsi dalla casa madre, Larry Page guardava alla Cina come a una nuova opportunità di espansione. Con il mercato ormai maturo negli Stati Uniti e negli altri paesi occidentali, la Cina rappresentava per Google un’occasione unica. Era il paese più popoloso al mondo, con oltre 650 milioni di utenti internet, quasi il doppio dell’intera popolazione degli Stati Uniti. E considerando che solo la metà dei potenziali utenti era effettivamente online, la Cina rappresentava un mercato vasto e ancora poco sfruttato. La classe media cinese era in crescita, i consumi in aumento e il <span class="smallcaps">pil</span> del paese si attestava intorno agli 11.000 miliardi di dollari, rendendola la seconda economia più grande del pianeta. Era una potenziale miniera d’oro per qualsiasi azienda del web.</p>
			<p class="testo" id="p_0015">Google però non poteva entrare in Cina a suo piacimento. Nel 2010, infatti, aveva lasciato il paese accusando Pechino di aver hackerato la sua proprietà intellettuale e gli account Gmail di attivisti cinesi per i diritti umani. Il governo cinese aveva imposto a Google di censurare le ricerche su argomenti come piazza Tienanmen e altri temi controversi agli occhi del Partito comunista cinese. Poi aveva bloccato l’accesso a Facebook e Twitter, creando quello che sarebbe stato ribattezzato il Grande Firewall. I dirigenti di Google ostentavano comunque una certa sicurezza, ritenendo che si trattasse di una situazione temporanea, perché presto i cittadini cinesi avrebbero preteso i servizi sofisticati e potenti offerti dai giganti web della Silicon Valley.</p>
			<p class="testo" id="p_0016">«La domanda è se, in un arco di tempo sufficientemente lungo, questo tipo di approccio dittatoriale finirà», aveva dichiarato nel 2012 Eric Schmidt, all’epoca presidente di Google, alla rivista «Foreign Policy». «Io credo assolutamente di sì.»</p>
			<p class="testo" id="p_0017">Schmidt si sbagliava. Invece di stagnare, il settore internet cinese ebbe una vera e propria esplosione. Aziende come Meituan, Baidu e Alibaba divennero colossi, mentre ingegneri cinesi che avevano lavorato e avviato aziende nella Silicon Valley tornavano in patria per costruire i propri giganti tech. Un gran numero di ingegneri provenienti da Microsoft Research Asia assumeva ruoli di leadership in imprese come Alibaba e Tencent. Cinque anni dopo aver lasciato la Cina, Google vedeva il mercato del paese diventare sempre più redditizio ma non aveva una strategia chiara per rientrarvi. Le regole sulla censura, in Cina, non erano cambiate. Ma Google era ansiosa di accedere sia al crescente mercato dei consumatori sia ad alcune delle idee ingegneristiche innovative che stavano fiorendo nel paese. «Dobbiamo capire cosa sta succedendo lì per trarne ispirazione», dichiarò all’epoca Ben Gomes, responsabile della ricerca di Google, alla piattaforma The Intercept. «La Cina ci insegnerà cose che non sappiamo.»</p>
			<p class="testo" id="p_0018">In quel periodo, si verificò un importante cambiamento di leadership ai vertici di Google. Nel 2015, Page e Brin fecero un passo indietro rispetto all’azienda che avevano fondato per perseguire una serie di interessi personali al di fuori di Google, dalla filantropia alle auto volanti fino all’esplorazione spaziale, e nominarono Pichai nuovo <span class="smallcaps">ceo</span>. Pichai era il rispettato responsabile dei prodotti che i fondatori di DeepMind avevano intenzione di inserire nel nuovo consiglio operativo, una volta effettuato lo scorporo dall’azienda madre. A differenza di Page, però, non aveva molto tempo (e neppure molto interesse, probabilmente) per concentrarsi sul modo migliore di scorporare una delle acquisizioni più preziose di Google. Lui e Schmidt erano occupati a scovare un qualche sistema creativo per rientrare in Cina. In un certo momento di quell’anno, sembrava che potessero ottenere l’approvazione di Pechino a riportare il loro app store nel paese, ma alla fine non se ne fece nulla.</p>
			<p class="testo" id="p_0019">Poi arrivò un’opportunità di pubbliche relazioni che avrebbe messo DeepMind sotto i riflettori. DeepMind aveva addestrato i suoi modelli di <span class="smallcaps">ai</span> con i giochi, e il suo ultimo programma, AlphaGo, era in grado di cimentarsi in partite di Go, un gioco da tavola per due giocatori. Nato in Cina più di due millenni e mezzo anni fa, il Go potrebbe sembrare piuttosto semplice. Si gioca su una griglia di 19×19 con alcune manciate di pietre bianche e nere. I giocatori pongono a turno una pietra su un’intersezione della griglia. L’obiettivo è conquistare territorio sulla tavola circondando i punti vuoti con le proprie pietre e catturando quelle dell’avversario. In realtà, è uno dei giochi più complessi sotto il profilo strategico, dato che il numero di posizioni possibili sulla tavola è dell’ordine di 10<sup class="calibre8">170</sup>, di gran lunga maggiore rispetto alla stima degli atomi che compongono l’universo osservabile, più vicina a 10<sup class="calibre8">80</sup>.</p>
			<p class="testo" id="p_0020">Page aveva giocato a Go con il cofondatore di Google Sergey Brin all’epoca in cui stavano avviando l’azienda a Stanford, anni prima, e quando menzionò il suo interesse per il gioco a Hassabis, qualche settimana dopo l’acquisizione, quest’ultimo rispose che il suo team avrebbe potuto costruire un sistema <span class="smallcaps">ai</span> in grado di battere un campione umano.</p>
			<p class="testo" id="p_0021">Hassabis non mirava solo a impressionare il suo nuovo capo. Oltre che uno scienziato di successo, era anche un genio del marketing. Sapeva che se AlphaGo fosse riuscito a battere un campione mondiale di Go, come il computer Deep Blue di <span class="smallcaps">ibm</span> aveva battuto Garry Kasparov a scacchi nel 1997, ciò avrebbe segnato un nuovo, entusiasmante traguardo per l’<span class="smallcaps">ai</span> e consolidato la credibilità di DeepMind come leader nel campo. Puntati gli occhi sul sudcoreano Lee Sedol, nel marzo del 2016 DeepMind lo sfidò a un incontro di cinque partite a Seul.</p>
			<p class="testo" id="p_0022">Più di duecento milioni di persone si collegarono online e in <span class="smallcaps">tv</span> per guardare Lee giocare cinque partite di Go contro il computer di DeepMind. Il ricercatore di DeepMind che gestiva il programma smise di bere ore prima dell’evento per non dover chiedere una pausa per andare in bagno. Durante l’incontro, Hassabis camminava avanti e indietro tra la sala di controllo di AlphaGo e un’area privata di visione. Non riusciva a mangiare. Il suo team aveva insegnato alla rete neurale di AlphaGo trenta milioni di mosse possibili.</p>
			<p class="testo" id="p_0023">Per vincere a Go, i contendenti devono catturare le pietre dell’avversario circondandole completamente, e per farlo occorre una strategia su più livelli: bisogna bilanciare la necessità di attaccare e difendere, valutare obiettivi a lungo termine contro obiettivi a breve termine, nonché prevedere le sequenze di mosse dell’avversario. Questo impone di scegliere con attenzione su quali linee della griglia posizionare le proprie pietre. Le linee più vicine al bordo vengono utilizzate di rado perché non offrono molte possibilità di circondare un avversario per conquistare territorio, perciò la mossa di AlphaGo al trentasettesimo turno della seconda partita contro Lee fu giudicata strana: posizionò infatti una pietra sulla quinta linea della tavola partendo da destra. In genere, le mosse lungo la quinta linea sono considerate meno efficaci perché concedono all’avversario un vantaggio territoriale sulla quarta linea. Insomma, giocare sulla quinta linea era visto come uno spreco. La mossa fu così inattesa e inconsueta che Lee impiegò quindici minuti per riflettere sulla contromossa, arrivando persino a uscire dalla stanza.</p>
			<p class="testo" id="p_0024">«È una mossa sorprendente», disse un commentatore, convinto che l’operatore umano di AlphaGo avesse erroneamente cliccato sulla casella sbagliata della tavola.</p>
			<p class="testo" id="p_0025">Circa cento mosse dopo, però, la strana strategia iniziò ad assumere un senso. Due delle pietre nere di AlphaGo nella parte inferiore sinistra della tavola finirono per sconfinare nella parte opposta, connettendosi perfettamente con la pietra posizionata sulla quinta linea. Dopo altre quattro ore di gioco, Lee si ritirò. Lui e i commentatori avrebbero continuato a definire «fantastica» la trentasettesima mossa. Hassabis, dal canto suo, disse che mostrava bagliori di creatività nell’<span class="smallcaps">ai</span>. In totale, AlphaGo vinse quattro delle cinque partite contro Lee.</p>
			<p class="testo" id="p_0026">Questo momento storico per l’<span class="smallcaps">ai</span> comportò un’esplosione dell’attenzione mediatica nei confronti di DeepMind, con tanto di premi a un documentario Netflix su AlphaGo. Hassabis era pronto a chiudere in bellezza e a ritirare il programma per passare al progetto successivo.</p>
			<p class="testo" id="p_0027">Ma la dirigenza di Google intravide un’opportunità relativamente al suo disegno di mostrare la potenza tecnologica di Google a Pechino e aprirsi un varco per tornare in Cina. AlphaGo avrebbe potuto rappresentare una nuova forma di diplomazia del ping pong con la Cina, come lo scambio di giocatori di tennistavolo tra Stati Uniti e Cina nel 1971 che aveva contribuito a scongelare le relazioni diplomatiche in piena guerra fredda. Se la partita in Corea del Sud era stata una trovata pubblicitaria per DeepMind, un secondo incontro organizzato in Cina doveva andare a vantaggio di Google.</p>
			<p class="testo" id="p_0028">Questa voleva che DeepMind facesse confrontare AlphaGo con un giocatore ancora più performante, ovvero il diciannovenne Ke Jie, che allora occupava la posizione numero uno nel ranking mondiale di Go e viveva in Cina. Ke Jie era un giocatore completamente diverso da Lee Sedol: sempre pronto a provocare gli avversari, aspettava solo l’occasione di mettersi in mostra. Ma Google non era meno arrogante nella sua pretesa di potersi guadagnare il ritorno in Cina facendo sfoggio della sua tecnologia.</p>
			<p class="testo" id="p_0029">Hassabis era preoccupato dalla situazione. Se AlphaGo avesse vinto, avrebbe dato l’impressione che la malvagia <span class="smallcaps">ai</span> fosse ormai pronta a primeggiare ripetutamente sugli esseri umani. Se avesse perso, tutta l’euforia generatasi a Seul sarebbe svanita. Sembrava una causa persa in ogni caso.</p>
			<p class="testo" id="p_0030">Sapendo però che Google desiderava disperatamente rimettere piede in Cina, Hassabis fece leva sulla sua astuzia strategica per trovare un compromesso con Pichai: avrebbero organizzato un altro incontro, ma questa volta usando una nuova versione di AlphaGo chiamata AlphaGo Master. Invece di funzionare su centinaia di computer diversi, avrebbe operato tramite una sola macchina alimentata da un chip Google. In questo modo, avrebbero potuto presentare l’incontro come un test del loro nuovo sistema <span class="smallcaps">ai,</span> piuttosto che come un secondo tentativo di annientare i campioni umani. Se il sistema avesse perso, avrebbero potuto salvare la faccia dicendo che non era comparabile all’AlphaGo originale; se avesse vinto, avrebbero potuto annunciare un nuovo sistema più potente. Google avrebbe potuto promuovere la sua nuova piattaforma di apprendimento automatico chiamata TensorFlow e conquistare qualche grosso cliente in Cina per finanziare la sua piccola ma crescente attività di cloud computing. Pichai fu d’accordo.</p>
			<p class="testo" id="p_0031">L’evento si svolse a Wuzhen, in Cina, nel maggio del 2017, e se i dirigenti di Google avevano passato l’anno precedente a fare pressioni presso i funzionari governativi perché venisse trasmesso via <span class="smallcaps">tv</span> e internet in tutta la Cina, alla fine l’incontro rimase oscurato per la maggior parte del paese. Il nuovo AlphaGo vinse tutte e tre le partite in programma contro Ke Jie, ma in Cina quasi nessuno venne a saperlo.</p>
			<p class="testo" id="p_0032">La leadership di Google cercò di mantenere un atteggiamento positivo. Durante un’intervista sul palco dell’evento, Schmidt colse l’occasione per lodare TensorFlow, affermando che le principali aziende internet cinesi come Alibaba, Baidu e Tencent avrebbero dovuto provarlo. «Ne trarrebbero tutte vantaggio», disse. Dietro le quinte, Google era così ansiosa di rientrare nel mercato cinese da rivedere persino alcune delle precedenti resistenze alle richieste di Pechino riguardo alla censura e alla sorveglianza. Secondo una nota trapelata a The Intercept nel 2018, i dirigenti di Google avevano ordinato ai loro ingegneri di lavorare a un prototipo di motore di ricerca per la Cina (nome in codice: Dragonfly) che bandisse determinati termini dalla ricerca e collegasse le ricerche degli utenti ai loro numeri di telefono. L’azienda stava facendo un passo indietro rispetto ai suoi principi per aiutare un regime oppressivo a sorvegliare i propri cittadini.</p>
			<p class="testo" id="p_0033">Ma la fame di nuovi mercati aveva reso Google completamente incapace di vedere quanto fosse insensato il tentativo di rientrare in Cina. Le aziende tecnologiche cinesi stavano facendo enormi progressi nella ricerca sull’<span class="smallcaps">ai</span> e non avevano certo bisogno di TensorFlow o di Google. L’anno prima, il colosso internet Baidu aveva persino assunto Andrew Ng, il professore di Stanford che aveva avviato Google Brain. Il governo cinese aveva capito che i suoi cittadini e il suo fiorente settore tecnologico potevano vivere benissimo senza i servizi del gigante della ricerca online.</p>
			<p class="testo" id="p_0034">Due mesi dopo la partita con Ke Jie, Pechino rivelò il suo ultimo obiettivo a lungo termine per il paese, ovvero quello di diventare leader mondiale nel settore dell’<span class="smallcaps">ai</span>, superando gli Stati Uniti già entro il 2030. Il governo avrebbe finanziato una serie di start-up di <span class="smallcaps">ai</span> e di progetti futuristici che, presi nel complesso, somigliavano alla sua versione del programma Apollo. Per raggiungere l’obiettivo, non si citarono possibili collaborazioni con Google o con altre aziende tecnologiche della Silicon Valley.</p>
			<p class="testo" id="p_0035">A quel punto, i dirigenti di Google si resero conto che i loro sogni di entrare nel gigantesco mercato internet cinese aumentando i profitti in maniera esponenziale erano irrealistici. Per l’azienda, la delusione fu enorme. Lo stesso Hassabis, con il successo di AlphaGo, si era messo in una posizione scomoda. Creando un’ondata di pubblicità positiva per DeepMind e mostrando la sua <span class="smallcaps">ai</span> avanzata, aveva reso il laboratorio ancora più utile agli occhi di Alphabet. Tuttavia, intendeva ancora portare avanti il progetto di scorporo elaborato principalmente con Suleyman.</p>
			<p class="testo" id="p_0036">Era così fiducioso nella riuscita del suo piano che, poche settimane dopo la partita in Cina nel maggio 2017, portò la maggior parte degli oltre trecento membri del team di DeepMind in una zona rurale della Scozia per un ritiro durante il quale, insieme a Suleyman, espose loro il progetto. Nell’hotel e centro congressi preso in affitto, i due annunciarono l’intenzione di trasformare l’azienda in una società di interesse globale a sé stante. Rivelarono quindi che DeepMind sarebbe infine diventata un’organizzazione non profit (con Google come stakeholder) simile ad altre organizzazioni di interesse pubblico come le Nazioni Unite e la Gates Foundation. L’obiettivo era di diventare un’organizzazione orientata al bene comune, spiegarono, e di sovrintendere allo sviluppo dell’<span class="smallcaps">ai</span> in modo tale che avesse esiti positivi per l’intero pianeta. Invece di essere un bene finanziario di Google, DeepMind avrebbe stipulato con l’azienda un accordo di licenza esclusivo, continuando però a perseguire la propria missione.</p>
			<p class="testo" id="p_0037">Il team reagì con entusiasmo. Come ricercatore nel campo dell’<span class="smallcaps">ai</span>, ecco che all’improvviso avevi il meglio di entrambi i mondi. Lavoravi per un’azienda tecnologica che offriva un ottimo stipendio e svariati benefit, e intanto pensavi a «risolvere l’intelligenza e poi tutto il resto». I fondatori spiegarono che lo scorporo sarebbe stato finalizzato entro settembre di quell’anno, il 2017.</p>
			<p class="testo" id="p_0038">Hassabis e Suleyman chiesero ai dipendenti di mantenere segreto il progetto <span class="smallcaps">gic</span>, e la richiesta non era poi così insolita visto che la maggior parte dei membri di DeepMind aveva firmato rigidi accordi di non divulgazione che impedivano loro di parlare dei piani e delle tecnologie dell’azienda. In questo caso, però, si chiedeva loro di non parlare dello scorporo nemmeno all’interno dell’azienda. Alcuni ricercatori ricevettero l’istruzione di usare parole in codice, per esempio riferendosi al progetto come <em class="calibre3">watermelon</em> («anguria»), e utilizzando app di messaggistica criptate come Signal. Alcuni leader di DeepMind consigliarono persino di non discuterne su dispositivi aziendali o app come Gmail.</p>
			<p class="testo" id="p_0039">I ricercatori di DeepMind ritenevano che la segretezza fosse dovuta alle preoccupazioni riguardo a ciò che Google avrebbe potuto fare con l’<span class="smallcaps">agi</span>. Qualche mese dopo, quando Google venne coinvolta in un progetto militare, quei sospetti acquisirono una certa credibilità. Nel 2017, il dipartimento della Difesa degli Stati Uniti aveva lanciato il cosiddetto Project Maven, con l’obiettivo di una maggiore integrazione dell’<span class="smallcaps">ai</span> e dell’apprendimento automatico nelle sue strategie di difesa, fornendo per esempio i suoi droni di <em class="calibre3">computer vision</em> per affinare la precisione nell’acquisizione dei bersagli. Quando si unì al progetto, Google si aspettava di guadagnare dalla partnership 250 milioni di dollari l’anno, secondo alcune e-mail fatte trapelare a The Intercept. Tuttavia, di fronte alle massicce proteste interne, Google fu costretta a chiudere il progetto e a rifiutare il rinnovo del contratto con il dipartimento della Difesa, confermando comunque i timori di DeepMind riguardo a un possibile uso improprio della sua <span class="smallcaps">ai</span>.</p>
			<p class="testo" id="p_0040">Le operazioni di scorporo però procedevano a rilento. Hassabis e altri dirigenti rassicuravano il personale che alla separazione mancavano sei mesi, per poi ribadire la promessa a distanza di qualche mese. Dopo un po’, gli ingegneri cominciarono a chiedersi se il piano si sarebbe mai concretizzato. E non aiutava il fatto che i contorni del progetto sembrassero piuttosto vaghi. Suleyman, per esempio, diceva al team di voler rendere legalmente vincolanti le nuove regole sui rapporti tra DeepMind e Google, ma né lui né gli altri dirigenti erano in grado di precisare come ciò sarebbe stato possibile nella pratica. Nell’ipotesi che in futuro Google usasse l’<span class="smallcaps">ai</span> di DeepMind per scopi militari, DeepMind avrebbe potuto intentare una causa? Non era chiaro. Il team di DeepMind venne incaricato di redigere linee guida che vietassero l’utilizzo della sua <span class="smallcaps">ai</span> per violazioni dei diritti umani e «danni di ampia portata». Ma cosa significava nel dettaglio? Nessuno era in grado di dirlo.</p>
			<p class="testo" id="p_0041">Parte del problema stava nel fatto che DeepMind non aveva assunto abbastanza persone per poter rispondere a queste domande. Aveva investito nell’assunzione di scienziati e programmatori per migliorare le prestazioni dei suoi modelli di <span class="smallcaps">ai</span>, ma solo un numero ristretto di dipendenti si occupava di questioni etiche legate alla progettazione di questi modelli. Nel 2020, per esempio, la maggior parte dei circa mille dipendenti di DeepMind era composta da ricercatori scientifici e ingegneri; meno di una dozzina di persone si occupava di etica e solo due di queste conducevano studi accademici sul tema. Quasi nessuno stava analizzando i modi in cui i sistemi di <span class="smallcaps">ai</span> potevano generare bias, razzismo o danneggiare i diritti umani. «Non puoi dire di avere un team dedicato all’etica quando in realtà si parla di due persone», disse all’epoca un membro di DeepMind.</p>
			<p class="testo" id="p_0042">In ambito <span class="smallcaps">ai</span>, «etica» e «sicurezza» possono riferirsi a obiettivi di ricerca diversi, e negli ultimi anni i loro sostenitori si sono spesso trovati in disaccordo. I ricercatori che si occupano di sicurezza nell’<span class="smallcaps">ai</span> tendono a muoversi negli stessi ambienti di Yudkowsky e Jaan Tallinn e puntano ad assicurarsi che un sistema di <span class="smallcaps">agi</span> superintelligente non arrechi danni catastrofici all’umanità, in futuro, utilizzando per esempio la scoperta di nuovi farmaci per creare armi chimiche e sterminare la popolazione, o diffondendo disinformazione su internet fino a destabilizzare completamente la società.</p>
			<p class="testo" id="p_0043">La ricerca etica, invece, si concentra maggiormente sulla definizione di come i sistemi di <span class="smallcaps">ai</span> vengano progettati e utilizzati oggi, esaminando i modi in cui la tecnologia potrebbe già adesso arrecare danni alle persone. Questo perché l’algoritmo di Google Photos che ha etichettato i soggetti di colore come «gorilla» non è un caso isolato. Quello dei bias è un problema enorme in ambito <span class="smallcaps">ai</span>. Gli algoritmi utilizzati nel sistema giudiziario statunitense hanno etichettato, in maniera non corretta e sproporzionata, gli individui di colore come più propensi a reiterare i reati. Inoltre, alcuni sviluppatori hanno utilizzato gli strumenti di <span class="smallcaps">ai</span> per scopi eticamente riprovevoli, come i ricercatori di Stanford che hanno rilasciato un sistema di riconoscimento facciale che affermava di distinguere l’orientamento sessuale delle persone.</p>
			<p class="testo" id="p_0044">Gli sviluppatori dei tre sistemi citati avrebbero dovuto riflettere di più sulla progettazione dei loro modelli, tenendo conto di equità, trasparenza e diritti umani. Tuttavia, si tratta di questioni sfuggenti e di difficile definizione, anche perché in genere non hanno un impatto su quanti gestiscono le aziende di <span class="smallcaps">ai</span> (in larga parte, soggetti caucasici di sesso maschile). Oggi, quando i sistemi di <span class="smallcaps">ai</span> falliscono, è più probabile che i danni ricadano su persone di colore, donne e altre minoranze.</p>
			<p class="testo" id="p_0045">A lasciare perplessi è il fatto che nel 2017 DeepMind parlava alla stampa e sul proprio sito dell’importanza dell’etica nella sua «missione di risolvere il problema dell’intelligenza per far progredire la scienza in favore di tutta l’umanità.» Alla rivista «Wired», per esempio, aveva anticipato come il piccolo team di ricercatori in campo etico sarebbe cresciuto fino a comprendere venticinque elementi nell’arco di un anno.</p>
			<p class="testo" id="p_0046">In realtà, il team arrivò a soli quindici membri, soprattutto perché, secondo un ex dirigente, i leader di DeepMind erano quasi esclusivamente concentrati sul progetto di scorporo. «Ne parlano tutto il tempo, ma sono solo un pugno di ricercatori e fanno fatica», dichiarò un altro dipendente, spiegando che il team etico non aveva un gruppo di supporto né risorse adeguate. «Non ha senso. Stiamo parlando di un’azienda multimiliardaria.»</p>
			<p class="testo" id="p_0047">Se DeepMind non metteva in pratica i suoi stessi principi etici, veniva spontaneo chiedersi perché i fondatori fossero così determinati a separarsi da Google. Volevano davvero impedire che la loro tecnologia causasse danni, o intendevano solo soddisfare il desiderio, assai più personale, di mantenere il controllo? Nel quadro dell’accordo di separazione, DeepMind prevedeva di firmare un contratto di licenza esclusiva con Google, ma i fondatori non sembravano in grado di chiarire se l’uso della loro <span class="smallcaps">ai</span> per scopi bellici potesse essere vietato, né se tale vincolo fosse legalmente applicabile. Sembravano pieni di ambizioni ma carenti nei dettagli. Alcuni dipendenti iniziarono a chiedersi se la pretesa da parte di Hassabis, Suleyman e Legg di avere la botte piena e la moglie ubriaca – ovvero accettare i finanziamenti di Google per continuare a sviluppare l’<span class="smallcaps">agi</span> ma cercare nel contempo di sottrarle il controllo dell’azienda – non fosse indice di ingenuità.</p>
			<p class="testo" id="p_0048">Così come Google aveva iniziato con il motto <em class="calibre3">Don’t be evil</em> («Non essere malvagio»), anche i fondatori di DeepMind avevano cominciato la loro avventura sotto Google con le migliori intenzioni. Avevano lasciato sul tavolo di Facebook 150 milioni di dollari pur di mantenere il punto sulla necessità di un comitato etico. Anni dopo, però, sembravano ormai dare priorità alle prestazioni e al prestigio, piuttosto che all’etica e alla sicurezza. Non avevano risposte chiare su come avrebbero contenuto l’<span class="smallcaps">agi</span>, se non assumendo un team di matematici di alto livello come Terence Tao, né su come avrebbero impedito un uso deleterio della tecnologia.</p>
			<p class="testo" id="p_0049">Tutto ciò sollevava una domanda più ampia. Era possibile fare un lavoro significativo su un’<span class="smallcaps">ai</span> etica in seno a una grande corporazione? La risposta arrivò dalla stessa Google, ed era un secco no.</p>
		</section>
	</body>
</html>
