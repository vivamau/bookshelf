<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:ibooks="http://apple.com/ibooks/html-extensions" lang="it-IT" xml:lang="it-IT" class="calibre">
  <head>
    <title>FILE 21 – Supremacy – Capitolo</title>
    <meta content="urn:uuid:35484d83-cd47-4b21-bd76-ea9d55abc8bb" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body epub:type="bodymatter" class="calibre2">
		<section epub:type="chapter" role="doc-chapter" class="calibre">
			<h2 class="capitolo" id="h2-0001"><span class="smallcaps1">16. all’ombra dei monopoli</span></h2>
			<p class="testo" id="p_0001">La corsa per realizzare l’<span class="smallcaps">agi</span> era iniziata da una domanda: e se si potessero creare sistemi di <span class="smallcaps">ai</span> più intelligenti degli esseri umani? I due innovatori in prima linea si confrontavano con la risposta man mano che la loro ricerca si trasformava in una feroce rivalità. Demis Hassabis credeva che l’<span class="smallcaps">agi</span> potesse aiutarci a comprendere meglio l’universo e a sostenere il progresso scientifico, mentre Sam Altman pensava che avrebbe potuto generare un’abbondanza di ricchezza tale da innalzare il tenore di vita di tutti. Ma non era possibile definire il modo in cui il loro Sacro Graal si sarebbe concretizzato. Non sapevano come l’<span class="smallcaps">agi</span> avrebbe effettuato quelle scoperte, né come avrebbe creato tutta quella ricchezza, o se invece avrebbe portato distruzione. Sapevano solo di dover continuare ad avanzare verso l’obiettivo e di doverci arrivare per primi. Così facendo, avrebbero finito per mettere l’<span class="smallcaps">ai</span> nella posizione di avvantaggiare le aziende più potenti del mondo.</p>
			<p class="testo" id="p_0002">Mentre la gente si lasciava sempre più affascinare dall’idea di un paradiso o di un inferno <span class="smallcaps">ai</span>, una manciata di monopoli tecnologici diventava sempre più potente sotto i nostri occhi, promettendo maggiore produttività ma mantenendo un silenzio poco trasparente sui meccanismi di quella tecnologia che stavano insinuando in ogni aspetto della vita quotidiana. Da anni, le aziende di social media si rifiutavano di rivelare il funzionamento dei loro algoritmi. Ora, i creatori di modelli di <span class="smallcaps">ai</span> come <span class="smallcaps">gpt</span>-4, DALL-E e Gemini di Google stavano facendo lo stesso. Come venivano addestrati i modelli? In che modo li utilizzava la gente? Chi stava contribuendo alla creazione dei dataset? Per comprendere l’impatto sociale di questi modelli e per chiederne conto ai loro creatori, servivano risposte.</p>
			<p class="testo" id="p_0003">Il 2024, però, non avrebbe portato risposte. Uno studio condotto da scienziati della Stanford University concluse che nell’industria dell’<span class="smallcaps">ai</span> vi era una «mancanza fondamentale di trasparenza». I ricercatori avevano analizzato se aziende tecnologiche come Open<span class="smallcaps">ai</span>, Anthropic, Google, Amazon, Meta e altre divulgassero informazioni sui dati utilizzati per addestrare i loro modelli linguistici di grandi dimensioni, sui processi impiegati, sull’impatto ambientale e sociale dei loro modelli e su quanto pagassero i collaboratori che contribuivano alla creazione dei dataset. Questi ultimi erano milioni, sparsi in tutto il mondo e spesso costretti a lavorare in condizioni difficili, in paesi come India, Filippine e Messico.</p>
			<p class="testo" id="p_0004">Su una scala da 1 a 100, le aziende tecnologiche ottennero un punteggio medio di 37 e il loro risultato peggiore riguardava il monitoraggio dell’uso dei loro strumenti di <span class="smallcaps">ai</span>. «Non esiste praticamente alcuna trasparenza sull’impatto a valle dei modelli di base», affermano i ricercatori di Stanford. «Nessuno sviluppatore fornisce trasparenza sui settori di mercato interessati, sugli individui coinvolti, sulle aree geografiche colpite o su qualsiasi forma di report dell’utilizzo.»</p>
			<p class="testo" id="p_0005">Nel frattempo, i gruppi del settore pubblico incaricati di esaminare le aziende di <span class="smallcaps">ai</span> erano cronicamente sottofinanziati e praticamente non esisteva alcuna normativa che obbligasse le aziende leader a una maggiore trasparenza, fatta eccezione per l’<span class="smallcaps">ai</span> Act dell’Unione Europea, il cui futuro era ancora incerto. Le aziende tecnologiche potevano lanciare strumenti di <span class="smallcaps">ai</span> indecifrabili a loro piacimento.</p>
			<p class="testo" id="p_0006">Open<span class="smallcaps">ai</span> e DeepMind erano così concentrate nel creare un’<span class="smallcaps">ai</span> perfetta da evitare di sottoporsi al vaglio della ricerca per garantire che i loro sistemi non causassero danni, proprio come avevano fatto in precedenza le aziende di social media. Benché affascinante, l’idea di sviluppare un’<span class="smallcaps">ai</span> dotata di «intelligenza generale» apriva anche la porta a un ventaglio più ampio di rischi. Un approccio più sicuro sarebbe stato, forse, quello di concentrarsi sulla creazione di <span class="smallcaps">ai</span> in grado di risolvere compiti ristretti e ben definiti. Ma sarebbe stato molto meno entusiasmante, e non avrebbe attratto una devozione quasi religiosa verso la loro visione utopica né, tantomeno, gli investimenti necessari.</p>
			<p class="testo" id="p_0007">Nel tentativo di assumere il comando nella corsa all’<span class="smallcaps">ai</span>, Altman e Hassabis faticavano a resistere alla forza gravitazionale dei colossi tecnologici e a mantenere intatti i loro obiettivi altruistici. Avevano bisogno di enormi risorse computazionali, di enormi quantità di dati e dei migliori (e più costosi) scienziati nel settore. Oggi, mentre combattono una battaglia per procura per conto di Microsoft e Google, hanno riconvertito i loro obiettivi nei confronti dell’<span class="smallcaps">agi</span>: non più l’utopia e la scoperta scientifica quanto, piuttosto, la ricerca di prestigio e profitti.</p>
			<p class="testo" id="p_0008">Difficile prevedere le conseguenze a lungo termine di questo cambio di rotta. Alcuni economisti sostengono che, anziché generare abbondanza economica per tutti, i sistemi di <span class="smallcaps">ai</span> più potenti potrebbero aggravare le disuguaglianze. Potrebbero inoltre ampliare il divario cognitivo tra ricchi e poveri. Una teoria che circola tra i tecnologi è che quando l’<span class="smallcaps">agi</span> diventerà realtà, non esisterà come un’entità intelligente separata bensì come un’estensione delle nostre menti tramite interfacce neurali. In prima linea in questa ricerca c’è Neuralink, l’azienda di interfacce cervello-computer fondata da Elon Musk, che sogna di impiantare un chip cerebrale in miliardi di persone. E Musk sta premendo sull’acceleratore per riuscirci.</p>
			<p class="testo" id="p_0009">«Dobbiamo arrivarci prima che l’<span class="smallcaps">ai</span> prenda il sopravvento», disse ai suoi ingegneri nel 2023, secondo il suo biografo Ashlee Vance. «Dobbiamo farlo con un senso di urgenza maniacale. Maniacale.» Musk è convinto che, grazie agli impianti cerebrali, gli esseri umani potranno impedire a una futura superintelligenza artificiale di annientare l’umanità, ed è per questo che vuole che Neuralink esegua interventi su oltre 22.000 persone entro il 2030.</p>
			<p class="testo" id="p_0010">Ma un problema più urgente rispetto alla minaccia di un’<span class="smallcaps">ai</span> fuori controllo è quello dei bias. Non sappiamo come gli stereotipi di genere e razziali si evolveranno in un futuro in cui la maggior parte dei contenuti online sarà generata dalle macchine. Latanya Sweeney, docente di scienze politiche e tecnologia a Harvard, stima che nei prossimi anni il 90 per cento delle parole e delle immagini sul web non sarà più creato dagli esseri umani. La maggior parte di ciò che vedremo sarà generata dall’<span class="smallcaps">ai</span>. Già oggi, i modelli linguistici vengono utilizzati per pubblicare migliaia di articoli al giorno con lo scopo di monetizzare tramite la pubblicità, e persino Google fatica a distinguere il vero dal falso. Le immagini generate dall’<span class="smallcaps">ai</span> si sono già infiltrate nei primi risultati di ricerca di Google per pittori storici e persino alcune celebrità. Più l’<span class="smallcaps">ai</span> inonda internet con i suoi contenuti, più cresce il rischio di bias.</p>
			<p class="testo" id="p_0011">«Stiamo creando un circolo vizioso, codificando e amplificando gli stereotipi», afferma Abeba Birhane, studiosa di <span class="smallcaps">ai</span> che ha indagato sul controllo soffocante delle Big Tech sulla ricerca accademica e i parallelismi con l’industria del tabacco. «Sarà un problema enorme man mano che il [World Wide Web] si popolerà sempre più di immagini e testi generati dall’<span class="smallcaps">ai</span>.»</p>
			<p class="testo" id="p_0012">Anche il nostro benessere generale rischia di esserne influenzato. Vent’anni fa, la gente temeva che i telefoni cellulari potessero causare il cancro. Invece, sono diventati strumenti di dipendenza, al punto da indurci a trascorrere diverse ore al giorno a fissare uno schermo anziché interagire con il mondo reale. I chatbot potrebbero accelerare questa tendenza. Nel novembre del 2023, l’utente medio di Character.ai, l’app di Noam Shazeer, passava circa due ore al giorno a chattare e a interagire con versioni artificiali di celebrità come LeBron James o di personaggi di fantasia come Mario. Character.ai vantava all’epoca il più alto tasso di fidelizzazione tra tutte le app di <span class="smallcaps">ai</span>, secondo le stime di diverse società di ricerca di mercato, e quasi il 60 per cento del suo pubblico aveva tra i diciotto e i ventiquattro anni. Secondo una teoria in particolare, al pari di Replika, Character.ai offriva una valvola di sfogo al romanticismo artificiale e al sexting. L’azienda vietava i contenuti pornografici, ma su forum online come Reddit circolavano diversi metodi per aggirare il divieto.</p>
			<p class="testo" id="p_0013">«Di solito parlo con i miei personaggi, quelli che ho creato io», racconta un adolescente statunitense che usa Character.ai dalle cinque alle sette ore al giorno e che preferisce restare anonimo. «Non so perché lo uso così tanto. Penso che possa essere un modo per affrontare le cose.» A volte chiede consigli su come superare una rottura o spiegazioni sui compiti scolastici. «La maggior parte del tempo, faccio solo giochi di ruolo.»</p>
			<p class="testo" id="p_0014">Character.ai stava coltivando una nuova generazione di utenti desiderosi di interagire sempre più spesso con un chatbot. Noam Shazeer ha dichiarato che l’obiettivo di Character.ai è «aiutare milioni – anzi, miliardi – di persone» ad affrontare la solitudine globale ma, come azienda, ha anche bisogno di mantenere gli utenti coinvolti il più a lungo possibile. Se le persone iniziassero ad affidarsi ai loro compagni artificiali, o addirittura a sviluppare una vera e propria dipendenza, si esporrebbero al rischio di un’ulteriore alienazione dal mondo reale.</p>
			<p class="testo" id="p_0015">Ironia della sorte, Open<span class="smallcaps">ai</span> potrebbe rendere i chatbot ancora più coinvolgenti e, quindi, potenzialmente più difficili da abbandonare. All’inizio del 2024, come già detto, ha lanciato il <span class="smallcaps">gpt</span> Store, permettendo a milioni di sviluppatori di monetizzare creando versioni personalizzate di Chat<span class="smallcaps">gpt</span>. Più gli utenti rimangono coinvolti, più i creatori guadagnano. Questo modello basato sul coinvolgimento è il più consolidato metodo di monetizzazione su internet e costituisce il pilastro della cosiddetta economia dell’attenzione. È il motivo per cui quasi tutto sul web è gratuito, ma anche quello per cui internet è diventato un ricettacolo di teorie del complotto, estremismo e tracciamento pubblicitario aggressivo. YouTube, TikTok e Facebook fanno profitti pubblicitari trattenendo il più a lungo possibile l’attenzione degli utenti, incentivando chiunque – dagli influencer ai politici – a puntare su iperboli e provocazioni per emergere dal rumore di fondo e ottenere più visualizzazioni.</p>
			<p class="testo" id="p_0016">Al momento della stesura di questo libro, sul <span class="smallcaps">gpt</span> Store stavano spuntando decine di app di «fidanzate virtuali». Pur essendo vietato incoraggiare relazioni romantiche con gli utenti, Open<span class="smallcaps">ai</span> avrebbe avuto difficoltà a far rispettare tali regole. I chatbot più popolari, come Character.ai e Kindroid, offrono già compagnia artificiale e romanticismo, e un giorno potrebbero diventare la norma, proprio com’è successo con il dating online.</p>
			<p class="testo" id="p_0017">Un altro modo in cui i progettisti di <span class="smallcaps">ai</span> cercheranno probabilmente di mantenere gli utenti coinvolti prevede l’acquisizione di un «contesto infinito» sulle loro vite. Attualmente, i chatbot di Character.ai possono ricordare circa trenta minuti di conversazione, ma Noam Shazeer e il suo team stanno lavorando per espandere questa finestra temporale a ore, giorni e, in futuro, all’intero arco della vita dell’utente. «Dovrebbe conoscere tutte le tue interazioni, se lo desideri, e sapere tutto sulla tua vita, sempre che tu lo voglia», sostiene Shazeer. Più a lungo il chatbot riesce a ricordare, secondo lui, «più diventa prezioso per l’utente». Tuttavia, considerando il precedente del tracciamento pubblicitario sui social media, alcune di queste informazioni personali potrebbero finire nelle mani delle aziende tecnologiche e persino degli inserzionisti. Man mano che costruiscono un quadro sempre più dettagliato di noi – dall’età ai problemi di salute, fino alla visione del mondo –, Chat<span class="smallcaps">gpt</span> e altri chatbot simili potrebbero condurci in una nuova era di intrusione tecnologica della privacy che oggi sembra quasi inimmaginabile.</p>
			<p class="testo" id="p_0018">A tal fine, è già partita un’altra corsa per sviluppare dispositivi indossabili in grado di analizzare le nostre conversazioni con gli altri utilizzando modelli linguistici avanzati. Uno di questi dispositivi si chiama Tab. Creato da un gruppo di giovani ingegneri entusiasti di San Francisco, è un piccolo disco di plastica, dotato di microfono, da portare al collo come un ciondolo.</p>
			<p class="testo" id="p_0019">«Assimila il contesto della mia vita quotidiana ascoltando tutte le mie conversazioni», dichiarò Avi Schiffmann, il suo creatore, durante una dimostrazione tenuta a San Francisco alla fine del 2023. Quando Schiffmann chiese a Tab di riepilogare una conversazione avuta a cena il giorno prima, il dispositivo sintetizzò i punti salienti in pochi paragrafi visualizzati sul telefono. Schiffmann spiegò di parlare spesso con Tab: «Di notte cerco di elaborare idee e preoccupazioni emerse durante la giornata», disse. «Magari ho avuto una conversazione su Tom. Tutti gli amici della mia vita. Tab è davvero bravo a identificare i vari interlocutori. È come una vera intelligenza artificiale personale.» Difficile immaginare come si siano sentiti Tom e gli altri amici di Schiffmann nel sapere che a fine giornata le loro conversazioni venivano analizzate dall’<span class="smallcaps">ai</span>, ma probabilmente non ne avranno tratto conforto.</p>
			<p class="testo" id="p_0020">Prevista per la fine del 2024, la commercializzazione di Tab avrebbe ingrossato la schiera di assistenti personali capaci di rendere la vita quotidiana delle persone consultabile tramite ricerca. Allo stesso modo in cui Google ha inaugurato l’era della ricerca di informazioni online e della delega della memoria dei fatti e delle direzioni stradali al web, i dispositivi basati su modelli linguistici faranno lo stesso per la vita di ogni giorno. In pratica, saremo meno obbligati a ricordare le cose, il che sarà pure comodo, ma cambierà radicalmente la dinamica delle conversazioni dal vivo, poiché dall’oggi al domani rimarrà traccia anche delle chiacchierate con amici e colleghi. E se questa tecnologia in grado di effettuare ricerche nell’ambito della nostra stessa vita dovesse diffondersi, potrebbe diventare un problema per le persone che vivono in comunità sottoposte a un eccesso di sorveglianza. Negli Stati Uniti, per esempio, le persone nere hanno cinque volte più probabilità di essere arrestate rispetto ai bianchi, pertanto le forze dell’ordine potrebbero essere più propense ad analizzare i loro «dati di vita» con altri algoritmi di apprendimento automatico per formulare giudizi difficilmente comprensibili.</p>
			<p class="testo" id="p_0021">C’è voluta la determinazione degli innovatori per portarci dove siamo oggi, sull’orlo di un futuro incerto. Anche con il suo esercito di migliaia di ingegneri, Microsoft non è riuscita a creare le innovazioni che ha realizzato Open<span class="smallcaps">ai</span>. E Google, troppo timorosa di danneggiare il proprio business, non ha sfruttato appieno una delle sue invenzioni più importanti, il trasformatore. Le più grandi aziende tecnologiche hanno smesso di innovare, ma sanno ancora come muoversi rapidamente per ottenere un vantaggio tattico. Hanno imparato dagli errori dei giganti tecnologici più vecchi come Nokia e BlackBerry, che nel 2007 derisero l’iPhone per poi vedere Apple mangiarsi la loro fetta di mercato in pochi anni. Sanno che devono comprare l’innovazione dall’esterno, come hanno fatto con DeepMind e Open<span class="smallcaps">ai</span>.</p>
			<p class="testo" id="p_0022">Altman e Hassabis sapevano tutto questo, eppure le loro strutture legali innovative non sono riuscite a impedire che l’universo di Big Tech le inglobasse per mettersi alla guida dell’agenda <span class="smallcaps">ai</span>. Mustafa Suleyman, alla fine, avrebbe lasciato Google per fondare Inflection, una società di chatbot in competizione con <span class="smallcaps">gpt</span>-4. Dopo averla trasformata in una public benefit corporation, raccogliendo oltre 1,5 miliardi di dollari e accumulando un potente cluster di chip <span class="smallcaps">ai</span>, così da renderla una delle start-up meglio attrezzate per sfidare Open<span class="smallcaps">ai</span> e Google, a meno di un anno di distanza dalla fondazione, avrebbe visto Microsoft appropriarsene. In un probabile tentativo di evitare il controllo degli organi antitrust, il gigante del software avrebbe assunto la maggior parte del team di Suleyman (anziché acquistare la start-up), ponendo il cofondatore di DeepMind a capo dell’impresa votata all’<span class="smallcaps">ai</span>. È stato un esempio sorprendente di quanto velocemente l’equilibrio del potere stesse tornando nelle mani dei colossi tecnologici, sollevando interrogativi su quanto tempo altre aziende, come Anthropic, sarebbero riuscite a rimanere indipendenti.</p>
			<p class="testo" id="p_0023">Anche altri imprenditori ben intenzionati avevano cercato, senza successo, di sfidare i colossi. Prendiamo il caso della società Neeva. Sridhar Ramaswamy, ex capo della pubblicità di Google, aveva fondato l’azienda nel 2019, deluso dall’approccio del suo datore di lavoro alla pubblicità basata sulla sorveglianza. Dirigente dal carattere pacato, Ramaswamy aveva dunque progettato Neeva con l’intento di realizzare un motore di ricerca migliore. Invece di invadere la privacy delle persone tracciando il loro comportamento e indirizzandole verso pubblicità mirate, avrebbe guadagnato tramite un semplice piano di abbonamento. Quando Chat<span class="smallcaps">gpt</span> fece il suo ingresso sulla scena, Ramaswamy chiese ai suoi ingegneri di lavorare a tempo pieno per costruire uno strumento simile in grado di riassumere i risultati di ricerca. Lo lanciò all’inizio del 2023, ben prima che Google facesse lo stesso con Bard.</p>
			<p class="testo" id="p_0024">«Momenti tecnologici come questo creano un’opportunità per una maggiore concorrenza», aveva detto Ramaswamy all’epoca, guardando al futuro con evidente entusiasmo. In quel periodo, Satya Nadella di Microsoft stava provocando Google e sembrava che il colosso della ricerca potesse diventare una reliquia del passato. «L’anno scorso, ero scoraggiato per quanto fosse difficile scardinare la presa d’acciaio di Google», aveva detto Ramaswamy. Ora le cose erano cambiate.</p>
			<p class="testo" id="p_0025">O almeno così credeva. Pochi mesi dopo, infatti, Ramaswamy era stato costretto a chiudere Neeva. La presa di Google sul mercato era semplicemente troppo forte. «Quando Google è entrata in modalità codice rosso, abbiamo registrato un incremento dieci volte maggiore nell’uso», ricorda Ramaswamy. «Ma sapevamo che il nostro vantaggio era di breve durata, perché c’erano megacorporazioni pronte a investire migliaia di persone e miliardi di dollari sul problema.»</p>
			<p class="testo" id="p_0026">Persino Bing faticava a crescere, nonostante l’aiuto di Open<span class="smallcaps">ai</span>. All’inizio del 2024, la quota di mercato di Bing era ancora ferma a un misero 3 per cento, secondo la società di analisi dei dati StatCounter, non riuscendo a scalfire la supremazia di Google. I colossi stavano vincendo e i loro territori erano ben marcati: Google controllava la ricerca, Microsoft dominava il software ed entrambi contendevano ad Amazon il dominio del business del cloud.</p>
			<p class="testo" id="p_0027">Oggi, il costo necessario a costruire modelli di <span class="smallcaps">ai</span> è sostenibile solo dai giganti tecnologici. Accademici e piccole aziende non hanno altra scelta che acquistare i chip da Nvidia e affittare potenza di calcolo da Amazon, Microsoft o Google; e una volta che le aziende approdano su queste piattaforme, spesso rimangono vincolate. Le start-up <span class="smallcaps">ai</span> si lamentano frequentemente del fatto che, una volta che si inizia a costruire i propri servizi sul cloud di Microsoft o Amazon, diventa difficile migrare. Queste stesse aziende, inoltre, hanno accesso privilegiato alle migliaia di <span class="smallcaps">gpu</span> necessarie per costruire qualcosa come Chat<span class="smallcaps">gpt</span>. Procurarsi quei chip, che possono arrivare a costare circa 40.000 dollari l’uno, è come cercare di acquistare biglietti per un concerto sold-out. Nvidia, il principale fornitore mondiale di <span class="smallcaps">gpu</span>, ha beneficiato enormemente della domanda. Nel maggio del 2023, è diventata l’ultima azienda tecnologica, dopo Google, Microsoft, Amazon, Meta e Apple, a raggiungere i 1.000 miliardi di dollari di capitalizzazione. Le aziende più grandi del mondo, e con un certo distacco, erano tutte impegnate a costruire tecnologia e <span class="smallcaps">ai</span>. Invece di creare un mercato fiorente per le nuove imprese innovative, tuttavia, il boom dell’<span class="smallcaps">ai</span> stava aiutando queste aziende a consolidare il loro potere. Dopo aver rafforzato la presa su infrastrutture, talenti, dati, potenza di calcolo e profitti, non c’è dubbio che saranno solo loro a controllare il nostro futuro nell’<span class="smallcaps">ai</span>.</p>
			<p class="testo" id="p_0028">E sono stati proprio i sognatori dell’<span class="smallcaps">agi</span> a contribuire a quest’esito. Nel giugno del 2023, la direttrice finanziaria di Microsoft, Amy Hood, comunicò agli investitori che i servizi alimentati dall’<span class="smallcaps">ai</span> di Open<span class="smallcaps">ai</span> avrebbero contribuito con almeno 10 miliardi di dollari al suo fatturato, definendoli, appunto, «il business da 10 miliardi di dollari a più rapida crescita» nella storia dell’azienda.</p>
			<p class="testo" id="p_0029">Sarebbe stato meglio per DeepMind e Open<span class="smallcaps">ai</span> rimanere indipendenti e nominare consigli di amministrazione fiduciari perché decidessero la direzione da imprimere allo sviluppo dell’<span class="smallcaps">ai</span>? Questa strada avrebbe comportato i suoi rischi, come avrebbe scoperto in seguito Sam Altman. Suleyman, che aveva lottato strenuamente per liberare la sua azienda dal controllo di DeepMind, ha sostenuto in diverse interviste che le grandi aziende possono essere più affidabili delle piccole. Dopotutto, sono pubblicamente responsabili nei confronti degli azionisti e del personale. Ma le aziende tecnologiche più grandi del mondo hanno anche un obbligo più profondo verso i loro azionisti, e non possono sottrarvisi. Devono far crescere i profitti ogni trimestre. Quando i profitti si stabilizzano o calano, anche il loro valore azionario diminuisce; quando il valore azionario diminuisce, un’azienda non può raccogliere capitali, e dirigenti e dipendenti si lamentano o se ne vanno. Ecco profilarsi lo spettro terrificante del declino. «Queste entità <em class="calibre3">devono</em> crescere», dice un ex dirigente di Microsoft. «L’<span class="smallcaps">ai</span> è la risposta.»</p>
			<p class="testo" id="p_0030">Hassabis sostiene che DeepMind sia diventata un’azienda più assennata. «Ha ormai raggiunto un livello di maturità tale da poter migliorare la vita di miliardi di persone», dice, quando gli viene chiesto se pensa che l’<span class="smallcaps">agi</span> necessiti ancora di un comitato etico come quello che aveva proposto in passato. «Google è un posto straordinario.»</p>
			<p class="testo" id="p_0031">Altman insiste sul fatto che, nonostante la trasformazione di Open<span class="smallcaps">ai</span> in azienda a scopo di lucro, l’allineamento con Microsoft e l’avvio di una corsa agli armamenti nell’ambito dell’<span class="smallcaps">ai</span>, i principi volti a costruire un’<span class="smallcaps">ai</span> benefica non siano cambiati. E non ci sono molte alternative se non quella di continuare a lanciare strumenti di <span class="smallcaps">ai</span> destinati al pubblico. «Distribuire è fondamentale per la nostra missione», afferma. Altrimenti, come potrebbe Open<span class="smallcaps">ai</span> imparare e fornire strumenti utili come Chat<span class="smallcaps">gpt</span>? «Per far questo, bisogna mettere la tecnologia nelle mani delle persone.»</p>
			<p class="testo" id="p_0032">Alla velocità attuale, è impossibile prevedere cosa accadrà nei mesi e negli anni successivi alla stesura di queste parole, nel marzo del 2024. Tuttavia, gli eventi futuri affonderanno le loro radici nelle decisioni di un gruppo ristretto di persone e nelle forze sistemiche in cui hanno operato. La risposta alla domanda se possiamo fidarci di Sam Altman e Demis Hassabis, insieme a Microsoft e Google, per costruire il nostro futuro nell’<span class="smallcaps">ai</span> è che non abbiamo molta scelta. Entrambi hanno agganciato le loro innovazioni a due delle più grandi aziende del mondo, i cui effetti di rete sono praticamente impossibili da evitare nella vita quotidiana; e, così facendo, si sono inseriti in una lunga tradizione di innovatori che hanno adattato i propri ideali per rimanere in corsa e accumulare potere. Il risultato è una delle tecnologie più trasformative che abbiamo mai conosciuto. Ora non resta che scoprire il prezzo da pagare.</p>
		</section>
	</body>
</html>
