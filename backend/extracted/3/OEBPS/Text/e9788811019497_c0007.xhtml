<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:ibooks="http://apple.com/ibooks/html-extensions" lang="it-IT" xml:lang="it-IT" class="calibre">
  <head>
    <title>FILE 7 – Supremacy – Capitolo</title>
    <meta content="urn:uuid:35484d83-cd47-4b21-bd76-ea9d55abc8bb" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body epub:type="bodymatter" class="calibre2">
		<section epub:type="chapter" role="doc-chapter" class="calibre">
			<h2 class="capitolo" id="h2-0001"><span class="smallcaps1">5. per l’utopia, per i soldi</span></h2>
			<p class="testo" id="p_0001">Il messaggio proveniva da un dirigente della sede di Google, a più di ottomila chilometri di distanza, nella soleggiata Mountain View, in California. Aprendolo sul suo computer, a Londra, Hassabis trovò un invito a incontrare Larry Page, il <span class="smallcaps">ceo</span> di Google. Page aveva cofondato Google con un altro dottorando di Stanford, Sergey Brin, nel 1998. I due volevano facilitare le ricerche su internet, e lo avevano fatto creando un algoritmo denominato PageRank, che classificava le pagine web in base a rilevanza e interconnessione. Partendo dal garage di un amico a Menlo Park, in California, avevano finito per strutturare una delle più grandi aziende tecnologiche al mondo.</p>
			<p class="testo" id="p_0002">Quanto al modo in cui Google guadagnava, non era particolarmente high-tech o innovativo: era diventata una gigantesca azienda pubblicitaria, come Facebook. La maggior parte dei profitti di Google proveniva dal monitoraggio delle informazioni personali al fine di raggiungere gli utenti con pubblicità mirate tramite la ricerca, YouTube, Gmail e milioni di siti web e app che usavano la Rete Display di Google.</p>
			<p class="testo" id="p_0003">C’era qualcosa di leggermente inquietante in tutto questo, per uno come Hassabis che voleva usare l’<span class="smallcaps">ai</span> per aiutare il mondo. D’altro canto era consapevole che, se non avesse accettato l’offerta, Google avrebbe potuto soffiargli il personale e magari costruire l’<span class="smallcaps">agi</span> senza di lui. Google aveva già centinaia di ingegneri che lavoravano sull’<span class="smallcaps">ai</span>, e proprio per questo Hassabis si persuase ad accettare l’invito.</p>
			<p class="testo" id="p_0004">Quando incontrò Page, ebbe la sensazione di parlare con uno spirito affine. Davanti a lui c’era un introverso laureato in matematica dalle folte sopracciglia scure che indossava camicie casual e bermuda. Per un’intera carriera dedicata alla costruzione di Google, Page aveva coltivato il sogno di creare un’<span class="smallcaps">ai</span> performante. «Mi disse di aver sempre pensato a Google come a un’azienda di <span class="smallcaps">ai</span>, sin da quei primi giorni del 1998, nel garage», ricorda Hassabis.</p>
			<p class="testo" id="p_0005">In parte, la questione era personale: suo padre era stato docente di intelligenza artificiale e scienze informatiche fino alla morte, avvenuta nel 1996. Questo faceva di lui una sorta di tecnologo dell’<span class="smallcaps">ai</span> di seconda generazione. Page ammirava la serietà con cui Hassabis stava costruendo l’<span class="smallcaps">agi</span>, e non considerava affatto strampalate le sue idee. Aveva già dato il via a un progetto interno a Google per sviluppare un’<span class="smallcaps">ai</span> che imitasse quella umana, un’iniziativa che in futuro avrebbe finito per alimentare una forte rivalità con lo stesso Hassabis.</p>
			<p class="testo" id="p_0006">Il progetto di Page, di cui all’epoca Hassabis non era a conoscenza, si chiamava Google Brain. Era nato da una proposta di Andrew Ng, un professore di Stanford dall’eloquio pacato che voleva costruire sistemi di <span class="smallcaps">ai</span> più avanzati all’interno di Google. Nel 2011, qualche anno prima che Google contattasse DeepMind, Ng aveva inviato a Page un documento di quattro pagine dal titolo <em class="calibre3">Neuroscience-Informed Deep Learning</em> («Apprendimento profondo basato sulle neuroscienze»). Con questa mossa, sperava che il <span class="smallcaps">ceo</span> di Google approvasse un progetto mirato a realizzare sistemi di <span class="smallcaps">ai</span> «per uso generico», lo stesso obiettivo su cui Hassabis lavorava in Inghilterra.</p>
			<p class="testo" id="p_0007">Venne fuori che Ng e Hassabis approcciavano la questione con un metodo simile, cercando entrambi ispirazione nelle neuroscienze. Nella sua proposta, il professore di Stanford aveva spiegato a Page che il suo intento era di ricreare «approssimazioni sempre più accurate di piccole parti del cervello dei mammiferi».</p>
			<p class="testo" id="p_0008">Anche per uno come Ng, che era già una figura di spicco nel settore e lavorava per una delle università più prestigiose al mondo, l’idea di costruire un’<span class="smallcaps">agi</span> era controversa. «I miei amici mi consigliavano di lasciar perdere. Dicevano: “Non gioverà alla tua carriera”», ricorda.</p>
			<p class="testo" id="p_0009">In un certo senso, avevano ragione. Sotto il profilo scientifico, l’ossessione di Ng e Hassabis per il cervello umano presentava alcuni problemi. In teoria, usare la nostra materia grigia come modello per l’<span class="smallcaps">ai</span> era una scelta logica, ma copiare ciò che troviamo in natura non sempre funziona. Basti pensare ai primi tentativi di realizzare macchine volanti e agli inventori che costruivano congegni che imitavano la meccanica del volo degli uccelli e che finivano puntualmente per schiantarsi al suolo. Altri scienziati informatici si erano già ritrovati in un vicolo cieco tentando di copiare troppo fedelmente il cervello. Nel 2013, il neuroscienziato Henry Markham affermò in un <span class="smallcaps">ted</span> Talk di aver scoperto il modo di simulare un intero cervello umano su supercomputer e ci sarebbe riuscito nel giro di un decennio. Dieci anni più tardi, il suo Human Brain Project, costato già oltre un miliardo di dollari, poteva dirsi in gran parte fallito.</p>
			<p class="testo" id="p_0010">Negli anni successivi, Ng, Hassabis e altri scienziati nel campo dell’<span class="smallcaps">ai</span> avrebbero preso coscienza di quanto fosse difficile emulare il cervello, avendone ancora una conoscenza così incompleta, dalle funzioni dei neuroni alla dinamica delle regioni cerebrali. Sapevamo già che nel nostro cranio ci sono circa novanta miliardi di neuroni che si attivano continuamente, ma non avevamo alcuna idea di come venissero elaborate le informazioni.</p>
			<p class="testo" id="p_0011">«Con il senno di poi, provare a rimanere così fedeli alla biologia è stato un errore», afferma Ng. Tuttavia, la ricerca del professore si rivelò efficace nell’ampliare le sue reti neurali.</p>
			<p class="testo" id="p_0012">Una rete neurale è un tipo di software che viene costruito tramite un processo di addestramento ripetuto grazie a enormi quantità di dati. Una volta addestrata, una rete neurale può riconoscere volti, prevedere mosse di scacchi o consigliarvi il prossimo film su Netflix. Chiamata anche «modello», una rete neurale è spesso composta da molti strati e nodi che elaborano informazioni in modo vagamente simile ai neuroni del nostro cervello. Più il modello viene addestrato, più quei nodi migliorano la propria capacità di prevedere o riconoscere le cose.</p>
			<p class="testo" id="p_0013">Ng aveva scoperto che questi modelli potevano svolgere più compiti se disponevano di un maggior numero di nodi, strati e dati su cui allenarsi. Anni dopo, anche Open<span class="smallcaps">ai</span> avrebbe fatto una scoperta simile sull’importanza di potenziare questi elementi chiave. Nei suoi esperimenti a Stanford, Ng aveva notato che i suoi modelli di <em class="calibre3">deep learning</em> funzionavano molto meglio quando erano costruiti in scala più grande. Entusiasmato dai risultati, aveva inviato la sua proposta di quattro pagine a Page, suggerendo di poter costruire «simulazioni cerebrali su larga scala» come primo passo verso un’«<span class="smallcaps">ai</span> di livello umano».</p>
			<p class="testo" id="p_0014">Innamoratosi dell’idea, Page prese a bordo Ng perché guidasse il progetto di ricerca più all’avanguardia di Google fino a quel momento. Pochi anni dopo, però, Google Brain non sembrava più così orientato verso la costruzione di un’<span class="smallcaps">agi</span>. Piuttosto, stava aiutando Google a ottimizzare il suo business pubblicitario mirato – rendendo gli annunci ancora più spaventosamente accurati per gli utenti, migliorando la capacità di prevedere su cosa avrebbero cliccato questi ultimi – e a incrementarne i ricavi. Ng ammette che non era ciò per cui aveva inviato la sua proposta a Page. «Non è la cosa più entusiasmante a cui abbia lavorato», confessa.</p>
			<p class="testo" id="p_0015">Ciò a cui ambiva veramente Ng con la sua ricerca era affrancare l’umanità dalla fatica mentale, nello stesso modo in cui la rivoluzione Industriale ci aveva liberati dal lavoro fisico incessante. Credeva che sistemi di <span class="smallcaps">ai</span> più avanzati avrebbero fatto lo stesso per i lavoratori professionisti, «permettendo a noi tutti di dedicarci a compiti più stimolanti e di alto livello sotto il profilo intellettuale».</p>
			<p class="testo" id="p_0016">Ma era nelle modalità con cui perseguiva questo obiettivo che Ng differiva da Hassabis. Mentre l’imprenditore britannico voleva quanta più indipendenza possibile dal colosso pubblicitario, il professor Ng era ben felice di lavorare nel ventre della bestia. In tal senso, aveva reso un enorme favore a Hassabis. Stabilendosi all’interno della casa madre di Google, la sua ricerca era già destinata a contribuire al business pubblicitario dell’azienda, il che evitava a DeepMind di doverlo fare nell’immediato.</p>
			<p class="testo" id="p_0017">Quando Google contattò DeepMind, alla fine del 2013, i ricercatori di Ng erano già stati assorbiti dallo sviluppo di sofisticati modelli di <span class="smallcaps">ai</span> con cui potenziare gli strumenti pubblicitari di Google, distogliendoli dall’obiettivo più ambizioso di Ng, ovvero quello di creare un’<span class="smallcaps">ai</span> onnipotente capace di liberare l’umanità dai lavori poco stimolanti. Mentre volava a Londra per negoziare l’acquisto di DeepMind, Page sapeva di poter investire una parte del denaro di Google per qualcosa di un po’ più visionario.</p>
			<p class="testo" id="p_0018">I fondatori di DeepMind accolsero il miliardario di Google nel loro ufficio di Londra, con una presentazione sui progressi dell’azienda fino a quel momento, secondo quanto Cade Metz, corrispondente del «New York Times», riporta nel suo <em class="calibre3">Costruire l’intelligenza</em>. Hassabis spiegò come il suo team avesse sviluppato una nuova tecnica chiamata <em class="calibre3">reinforcement learning</em> («apprendimento per rinforzo») per addestrare un sistema di <span class="smallcaps">ai</span> a padroneggiare il gioco retrò Atari <em class="calibre3">Breakout</em>. Nel gioco, bisogna spedire una pallina contro una parete di mattoni utilizzando una paletta che si muove da un lato all’altro. In circa due ore, il sistema aveva imparato a colpire la pallina nel punto giusto, in modo che aprisse un varco nello spazio stretto oltre la fila superiore di mattoni, distruggendone un gran numero in un colpo solo. Page ne rimase impressionato.</p>
			<p class="testo" id="p_0019">L’apprendimento per rinforzo non era molto diverso dal modo in cui si premia un cane con dei bocconcini ogni volta che si siede a comando. Nell’addestramento dell’<span class="smallcaps">ai</span>, si premia analogamente il modello, magari con un segnale numerico come un +1, per dimostrare che un certo risultato è positivo. Attraverso ripetuti tentativi ed errori, e giocando centinaia di partite, il sistema imparava cosa funzionava e cosa no. Era un’idea di una elegante semplicità confezionata in un codice informatico estremamente sofisticato.</p>
			<p class="testo" id="p_0020">Poi Legg illustrò a Page la direzione verso cui puntava questa ricerca: l’applicazione di queste tecniche al mondo reale. Così come il loro sistema aveva imparato a padroneggiare un videogioco, avrebbero potuto insegnare a un robot a orientarsi in una casa o a un agente autonomo a destreggiarsi nella lingua inglese. Erano queste le applicazioni in cui le scoperte di DeepMind e l’<span class="smallcaps">agi</span> stessa avrebbero avuto il maggior impatto. E ciò convinse Page e il suo team.</p>
			<p class="testo" id="p_0021">Il <span class="smallcaps">ceo</span> di Google guidò le trattative con Hassabis e i suoi cofondatori sapendo che avevano già rifiutato un’offerta sostanziosa da parte di Facebook. Stava per scoprirne il motivo. Hassabis espose le due condizioni fondamentali per la vendita. Per prima cosa, lui e i cofondatori non volevano che Google usasse la tecnologia di DeepMind per scopi militari, che si trattasse di dirigere droni autonomi o armi, o di supportare soldati sul campo. Per loro, questi erano confini etici invalicabili.</p>
			<p class="testo" id="p_0022">In secondo luogo, volevano che i dirigenti di Google firmassero un accordo di etica e sicurezza. Redatto da avvocati londinesi, il contratto cedeva il controllo di qualsiasi tecnologia di intelligenza artificiale generale sviluppata in futuro da DeepMind a un comitato etico istituito da Hassabis e Suleyman. Entrambi avevano ancora solo una vaga idea di chi dovesse farne parte, ma volevano che avesse il controllo legale assoluto sull’<span class="smallcaps">ai</span> avanzata che avrebbero costruito.</p>
			<p class="testo" id="p_0023">«Se fossimo riusciti nell’impresa, sarebbe stato necessario gestire [l’<span class="smallcaps">agi</span>] con attenzione», dice Hassabis riguardo al comitato. «Data la sua versatilità, poteva trattarsi di una delle tecnologie più potenti di tutti i tempi, perciò all’epoca volevamo la certezza di trattare con persone che se ne accollassero seriamente le responsabilità.»</p>
			<p class="testo" id="p_0024">Non sorprende che ci siano voluti mesi di complesse trattative per convincere Google ad accettare la medesima condizione che aveva frenato Facebook. L’acquisto di DeepMind consegnava a Page la prima azienda in grado di costruire un’<span class="smallcaps">agi</span>. E lui sapeva che se questo comitato etico avesse avuto il controllo legale sulla tecnologia in questione, sarebbe stato molto più complicato, per Google, trarne profitto; tuttavia, alla fine, la sua visione idealista prevalse. Avrebbero trovato un modo per far funzionare le cose. Di conseguenza, accettò le condizioni di DeepMind circa il comitato etico.</p>
			<p class="testo" id="p_0025">L’<span class="smallcaps">agi</span> non necessitava di una gestione attenta solo in relazione ai possibili scenari futuri legati ai giganti aziendali. Era anche al centro di diverse ideologie che avrebbero potuto indirizzare la tecnologia in diverse direzioni. Hassabis ne aveva avuto un assaggio da investitori come Peter Thiel, che voleva accelerarne lo sviluppo, e da Jaan Tallinn, che invece temeva l’innesco di una sorta di apocalisse.</p>
			<p class="testo" id="p_0026">Il potenziale sconvolgente dell’<span class="smallcaps">ai</span> esercitava una fascinazione quasi mistica su individui animati da convinzioni forti su come dovesse essere utilizzata. Negli anni a venire, queste forze ideologiche si sarebbero scontrate con gli innovatori e i monopoli aziendali che si contendevano il controllo dell’<span class="smallcaps">agi</span>, diventando un pericolo imprevedibile per la tecnologia. Avrebbero spinto, per esempio, Sam Altman fuori da Open<span class="smallcaps">ai</span> e, paradossalmente, rafforzato gli sforzi commerciali delle aziende, dipingendo un quadro apocalittico del potere dell’<span class="smallcaps">ai</span> che finiva per rendere il software più attraente per le imprese. A contatto con il mondo degli affari e del profitto, sempre più costruttori di <span class="smallcaps">ai</span> si ritrovavano a seguire devotamente dottrine diverse, da quella permeata dall’ansia di realizzare quanto prima l’<span class="smallcaps">ai</span> per dare vita a un’utopia a quella che fomentava la paura che potesse provocare l’Armageddon.</p>
			<p class="testo" id="p_0027">In quanto pensatore strategico che procedeva sempre con i piedi di piombo, Hassabis si trovò in gran parte fuori da questi principi ideologici in conflitto, grazie anche all’obiettivo che aveva in testa, ovvero giungere a scoperte straordinarie e forse persino divine tramite l’<span class="smallcaps">agi</span>. Suleyman era anche più preoccupato per i problemi sociali che l’<span class="smallcaps">ai</span> poteva causare prima di quel momento. Dei tre cofondatori, Shane Legg era quello maggiormente in linea con le ideologie più radicali legate alla ricerca dell’<span class="smallcaps">agi</span>, inclusa una che, stando alle parole dei suoi ex colleghi, covava ormai da decenni. Nota come transumanismo, l’idea aveva radici controverse e una storia che contribuiva a spiegare perché i costruttori di <span class="smallcaps">ai</span> talvolta trascurassero gli effetti collaterali sgradevoli, e più attuali, della tecnologia.</p>
			<p class="testo" id="p_0028">La premessa di base del transumanismo è che noi umani siamo al momento una specie di qualità inferiore. Con le appropriate scoperte scientifiche e tecnologiche, un giorno potremmo evolverci oltre gli attuali limiti fisici e mentali in una specie più dotata. Saremo più intelligenti e creativi, e vivremo più a lungo. Potremmo anche riuscire a fondere le nostre menti con i computer e a esplorare la galassia.</p>
			<p class="testo" id="p_0029">L’idea centrale risale al periodo tra gli anni Quaranta e Sessanta del secolo scorso, quando un biologo evoluzionista di nome Julian Huxley aderì alla British Eugenics Society, diventandone il presidente. Il movimento eugenetico sosteneva che gli esseri umani dovessero migliorarsi attraverso la selezione della riproduzione, e si diffuse nelle università britanniche e tra le classi intellettuali e altolocate del paese. Lo stesso Huxley proveniva da una famiglia aristocratica (suo fratello Aldous scrisse <em class="calibre3">Il mondo nuovo</em>) e riteneva che l’élite della società fosse geneticamente superiore. Le persone delle classi inferiori andavano eliminate come una messe cattiva e sottoposte a sterilizzazione forzata. «Si stanno riproducendo troppo in fretta», scriveva Huxley.</p>
			<p class="testo" id="p_0030">Quando i nazisti fecero propria l’ideologia eugenetica, Huxley decise che il movimento aveva bisogno di un nuovo nome. Coniò così il termine <em class="calibre3">transumanismo</em> in un saggio in cui affermava che, oltre alla riproduzione selettiva, l’umanità avrebbe anche potuto «trascendere sé stessa» attraverso la scienza e la tecnologia. Il movimento acquistò slancio negli anni Ottanta e Novanta, quando il nascente campo dell’intelligenza artificiale suggerì una possibilità allettante: forse gli scienziati avrebbero potuto potenziare la mente umana attraverso una fusione con macchine intelligenti.</p>
			<p class="testo" id="p_0031">L’idea si cristallizzò nel concetto di singolarità, quel momento collocato nel futuro in cui l’<span class="smallcaps">ai</span> e la tecnologia avrebbero raggiunto un livello talmente avanzato da provocare un cambiamento drammatico e irreversibile nel genere umano, fondendolo con le macchine e potenziandolo. Si trattava di una prospettiva che sin dall’adolescenza aveva affascinato Legg, così come il facoltoso finanziatore di DeepMind Peter Thiel. Tra i tecnologi, l’attrazione per questa utopia era tale che alcuni di loro, come Altman e Thiel, si erano registrati presso diverse aziende specializzate nella criogenizzazione del cervello o dell’intero corpo, nel caso in cui non fossero riusciti a fondersi con le macchine prima della morte. «Non mi aspetto necessariamente che funzioni», disse Thiel alla giornalista Bari Weiss nel suo podcast. «Ma credo che sia il genere di cosa che dovremmo almeno provare a fare.»</p>
			<p class="testo" id="p_0032">Il problema con alcune di queste idee era che, nel corso degli anni, i loro seguaci divennero sempre più fanatici. I cosiddetti «accelerazionisti dell’<span class="smallcaps">ai</span>», per esempio, credevano che gli scienziati avessero l’imperativo morale di lavorare il più velocemente possibile per sviluppare un’<span class="smallcaps">agi</span> capace di creare un paradiso postumano, una sorta di estasi tecnologica per nerd. Se fosse stata realizzata durante l’arco della loro esistenza, avrebbero potuto vivere per sempre. Tuttavia, accelerare lo sviluppo dell’<span class="smallcaps">ai</span> poteva anche significare prendere scorciatoie e generare una tecnologia potenzialmente dannosa per determinati gruppi di persone o capace di sfuggire al controllo.</p>
			<p class="testo" id="p_0033">Altri, invece, si posizionavano sulla sponda opposta, vedendo nell’<span class="smallcaps">ai</span> una sorta di minaccia demoniaca da fermare a tutti i costi. Eliezer Yudkowsky, il barbuto libertario che aveva contribuito a radicalizzare Jaan Tallinn davanti a un caffè, era uno dei leader di questo movimento ideologico, al quale diede sempre più slancio attraverso il già citato sito LessWrong. Quando Google acquistò DeepMind, nel 2014, centinaia di persone, tra cui numerosi ricercatori di <span class="smallcaps">ai</span>, stavano partecipando a dibattiti di carattere filosofico sul sito, discutendo di come evitare che una superintelligenza, in futuro, finisse per annientare il genere umano. LessWrong era diventato l’hub online delle paure apocalittiche legate all’<span class="smallcaps">ai</span>, e alcuni articoli sottolineavano come ormai avesse tutte le caratteristiche di un moderno culto millenarista. Quando un partecipante suggerì l’ennesimo possibile scenario in cui l’<span class="smallcaps">ai</span> avrebbe potuto distruggere l’umanità, lo stesso Yudkowsky reagì con veemenza, attaccandolo pubblicamente con un messaggio tutto in maiuscolo e infine espellendolo dal gruppo.</p>
			<p class="testo" id="p_0034">Con il tempo, i cosiddetti <em class="calibre3">doomers</em> dell’<span class="smallcaps">ai</span> guadagnarono abbastanza sostegno tra i ricchi imprenditori tecnologici da ottenere finanziamenti con cui avviare aziende e plasmare le politiche governative. Il sito di Yudkowsky divenne così influente che molti dei suoi lettori più assidui finirono per entrare in Open<span class="smallcaps">ai</span>.</p>
			<p class="testo" id="p_0035">Ma forse le ideologie più inquietanti che iniziavano a diffondersi intorno all’<span class="smallcaps">agi</span> erano quelle che miravano a creare una specie umana quasi perfetta in forma digitale. L’idea era stata in parte resa popolare dal già citato <em class="calibre3">Superintelligenza</em> di Bostrom, libro che ebbe un impatto paradossale sul campo dell’<span class="smallcaps">ai</span>: da un lato, alimentando i timori sulla possibile distruzione del genere umano a opera di un’<span class="smallcaps">ai</span> superintelligente e fuori controllo che avrebbe potuto sterminarci senza nemmeno volerlo, trasformandoci in graffette; dall’altro, descrivendo la possibilità di un’utopia gloriosa verso cui avrebbe potuto introdurci l’<span class="smallcaps">ai</span>, se fosse stata costruita nel modo giusto.</p>
			<p class="testo" id="p_0036">Uno degli aspetti più affascinanti di questa visione, secondo Bostrom, era la creazione di «postumani» dotati di capacità enormemente superiori a quelle degli umani «normali» e destinati a vivere in substrati digitali. Secondo questa utopia digitale, gli esseri umani avrebbero potuto esplorare ambienti che sfidavano le leggi della fisica, decidere autonomamente la propria fine o esplorare mondi fantastici. Avrebbero potuto rivivere ricordi preziosi, creare nuove avventure o sperimentare diverse forme di coscienza. Le interazioni sarebbero diventate più profonde, poiché questi nuovi esseri umani avrebbero potuto condividere pensieri ed emozioni in maniera diretta, portando a connessioni più intime e significative.</p>
			<p class="testo" id="p_0037">Queste idee erano irresistibili per alcuni esponenti della Silicon Valley, convinti com’erano che una simile realtà fosse raggiungibile grazie ad algoritmi appropriati. Presentando un futuro che poteva somigliare tanto al paradiso quanto all’inferno, Bostrom alimentò una convinzione che avrebbe spinto i costruttori di <span class="smallcaps">ai</span> della Silicon Valley, come Sam Altman, a gareggiare per sviluppare l’<span class="smallcaps">agi</span> prima di Demis Hassabis a Londra. Dovevano arrivare per primi, perché <em class="calibre3">soltanto loro</em> potevano farlo in sicurezza. Se qualcun altro fosse riuscito a precederli, senza un adeguato allineamento ai valori umani, c’era il rischio di annientare non solo i miliardi di umani viventi, ma anche le potenziali migliaia di miliardi di umani-digitali del futuro. In sostanza, avremmo perso la possibilità di vivere in un nirvana tecnologico. Nel frattempo, le teorie di Bostrom avrebbero avuto anche effetti collaterali pericolosi, distogliendo l’attenzione dallo studio dei modi in cui l’intelligenza artificiale poteva danneggiare le persone già nel presente.</p>
			<p class="testo" id="p_0038">Mentre queste ideologie prendevano piede e s’intrecciavano con le trattative tra DeepMind e Google, emergeva una scomoda realtà: per le aziende tecnologiche, trovare una forma di gestione responsabile dell’<span class="smallcaps">ai</span> diventava sempre più difficile. Obiettivi contrastanti erano destinati a collidere, spinti da un fervore quasi religioso da un lato e da una fame insaziabile di crescita economica dall’altro.</p>
			<p class="testo" id="p_0039">Per il momento, e in virtù dei motivi personali che lo spingevano a realizzare l’<span class="smallcaps">agi</span>, Hassabis rimaneva distante da queste battaglie ideologiche. Operando in Inghilterra, lontano dalla bolla della Silicon Valley, si era circondato di un team di scienziati e ingegneri straordinariamente brillanti, destinato tra l’altro a crescere. Era determinato a risolvere l’enigma dell’<span class="smallcaps">agi</span> nel giro di cinque anni, un’impresa che – secondo chi lavorava con lui – avrebbe potuto garantirgli persino un Nobel. Né gli importava il fatto che un colosso aziendale potesse inglobarlo: una volta costruita l’<span class="smallcaps">agi</span>, il concetto stesso di economia sarebbe diventato obsoleto, e né DeepMind né Google avrebbero più dovuto preoccuparsi di fare soldi. L’<span class="smallcaps">ai</span> avrebbe risolto anche quel problema.</p>
			<p class="testo" id="p_0040">Quando l’accordo fu finalmente firmato e il comitato etico aggiunto al contratto di acquisizione, Google acquistò DeepMind per 650 milioni di dollari. Era una cifra inferiore a quella che i fondatori avrebbero ottenuto da Zuckerberg, ma comunque enorme per un’azienda tecnologica britannica, e includeva un elemento cruciale: la garanzia che il controllo dell’<span class="smallcaps">agi</span> non sarebbe finito nelle mani di una grossa corporation.</p>
			<p class="testo" id="p_0041">L’afflusso di denaro da parte di Google consentì a Hassabis di reclutare ancora più ricercatori di talento. Benché alcuni dipendenti non fossero entusiasti di «svendersi» a Google, molti altri erano euforici per i corposi aumenti di stipendio e le allettanti stock option che rendevano meno appetibile la concorrenza. Ora, invece di temere che Facebook o Amazon gli portassero via il personale, Hassabis poteva fare il contrario: reclutare <em class="calibre3">i loro</em> migliori talenti e attirare alcune delle menti più brillanti del mondo accademico con stipendi da capogiro. In ogni caso, guidando l’azienda verso lo sviluppo di tecnologie sempre più avanzate, Hassabis mantenne la cultura improntata alla segretezza di DeepMind. Il suo sito web, per esempio, rimase una semplice pagina bianca con al centro un logo circolare. Il laboratorio di <span class="smallcaps">ai</span> era così avvolto nel mistero che chiunque si candidasse per un lavoro presso la sede londinese non riceveva nemmeno l’indirizzo via e-mail: un rappresentante gli andava incontro alla stazione ferroviaria di King’s Cross e lo accompagnava a piedi fino all’ufficio.</p>
			<p class="testo" id="p_0042">«Nei colloqui di lavoro, i fondatori erano persuasivi, specie Suleyman», racconta un ex dirigente. «Era estremamente carismatico e trasmetteva l’idea che si trattasse dell’opportunità irripetibile di far parte di qualcosa destinato a cambiare il mondo.»</p>
			<p class="testo" id="p_0043">Accademici e funzionari pubblici con oltre dieci anni di carriera alle spalle, che avrebbero potuto facilmente accedere a ruoli ben retribuiti nel settore privato, uscivano dopo venti minuti di conversazione con Suleyman convinti di dover contribuire alla costruzione dell’<span class="smallcaps">agi</span>. «Spiegava che la rivoluzione si sarebbe basata su una matematica migliore», aggiunge l’ex dirigente. Hassabis e Suleyman sostenevano di assumere «i migliori matematici e fisici del mondo». E ora, in Google, avevano accesso ai supercomputer più avanzati e a un’enorme quantità di dati con cui addestrare i loro modelli di <span class="smallcaps">ai</span>.</p>
			<p class="testo" id="p_0044">Circa la metà dei nuovi assunti di DeepMind proveniva ormai dal mondo accademico, e non riusciva a credere alla propria fortuna. Schiacciati per anni tra gli schedari e costretti a mendicare fondi, si ritrovavano ora in uffici scintillanti, circondati da ristoranti cosmopoliti e giardini, con computer ultraveloci e risorse pressoché illimitate. La parte migliore? DeepMind faceva in modo che non sembrasse di lavorare per un colosso della pubblicità. Si conducevano ricerche in un’organizzazione scientifica prestigiosa, pubblicando articoli su riviste peer-reviewed come «Science» e «Nature» e affrontando alcune delle sfide più urgenti per il pianeta. Era il meglio di entrambi i mondi, se mai una cosa simile fosse stata possibile.</p>
			<p class="testo" id="p_0045">Sul lungo termine, non lo era. Ma stipendi a sei cifre e benefit incredibili facevano dimenticare ai dipendenti di DeepMind quanto fosse strano essere pagati così generosamente da Google solo per rendere il mondo un posto migliore. A volte, però, questa incongruenza affiorava, come quando ex colleghi del polveroso mondo accademico o della pubblica amministrazione chiedevano di visitare gli uffici.</p>
			<p class="testo" id="p_0046">«Mi sentivo in imbarazzo», confessa un ex dipendente, passato a DeepMind dopo aver lasciato un incarico universitario. Quando i suoi ex colleghi gli domandavano di vedere il suo nuovo ufficio, cercava di dissuaderli, proponendo invece di incontrarli in un ristorante nei dintorni. Anche quello sarebbe stato un ambiente più sobrio rispetto alla mensa di DeepMind, che offriva buffet degni di un cinque stelle a Dubai. «Sembrava un mondo a parte», aggiunge. «Era davvero assurdo.»</p>
			<p class="testo" id="p_0047">I ricercatori erano serviti e riveriti come rockstar. Un giorno, uno di loro scrisse al servizio di supporto interno – utilizzato in genere per rimborsi spese o richieste di visto – suggerendo che sarebbe stato più efficiente servire tutte le fragole già private delle foglioline. Due giorni dopo, al buffet comparvero ciotole di fragole pulite alla perfezione.</p>
			<p class="testo" id="p_0048">La visione dietro la costruzione dell’<span class="smallcaps">agi</span> veniva costantemente riproposta ai dipendenti, e Hassabis andava ripetendo che, al ritmo con cui progredivano, l’obiettivo finale distava ormai solo cinque anni. A detta di chi lavorava in DeepMind, Hassabis era un maestro nel dipingere una visione ispirata sul futuro dell’azienda. Durante i ritiri aziendali, lui e Suleyman tenevano presentazioni che somigliavano più a comizi motivazionali che a spiegazioni dettagliate di piani operativi. I fondatori, infatti, spesso evitavano di scendere nei dettagli sulle strategie adottate.</p>
			<p class="testo" id="p_0049">«Era tutto molto orientato alla visione, alla missione da compiere», racconta un ex dipendente. «Demis e Mustafa erano affabulatori straordinari. Si bilanciavano incredibilmente bene.» Hassabis era la mente, l’uomo che leggeva articoli scientifici fino a notte fonda, che discuteva per ore di metodologie con i suoi ricercatori di punta e tendeva a evitare il personale di rango inferiore che non aveva un dottorato. Era stato lui a plasmare la cultura profondamente gerarchica di DeepMind, basata in gran parte sul prestigio accademico. Suleyman, invece, era il visionario carismatico, capace di delineare il futuro per cui tutti stavano lavorando. Un ex membro del team lo descrive come il pifferaio magico di DeepMind. Shane Legg, il più accademico del trio, si teneva più sullo sfondo. «Shane era il più taciturno», osserva l’ex dipendente.</p>
			<p class="testo" id="p_0050">Hassabis credeva così fermamente nel potere trasformativo dell’<span class="smallcaps">agi</span> da ripetere ai dipendenti di DeepMind che, nel giro di cinque anni, non avrebbero più dovuto preoccuparsi del denaro, perché l’<span class="smallcaps">agi</span> avrebbe reso l’economia obsoleta. Questa divenne presto la convinzione dei vertici. «Avevano bevuto il loro stesso Kool-Aid», commenta un ex dirigente. Erano convinti di essere sul punto di creare la tecnologia più importante che l’umanità avesse mai conosciuto.</p>
			<p class="testo" id="p_0051">Dietro le quinte, consapevoli della necessità di una salvaguardia, Hassabis e soprattutto Suleyman stavano istituendo il comitato etico e di sicurezza che Google aveva accettato come condizione per acquisire DeepMind. Google aveva l’obbligo fiduciario verso gli azionisti di aumentare i propri profitti ogni anno, cosa che continuava a fare con successo. Questo garantiva a DeepMind i talenti e le risorse computazionali che servivano, ma rappresentava un’arma a doppio taglio. Una volta creata l’<span class="smallcaps">agi</span>, infatti, Google avrebbe quasi certamente cercato di monetizzarla e controllarla. Non sapevano ancora come, di preciso, ma il comitato avrebbe almeno garantito che la super <span class="smallcaps">ai</span> non fosse utilizzata in modo improprio.</p>
			<p class="testo" id="p_0052">Circa un anno dopo l’acquisizione, DeepMind convocò la prima riunione del comitato etico e di sicurezza in una sala conferenze presso la sede di SpaceX, in California. Del comitato facevano parte Hassabis, Suleyman e Legg, così come Elon Musk e Reid Hoffman, il miliardario cofondatore di LinkedIn diventato investitore di venture capital. Tra gli altri presenti, secondo fonti informate, c’erano Larry Page, il dirigente di Google Sundar Pichai, il capo legale di Google Kent Walker, il consigliere postdottorato di Hassabis Peter Dayan e il filosofo della Oxford University Toby Ord.</p>
			<p class="testo" id="p_0053">La riunione andò bene, ma poi i fondatori ricevettero notizie sorprendenti da parte di Google: l’azienda non aveva più intenzione di proseguire con il comitato etico. Suleyman si arrabbiò, dal momento che era stato lui a spingere per la sua istituzione. Parte della spiegazione di Google, in quel momento, era che alcuni membri chiave del comitato avevano conflitti di interesse – Musk, per esempio, stava sostenendo progetti di <span class="smallcaps">ai</span> al di fuori di DeepMind – e istituire un comitato non era legalmente fattibile. A molti dei membri del comitato stesso la spiegazione suonò come una scusa. Il sospetto era che, in realtà, a Google non piacesse l’idea di trovarsi alla mercé di un gruppo di persone che potevano sottrarle il controllo di una tecnologia redditizia come quella dell’<span class="smallcaps">ai</span>.</p>
			<p class="testo" id="p_0054">Infuriati per quella che sembrava una violazione dell’accordo da parte di Google, Hassabis e Suleyman si lamentarono con i vertici aziendali per lo scioglimento del comitato. Desiderosi di mantenere i fondatori di DeepMind motivati a spingere i confini della ricerca sull’<span class="smallcaps">ai</span>, i dirigenti posero loro davanti una ricompensa ancora più grande. Un alto dirigente di Google li contattò spiegando che forse c’era una struttura migliore per proteggere la loro tecnologia <span class="smallcaps">agi</span>. I fondatori di DeepMind non lo sapevano, all’epoca, ma Google si stava preparando a trasformarsi in un conglomerato denominato Alphabet, cosa che avrebbe permesso alle diverse divisioni aziendali di operare con maggiore indipendenza. Il dirigente disse loro che queste nuove divisioni sarebbero state chiamate «unità autonome». Sarebbe stato come tornare a essere un’azienda indipendente. Avrebbero avuto i loro budget, i loro bilanci, i loro consigli di amministrazione e anche investitori esterni. L’idea sembrava allettante.</p>
			<hr class="salto"/>
			<p class="testo" id="p_0055">In realtà, il vero obiettivo di Google era far salire il suo valore azionario, che ristagnava da tempo. Per anni, gli analisti di Wall Street avevano faticato a valutare l’insieme delle attività di Google al di fuori di YouTube, Android e del suo redditizio motore di ricerca. Tra queste attività, per esempio, c’era un’azienda di termostati intelligenti chiamata Nest, una società di ricerca biotecnologica di nome Calico, una divisione di venture capital e l’X Lab dedicato ai progetti «moonshot». La maggior parte di queste divisioni non generava profitti, ma trasformarle in aziende separate sotto il cappello di un’unica holding avrebbe potuto alleggerire il bilancio complessivo e contribuire a valorizzare ciò che più interessava a Google: la pubblicità. L’attività pubblicitaria di Google rappresentava più del 90 per cento del fatturato annuo. Nonostante la reputazione di azienda tecnologica innovativa e popolata dai migliori ingegneri sulla piazza, la leadership di Google si concentrava ancora principalmente sul più tradizionale dei business: convincere la gente a comprare cose di cui non aveva necessariamente bisogno.</p>
			<p class="testo" id="p_0056">Focalizzati com’erano sulla realizzazione dell’<span class="smallcaps">agi</span>, Hassabis, Legg e Suleyman ebbero a stento modo di ponderare le vere motivazioni di Google, o il fatto che probabilmente l’azienda non aveva alcuna intenzione di concedere loro una reale autonomia, visto che la loro ricerca sull’<span class="smallcaps">ai</span> poteva rivelarsi oltremodo utile per far crescere il suo business. L’idea di diventare più indipendenti era semplicemente musica per le loro orecchie, perché significava che Google non avrebbe controllato la loro futura <span class="smallcaps">ai</span>, lasciandoli liberi di guidarne gli sviluppi. «Volevamo abbastanza indipendenza per poter affrontare ciò che sarebbe potuto accadere con l’avvento di un’<span class="smallcaps">agi</span> molto potente», ricorda Legg. «Volevamo assicurarci di avere un controllo sufficiente su come si sarebbero sviluppate le cose.»</p>
			<p class="testo" id="p_0057">I fondatori trascorsero l’anno e mezzo successivo a discutere con Page e altri dirigenti su come sarebbe stata la loro esistenza sotto questo nuovo ombrello aziendale e su cosa significasse effettivamente «unità autonoma». Ma poi, quando Google annunciò la ristrutturazione sotto il nome di Alphabet, non confermò alcun piano mirato a dare a DeepMind maggiore autonomia legale. Mentre altre scommesse di Google, come Verily Life Sciences, venivano trasformate in aziende indipendenti, non si registrò alcun progresso in tal senso per DeepMind. Fu come se Google si fosse dimenticata, ancora una volta, degli impegni presi.</p>
			<p class="testo" id="p_0058">Ma Hassabis non aveva tempo per soffermarsi sul modo in cui Google sembrava continuare a raggirarlo. All’orizzonte, infatti, si profilava una questione ben più preoccupante. A San Francisco, alcuni fondatori di start-up stavano organizzando un altro laboratorio di ricerca con lo stesso obiettivo di DeepMind. L’idea che promuovevano era di costruire un’<span class="smallcaps">agi</span> in modo sicuro e a beneficio dell’umanità. Il sottotesto era un po’ una stoccata, poiché implicava che l’altro importante tentativo di realizzare un’<span class="smallcaps">agi</span> – vale a dire, il suo – andasse a beneficio esclusivo di Google. E l’aspetto peggiore era il fatto che questa nuova organizzazione, chiamata Open<span class="smallcaps">ai</span>, era stata fondata da un suo ex investitore: Elon Musk.</p>
		</section>
	</body>
</html>
