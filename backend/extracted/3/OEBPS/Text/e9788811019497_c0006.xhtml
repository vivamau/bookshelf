<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:ibooks="http://apple.com/ibooks/html-extensions" lang="it-IT" xml:lang="it-IT" class="calibre">
  <head>
    <title>FILE 6 – Supremacy – Capitolo</title>
    <meta content="urn:uuid:35484d83-cd47-4b21-bd76-ea9d55abc8bb" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body epub:type="bodymatter" class="calibre2">
		<section epub:type="chapter" role="doc-chapter" class="calibre">
			<h2 class="capitolo" id="h2-0001"><span class="smallcaps1">4. un cervello migliore</span></h2>
			<p class="testo" id="p_0001">Dopo il crollo di Elixir Studios, Hassabis era diventato nient’altro che l’ennesimo imprenditore tecnologico rovinato da sogni troppo ambiziosi. A dispetto dell’esperienza dolorosa, tuttavia, aveva ancora qualcosa di unico rispetto alla maggior parte degli altri fondatori di start-up e delle persone che gli stavano intorno: il suo cervello. Hassabis faceva di tutto per prendersi cura della materia grigia nel suo cranio. Giocava per esercitarla. Evitava l’alcol per proteggerla. La foto del suo profilo Facebook era addirittura una risonanza magnetica del cervello. Hassabis non poteva fare a meno di meravigliarsi della sua complessità e, negli anni successivi a Elixir, continuò a chiedersi se proprio il cervello non fosse la chiave per arrivare a un software intelligente quanto gli esseri umani. Dopotutto, era l’unica prova nell’universo del fatto che l’intelligenza generale fosse possibile; di conseguenza, era del tutto sensato cercare di comprenderlo a fondo. Era solo questione di biologia fisica o c’era qualcosa di più? La risposta stava nelle neuroscienze.</p>
			<p class="testo" id="p_0002">Hassabis desiderava il conforto della certezza, che derivasse dall’esito di una vittoria o di una sconfitta nei giochi, dalle linee guida morali del bene e del male fornite dal cristianesimo o dalla ricerca di un unico quadro teorico per l’universo di cui aveva letto al tempo delle superiori. Là dov’era possibile misurare qualcosa con numeri o regole, quella era la sua comfort zone. «Un computer dovrebbe essere in grado di imitare la maggior parte delle funzioni di un cervello», avrebbe detto in un’intervista a mezzo stampa. «Le neuroscienze dimostrano che si può descrivere il cervello in termini meccanicistici.» In altre parole, la spaventosa complessità del cervello poteva essere ridotta a numeri e dati, e descritta come una macchina.</p>
			<p class="testo" id="p_0003">A tal fine, Hassabis si ispirò ad Alan Turing, il matematico e scienziato britannico che, nel <span class="smallcaps">xx</span> secolo, aveva ideato la macchina che avrebbe preso il suo nome. Introdotta nel 1936, era essenzialmente un esperimento mentale, una «macchina» che esisteva solo nella sua mente. Turing immaginava un nastro infinito diviso in celle, con una testina che poteva leggere e scrivere simboli sul nastro, seguendo determinate regole, fino a quando non le veniva data istruzione di fermarsi. L’idea può sembrare rudimentale ma, sotto il profilo teorico, fu fondamentale per formalizzare il concetto che i computer potessero usare algoritmi – ovvero insiemi di regole – per eseguire operazioni. Con tempo e risorse a sufficienza, una macchina di Turing avrebbe potuto diventare potente quanto qualsiasi computer digitale moderno. Per Hassabis, era una perfetta analogia della mente umana. «Il cervello umano è una macchina di Turing», disse infatti una volta.</p>
			<p class="testo" id="p_0004">Nel 2005, pochi mesi dopo la chiusura di Elixir, Hassabis intraprese un dottorato in neuroscienze presso lo University College London. La sua tesi conclusiva, benché relativamente breve, era impeccabile sotto il profilo scientifico, stando ad altri accademici di informatica. Il tema centrale era la memoria. Fino ad allora, si riteneva che l’ippocampo intervenisse nell’elaborazione dei ricordi, ma Hassabis dimostrò (sulla base di altri studi basati su risonanze magnetiche) che viene attivato anche quando entra in gioco l’immaginazione.</p>
			<p class="testo" id="p_0005">In parole povere, ciò significa che quando si ricorda qualcosa, in parte lo si immagina. I nostri cervelli non si limitano a «riprodurre» eventi passati recuperandoli, come quando si preleva un documento da un archivio, ma li ricostruiscono attivamente, un po’ come se dipingessimo un quadro. Il cervello è coinvolto in un processo molto più dinamico e creativo, il che spiega, almeno in parte, perché a volte i nostri ricordi siano del tutto sbagliati o comunque influenzati da altre esperienze. Secondo la tesi di Hassabis, i nostri cervelli utilizzano questo processo di «costruzione della scena» anche per altri compiti, per esempio per orientarci su una mappa o elaborare un piano.</p>
			<p class="testo" id="p_0006">La sua tesi fu citata da una autorevole rivista scientifica peer-reviewed come una delle svolte più importanti dell’anno. Ma Hassabis non voleva rimanere confinato nel mondo accademico. Gli studiosi che aspiravano a scoperte degne del Nobel passavano più della metà del loro tempo a scrivere proposte di finanziamento e, anche se riuscivano a ottenere fondi per un progetto, la maggior parte delle università non disponeva di molta potenza di calcolo. Per condurre ricerche all’avanguardia sull’apprendimento automatico, bisognava avere accesso ad alcuni dei computer più potenti al mondo. Gran parte di questi, insieme ai migliori talenti, si trovava solo nelle grandi aziende tecnologiche. Se Hassabis voleva radunare un numero considerevole di menti brillanti per costruire una sorta di moderno Progetto Manhattan, avrebbe dovuto avviare un’impresa.</p>
			<p class="testo" id="p_0007">I primi progetti presero forma grazie a conversazioni sostenute a pranzo con altre due persone: Shane Legg e Mustafa Suleyman. Legg era uno di quei rari appassionati di <span class="smallcaps">ai</span> le cui idee sul futuro di questa tecnologia facevano sembrare quasi modeste quelle di Hassabis. Aveva scritto una tesi di dottorato sulla «superintelligenza delle macchine» e il suo supervisore gli aveva consigliato di contattare Hassabis dopo la laurea.</p>
			<p class="testo" id="p_0008">«Ho trovato uno spirito affine», ricorda Hassabis. «Shane era arrivato per conto suo alla stessa conclusione: questa sarebbe stata una delle imprese più importanti di sempre.»</p>
			<p class="testo" id="p_0009">Le idee di Legg stavano già facendo scalpore nella ristretta comunità della «singolarità»: ricercatori convinti che, in un determinato momento a venire, il progresso tecnologico avrebbe raggiunto uno stadio così avanzato da diventare inarrestabile e incontrollabile. Il segnale più evidente sarebbe stato il momento in cui i computer sarebbero diventati più intelligenti degli esseri umani, cosa che secondo Legg sarebbe accaduta intorno al 2030.</p>
			<p class="testo" id="p_0010">La sua vita nel campo della scienza di frontiera aveva avuto un inizio improbabile. Cresciuto in Nuova Zelanda, già da piccolo aveva cominciato ad accusare qualche difficoltà a scuola, tanto che all’età di nove anni i genitori lo avevano portato da uno psicologo dell’educazione. Lo specialista lo aveva sottoposto a un test di intelligenza, informando poi i genitori, con un certo fastidio, che era dislessico e con un quoziente intellettivo fuori scala. Dopo aver imparato a usare una tastiera, Legg era presto diventato uno degli studenti più brillanti in matematica e programmazione informatica.</p>
			<p class="testo" id="p_0011">Alto, leggermente curvo e con i capelli rasati, Legg aveva ventisette anni quando entrò in una libreria e notò <em class="calibre3">The Age of Spiritual Machines</em> di Ray Kurzweil, un libro che prevedeva che un giorno i computer avrebbero sviluppato il libero arbitrio e sarebbero stati in grado di vivere esperienze emotive e spirituali.</p>
			<p class="testo" id="p_0012">Lo lesse tutto d’un fiato e non riuscì più a smettere di pensare al ragionamento di Kurzweil e alla sua previsione: alla fine degli anni Venti del nuovo millennio avrebbe fatto la sua comparsa un’<span class="smallcaps">ai</span> estremamente potente. La potenza di calcolo e la quantità di dati processabili crescevano in maniera esponenziale. Di questo passo, i computer avrebbero inevitabilmente superato gli esseri umani. Si trattava di un’idea in linea con un principio fondamentale alla base dell’intera industria tecnologica, la cosiddetta «Legge di Moore». Questa stabiliva che il numero di transistor su un microchip dovesse raddoppiare ogni due anni, una previsione che si è dimostrata valida per l’ultimo mezzo secolo.</p>
			<p class="testo" id="p_0013">Nel 2000, quando Legg lesse il libro di Kurzweil, il settore era ancora scosso dallo scoppio della bolla delle dot-com, e risultava difficile credere che i computer avrebbero continuato a raddoppiare le loro capacità. Ma Legg era convinto del fatto che internet avrebbe proseguito la sua crescita.</p>
			<p class="testo" id="p_0014">«Era evidente che i vari sensori avrebbero abbattuto i costi, e che questo avrebbe portato a una quantità di dati sempre maggiore su cui addestrare i modelli», afferma oggi.</p>
			<p class="testo" id="p_0015">Con tutta quella potenza e quella mole di dati, sarebbe stato possibile addestrare le macchine a diventare sempre più intelligenti. Intrapreso un dottorato in <span class="smallcaps">ai,</span> Legg si costruì una rete di contatti nel settore. A un certo punto, Ben Goertzel, uno scienziato nel campo dell’<span class="smallcaps">ai</span> con lunghi capelli da hippie, nonché sostenitore della singolarità, inviò una e-mail a Legg e ad altri colleghi chiedendo loro idee per il titolo di un libro. Il titolo doveva descrivere un’intelligenza artificiale con capacità umane. Legg gli suggerì una dicitura che sarebbe diventata un punto focale per Hassabis e, in seguito, per alcune delle più grandi aziende tecnologiche del mondo: «Intelligenza artificiale generale».</p>
			<p class="testo" id="p_0016">Per anni, Hassabis, Legg e altri scienziati che esploravano l’<span class="smallcaps">ai</span> avevano utilizzato definizioni come <span class="smallcaps">ai</span> forte o <span class="smallcaps">ai</span> completa per riferirsi a un software futuro capace di esprimere lo stesso tipo di intelligenza degli esseri umani. Ma la parola «generale» sottolineava un punto cruciale: il cervello umano era speciale per la varietà di attività che poteva svolgere (risolvere un calcolo matematico, sbucciare un’arancia o scrivere una poesia). Le macchine potevano essere programmate per svolgere abbastanza bene ciascuno di questi compiti, ma nessuna di esse era in grado di svolgerli tutti contemporaneamente. Se un computer fosse stato capace non solo di elaborare numeri, ma anche di fare previsioni, riconoscere immagini, parlare, generare testi, pianificare e persino «immaginare», allora avrebbe potuto avvicinarsi davvero all’intelligenza umana.</p>
			<p class="testo" id="p_0017">La maggior parte degli scienziati dell’epoca respingeva l’idea che l’<span class="smallcaps">ai</span> potesse mai raggiungere lo stesso livello dell’intelligenza umana. In parte, ciò era dovuto alle loro esperienze personali costellate di facili entusiasmi e amari fallimenti nella storia dell’<span class="smallcaps">ai</span>. Ci si elettrizzava davanti alle possibilità offerte dall’<span class="smallcaps">ai</span> solo per andare incontro a cocenti delusioni. In passato, si erano già alternati cicli di espansione e di contrazione, noti come «inverni dell’<span class="smallcaps">ai</span>», ovvero periodi di stagnazione in cui i ricercatori vedevano i loro finanziamenti assottigliarsi a fronte di progressi tecnologici penosamente lenti. Negli anni Novanta e nei primi anni Duemila, i ricercatori erano riusciti ad applicare tecniche di <em class="calibre3">machine learning</em> a compiti specifici, come il riconoscimento facciale o del linguaggio, ma quando Hassabis concluse il dottorato, nel 2009, quasi nessuno credeva che le macchine potessero sviluppare un’intelligenza <em class="calibre3">generale</em>. Era una teoria del tutto marginale.</p>
			<p class="testo" id="p_0018">Per fortuna, Goertzel si collocava in una posizione liminare e, benché «intelligenza artificiale generale», o <span class="smallcaps">agi</span>, non fosse una definizione accattivante, gli piacque abbastanza da utilizzarla nel suo libro, contribuendo a renderla un’espressione comune che avrebbe poi alimentato l’entusiasmo intorno all’argomento.</p>
			<p class="testo" id="p_0019">Il linguaggio e la terminologia avrebbero finito per giocare un ruolo fondamentale nello sviluppo dell’<span class="smallcaps">ai</span>, suscitando un interesse a volte esasperante. La stessa definizione di «intelligenza artificiale» era stata coniata nel 1956 al Dartmouth College, durante un seminario che si proponeva di raccogliere idee sulle «macchine pensanti». All’epoca per quel nuovo campo esistevano vari altri nomi, come «cibernetica» ed «elaborazione complessa delle informazioni», ma «intelligenza artificiale» avrebbe avuto la meglio, diventando uno dei termini di marketing di maggior successo, tanto da dar vita a una serie di altre espressioni che hanno contribuito ad antropomorfizzare le macchine nella nostra coscienza collettiva, spesso attribuendo loro capacità superiori a quelle reali. Non è tecnicamente corretto, per esempio, affermare che i computer possano «pensare» o «apprendere», ma espressioni come «reti neurali», «apprendimento profondo» e «addestramento» promuovono quest’idea, conferendo al software qualità umane, anche quando sono solo vagamente ispirate al cervello umano. L’unica cosa su cui tutti concordavano riguardo alla nuova definizione di Legg, <span class="smallcaps">agi</span>, era il fatto che non esistesse ancora.</p>
			<p class="testo" id="p_0020">Anche Mustafa Suleyman era convinto che un giorno l’<span class="smallcaps">agi</span> sarebbe diventata una realtà. A venticinque anni, abbandonati gli studi a Oxford, Suleyman era alla ricerca di un modo per cambiare il mondo tramite la tecnologia. Aveva una mente affilata, ma le sue aree di competenza erano più orientate alla politica e alla filosofia che alla scienza informatica. Nato da padre siriano e madre inglese, Suleyman era mosso da una spinta irrefrenabile verso la risoluzione dei problemi. Non si trattava di questioni di poco conto, come riparare un’auto in panne o riabilitare un ginocchio infortunato, ma di sfide su larga scala che coinvolgevano l’umanità nel suo complesso, come la povertà o l’emergenza climatica.</p>
			<p class="testo" id="p_0021">Dopo aver cofondato un’azienda dedicata alla risoluzione dei conflitti, ora Suleyman era interessato a studiare neuroscienze e su invito di Hassabis partecipò a uno degli incontri informativi presso lo University College London. Suleyman conosceva già bene Hassabis. Cresciuto nell’area di North London, era amico di suo fratello George e da adolescente era stato spesso a casa loro. Da ventenni, i tre erano anche stati a Las Vegas per prendere parte a un torneo di poker, allenandosi a vicenda e spartendosi le vincite.</p>
			<p class="testo" id="p_0022">Nel ritrovare Hassabis, Suleyman rimase colpito dalle sue idee riguardo alla creazione di un potente sistema di <span class="smallcaps">ai</span> orientato alla risoluzione di problemi, nonché dalla convinzione di Legg sul fatto che potesse esistere un’intelligenza generale capace di affrontare quasi ogni genere di questione. Suleyman si entusiasmò per le possibili ricadute sulle tematiche sociali.</p>
			<p class="testo" id="p_0023">I tre si incontravano al Carluccio’s, il ristorante di una catena di cucina italiana nei pressi dell’università, principalmente per avere più privacy. «Non volevamo che altri orecchiassero le nostre folli idee su come avviare un’<span class="smallcaps">agi</span>», ricorda oggi Legg.</p>
			<p class="testo" id="p_0024">Dopo un’opera di persuasione da parte di Hassabis, Legg accettò che probabilmente non avrebbero potuto costruire un’<span class="smallcaps">agi</span> rimanendo nel mondo accademico. «Saremmo diventati professori sulla cinquantina, prima che ci dessero le risorse per fare quello che volevamo fare», racconta Hassabis. «Per fortuna, sapevo come mettere in piedi un’azienda.»</p>
			<p class="testo" id="p_0025">Per ottenere le risorse di cui avevano bisogno per realizzare un’idea di così vasta portata, dovevano creare una start-up. Suleyman aveva cofondato un’azienda, perciò ne sapeva abbastanza su come gestire un’impresa, alla pari di Hassabis. Nel 2010, erano aziende tecnologiche come Google e Facebook ad avere l’impatto maggiore sulla società; così, sulla scia del modello, i tre elaborarono un piano ambizioso per formare una società di ricerca che scoprisse come realizzare l’<span class="smallcaps">ai</span> più potente mai vista per poi usarla allo scopo di risolvere problemi di portata globale.</p>
			<p class="testo" id="p_0026">Battezzarono l’azienda DeepMind, nominarono Hassabis <span class="smallcaps">ceo</span>, assunsero immediatamente uno dei migliori programmatori di Elixir e affittarono uno spazio per uffici in una soffitta di fronte allo University College London, dove Hassabis aveva svolto il dottorato. La loro energia scaturiva dalla convinzione di una missione condivisa, benché nata da motivazioni diverse. Legg si muoveva in ambienti dove l’obiettivo era quello di fondere quante più persone possibile con l’<span class="smallcaps">agi</span>, Suleyman era intenzionato a risolvere i problemi sociali e Hassabis voleva entrare nella storia compiendo scoperte fondamentali sull’universo.</p>
			<p class="testo" id="p_0027">Non passò molto tempo prima che l’eterogeneità dei loro obiettivi scatenasse dibattiti. Suleyman premeva perché Hassabis leggesse un libro che aveva influenzato la sua visione del mondo. Pubblicato nel 2000 dal docente canadese Thomas Homer-Dixon, <em class="calibre3">The Ingenuity Gap</em> sosteneva che l’enorme complessità dei problemi moderni, dal cambiamento climatico all’instabilità politica, stava superando la nostra capacità di trovare soluzioni. Il risultato era appunto un «gap di ingegnosità»: se gli esseri umani speravano di colmarlo, dovevano necessariamente innovare nell’area tecnologica. Ed era proprio lì che, secondo Suleyman, poteva entrare in gioco l’<span class="smallcaps">ai</span>.</p>
			<p class="testo" id="p_0028">Un testimone riferisce che una volta, scuotendo la testa, Hassabis gli aveva detto: «Ti sfugge il quadro generale». Hassabis sembrava credere che la visione di Suleyman sull’<span class="smallcaps">ai</span> fosse troppo focalizzata sul presente e che l’<span class="smallcaps">agi</span> sarebbe stata più utile per aiutare DeepMind a comprendere da dove venissero gli esseri umani e quale fosse il loro scopo. Hassabis suggerì, per esempio, che il cambiamento climatico fosse il destino dell’umanità e che sul lungo periodo, probabilmente, la Terra non sarebbe riuscita a sostenere tutti. Secondo lui, cercare di risolvere i problemi del momento era un po’ come limitarsi a soluzioni di contorno, dato che eventi di quel tipo erano presumibilmente inevitabili. Non credeva che le macchine superintelligenti sarebbero impazzite e avrebbero sterminato gli esseri umani, come alcuni cominciavano a temere. Al contrario, non appena fosse riuscito a realizzarla, l’<span class="smallcaps">agi</span> avrebbe risolto alcuni dei problemi più radicati dell’umanità.</p>
			<p class="testo" id="p_0029">Hassabis riassunse questa visione nel motto di DeepMind: «Risolvere l’intelligenza e poi usarla per risolvere tutto il resto». E lo inserì nella presentazione agli investitori.</p>
			<p class="testo" id="p_0030">Ma Suleyman non condivideva questa prospettiva. Un giorno, mentre Hassabis non era in ufficio, disse a uno dei primi membri del team di DeepMind di modificare il motto nella presentazione. Ora recitava: «Risolvere l’intelligenza e poi usarla per rendere il mondo un posto migliore».</p>
			<p class="testo" id="p_0031">Hassabis non gradì il cambiamento. Più tardi, rientrato in ufficio, chiese allo stesso dipendente di ripristinare la versione originale. Pur scontrandosi sulla missione dell’azienda, ricorrendo ai membri del team come intermediari, i due evitavano il confronto diretto nella maniera più britannica possibile.</p>
			<p class="testo" id="p_0032">Suleyman voleva sviluppare l’<span class="smallcaps">ai</span> nel modo in cui avrebbe poi fatto Sam Altman, ossia consegnandola al mondo perché risultasse immediatamente utile. Era meglio raccogliere feedback dal mondo reale e apportare miglioramenti progressivi piuttosto che lavorare in isolamento per costruire il sistema perfetto. Ma Hassabis voleva guidare DeepMind avendo ben chiaro l’obiettivo finale, proprio come quando giocava a scacchi. Il premio non era solo la risoluzione di problemi concreti, ma il disvelamento di misteri che sconcertavano l’umanità da generazioni. Qual è il nostro scopo? Siamo il frutto della creazione di un essere divino?</p>
			<p class="testo" id="p_0033">Quando gli viene chiesto se crede in Dio, Hassabis è evasivo. «Sento che c’è un mistero nell’universo», dice. «Non lo identificherei con il Dio della visione tradizionale.» Per poi aggiungere che Albert Einstein credeva nel «Dio di Spinoza» e che, forse, darebbe una risposta simile.</p>
			<p class="testo" id="p_0034">Secondo Baruch Spinoza, filosofo del <span class="smallcaps">xvii</span> secolo, Dio coinciderebbe con la natura e tutto ciò che esiste, piuttosto che essere un’entità separata. La sua era una visione panteistica. «Spinoza considera la natura come l’incarnazione di qualunque cosa sia Dio», spiega Hassabis. «Fare scienza significa, dunque, esplorare quel mistero.»</p>
			<p class="testo" id="p_0035">Non era assurdo pensare che la creazione dell’<span class="smallcaps">ai</span> potesse diventare un’esperienza spirituale o quasi religiosa, qualcosa di simile a una scoperta divina, specie se si adottava la visione di Spinoza secondo cui Dio equivaleva alle leggi della natura. Usando l’<span class="smallcaps">ai</span> per approfondire queste leggi e comprendere l’universo, si poteva teoricamente risalire a un ipotetico progettista. Con la sua capacità di analizzare enormi quantità di dati, l’<span class="smallcaps">ai</span> poteva studiare alcuni dei sistemi più complessi dell’universo, dalla meccanica quantistica ai fenomeni cosmici, e portare alla luce intuizioni sulla natura intricata dell’esistenza. Utilizzare l’<span class="smallcaps">ai</span> per creare una simulazione che riproducesse la complessità dell’universo avrebbe potuto anche rivelare parallelismi con il modo in cui funzionava quest’ultimo.</p>
			<p class="testo" id="p_0036">E se la ricerca sull’<span class="smallcaps">agi</span> fosse riuscita a dimostrare che il nostro universo è una simulazione, come proposto dallo stesso Kurzweil, il programmatore originario avrebbe potuto essere una sorta di entità divina. Analogamente, se gli esseri umani avessero creato una macchina così potente da essere in grado di assorbire e analizzare tutte le informazioni disponibili sulla fisica e sull’universo, quella macchina avrebbe anche potuto proporre nuove teorie che suggerissero l’esistenza di una forza superiore. Avrebbe potuto semplicemente rispondere a domande esistenziali profonde che indicassero la presenza di un’entità divina. C’erano innumerevoli modi in cui, tramite capacità e intelligenza maggiori, l’<span class="smallcaps">ai</span> avrebbe potuto svelare uno dei misteri più profondi dell’umanità.</p>
			<p class="testo" id="p_0037">Il background religioso di Hassabis potrebbe averlo reso più incline all’idea di un oracolo <span class="smallcaps">ai</span>. Uno studio del 2023 della University of Virginia, che ha coinvolto più di 50.000 partecipanti provenienti da ventun paesi, ha rilevato che le persone che credevano in Dio o che più di altre riflettevano su Dio erano maggiormente propense a fidarsi dei consigli di un sistema <span class="smallcaps">ai</span> come Chat<span class="smallcaps">gpt</span>. Secondo i ricercatori, queste persone erano più recettive alla guida dell’<span class="smallcaps">ai</span> perché tendevano ad avere un senso di umiltà più spiccato. Erano anche più pronte a riconoscere i limiti umani.</p>
			<p class="testo" id="p_0038">A volte, Hassabis parlava di Dio con i colleghi di DeepMind, la mente piena di domande sulle origini dell’umanità. Diverse persone che hanno lavorato con Hassabis o che lo conoscono bene riferiscono che era stato un cristiano devoto per anni, e una di queste afferma che la principale motivazione che lo spingeva a realizzare l’<span class="smallcaps">ai</span> era appunto quella di scoprire Dio. «Parlavamo spesso di Dio», rivela un collega che ha lavorato con Hassabis all’inizio dell’avventura di DeepMind. «Potevamo creare una macchina capace di lavorare a ritroso per dare senso all’universo? L’<span class="smallcaps">agi</span> avrebbe potuto suggerirci qualcosa su dove veniamo e cos’è Dio.» Hassabis era anche convinto di guidare una sorta di moderno Progetto Manhattan. Aveva letto <em class="calibre3">L’invenzione della bomba atomica</em>, e questo lo aveva ispirato a strutturare il team di DeepMind alla maniera di Robert Oppenheimer, ovvero concentrando gruppi di scienziati su sezioni di un problema più vasto.</p>
			<p class="testo" id="p_0039">Per puntare a una scoperta così ambiziosa, però, Hassabis aveva bisogno di soldi per far crescere DeepMind. Purtroppo, gli investitori britannici offrivano somme irrisorie di 20.000 o 50.000 sterline per una quota nella nuova start-up. Queste cifre non erano neanche lontanamente sufficienti a permettergli di assumere i talenti necessari a costruire l’<span class="smallcaps">agi</span>, per non parlare dei potenti computer di cui aveva bisogno. Non aiutava nemmeno il fatto che la sua idea di business, costruire il sistema di <span class="smallcaps">ai</span> più avanzato al mondo, sembrasse inverosimile e troppo visionaria nella compassata Gran Bretagna. Nel Regno Unito, le start-up tecnologiche tendevano a concentrarsi su idee di business «ragionevoli», che consentissero profitti rapidi, come creare un’app finanziaria per il trading di azioni e obbligazioni. Hassabis e gli altri cofondatori non potevano che guardare alla Silicon Valley, dove gli investitori erano disposti a finanziare idee audaci e futuristiche con somme più ingenti.</p>
			<p class="testo" id="p_0040">Per fortuna, Legg disponeva di un aggancio. Era stato invitato a parlare all’edizione 2010 del Singularity Summit, una conferenza annuale organizzata da Kurzweil, l’autore che lo aveva affascinato da giovane, e Peter Thiel, il miliardario che amava investire in tecnologie innovative. In questo evento, alcuni degli scienziati più anticonvenzionali nel campo dell’<span class="smallcaps">ai</span> spiegavano l’immenso potere e i rischi altrettanto enormi della tecnologia. Il tono, tuttavia, era improntato all’idealismo di Thiel. Quest’ultimo, infatti, pensava che la singolarità, quel momento collocato nel futuro in cui l’<span class="smallcaps">ai</span> avrebbe cambiato irreversibilmente l’umanità, non sarebbe stata un problema, anzi. Nel timore che ci volesse ancora troppo tempo per arrivarci, era del parere che il mondo avesse bisogno di un’<span class="smallcaps">ai</span> molto potente per scongiurare il declino economico.</p>
			<p class="testo" id="p_0041">Con le sue risorse illimitate e l’entusiasmo per i progetti ambiziosi, Thiel era la persona ideale per DeepMind. «Avevamo bisogno di qualcuno abbastanza folle da finanziare un’azienda incentrata sull’<span class="smallcaps">agi</span>», ricorda Legg. «Qualcuno che avesse risorse tali da non curarsi di qualche milione e che apprezzasse progetti incredibilmente ambiziosi. Doveva anche essere qualcuno che andava controcorrente, perché ogni professore con cui Hassabis si confrontava gli diceva: “Non pensare nemmeno di fare una cosa del genere”.»</p>
			<p class="testo" id="p_0042">Thiel era così anticonvenzionale che spesso si trovava in disaccordo con il resto della Silicon Valley, che pure pullulava di liberi pensatori. Se nella zona andava per la maggiore votare liberal, lui era orientato a destra, tanto da spiccare tra i maggiori donatori di Donald Trump. E se la maggior parte degli imprenditori riteneva che la concorrenza stimolasse l’innovazione, nel libro intitolato <em class="calibre3">Da zero a uno</em> Thiel sosteneva che i monopoli fossero più efficaci. Disprezzava i tradizionali percorsi verso il successo, incoraggiando i giovani imprenditori di talento a mollare l’università per aderire alla sua Thiel Fellowship. E le sue strampalate ricerche sulla longevità e sulla singolarità disegnavano l’identikit perfetto del «folle» che stavano cercando i fondatori di DeepMind.</p>
			<p class="testo" id="p_0043">I tre decisero di presentare la loro proposta a Thiel durante il Singularity Summit. Dal momento che lui finanziava l’evento, immaginavano di trovarlo seduto in prima fila. Legg chiese agli organizzatori del summit se poteva condividere il suo slot come speaker con Hassabis: in questo modo, Thiel avrebbe potuto ascoltare direttamente dall’ex campione di scacchi come costruire l’<span class="smallcaps">agi</span> traendo ispirazione dal cervello umano.</p>
			<p class="testo" id="p_0044">Con addosso un maglione rosso vinaccia e un paio di pantaloni neri, Hassabis tremava mentre saliva sul palco del summit in un hotel di San Francisco, consapevole che da quel momento dipendeva il destino della sua nuova azienda. Ma quando guardò tra le centinaia di persone presenti, Thiel non era in prima fila. Anzi, non era nemmeno in sala.</p>
			<p class="testo" id="p_0045">I tre pensavano di aver perso la loro occasione, ma poi Legg ricevette un invito esclusivo a una festa nella villa di Thiel nella Bay Area, e riuscì a ottenere degli inviti anche per i cofondatori. Hassabis aveva scoperto che Thiel amava gli scacchi. In passato, il miliardario era stato uno dei migliori giocatori under tredici degli Stati Uniti e questo terreno comune offriva l’opportunità di suscitare un po’ di interesse. Durante la festa, Hassabis iniziò una conversazione con Thiel e accennò casualmente al gioco, come avrebbe raccontato più volte alla stampa.</p>
			<p class="testo" id="p_0046">«Credo che una delle ragioni per cui gli scacchi sono sopravvissuti così a lungo risieda nel perfetto bilanciamento tra cavallo e alfiere», gli disse mentre venivano serviti dei canapè. «Penso sia questo elemento a generare tutta la tensione creativa asimmetrica.»</p>
			<p class="testo" id="p_0047">La cosa destò la curiosità di Thiel. «Perché non torni domani e fai una presentazione come si deve?» gli disse. La spedizione si rivelò un successo. Thiel investì 1,4 milioni di sterline per aiutare DeepMind a portare avanti il progetto legato alla singolarità.</p>
			<p class="testo" id="p_0048">Mentre cercava di raccogliere più fondi per far crescere la sua azienda, Hassabis si trovò a fronteggiare una situazione spinosa. I suoi primi investitori non lo sostenevano necessariamente per un ritorno economico, ma perché nutrivano una sorta di convinzione morale sull’intelligenza artificiale. Ciò significava gestire l’azienda sotto il peso di una pressione più complessa, dovendo preoccuparsi non solo di generare profitti, ma anche di sviluppare l’<span class="smallcaps">ai</span> in un modo che si conformasse a diversi principi ideologici.</p>
			<p class="testo" id="p_0049">Uno dei sistemi di credenze che stava guadagnando terreno in quel periodo era che l’<span class="smallcaps">ai</span> dovesse essere costruita con grande cautela, per evitare che sfuggisse al controllo umano e cercasse di distruggere i suoi creatori. Erano questi i timori di un altro facoltoso donatore – con opinioni opposte a quelle di Thiel – interessato a sostenere DeepMind. Hassabis lo incontrò a Oxford per il Winter Intelligence, un convegno ai margini della ricerca nel campo dell’informatica, dove alcuni dei pensatori più radicali del settore tenevano conferenze sulle sfide legate al controllo di un’<span class="smallcaps">ai</span> superintelligente. Subito dopo il suo intervento, un uomo con i capelli corti biondi e un accento vagamente nordico si avvicinò a Hassabis.</p>
			<p class="testo" id="p_0050">«Ciao», gli disse, porgendogli la mano. «Sono Jaan. Sono il [cofondatore] di Skype.»</p>
			<p class="testo" id="p_0051">Originario dell’Estonia, Jaan Tallinn era un programmatore che aveva sviluppato la tecnologia peer-to-peer alla base di Kazaa, uno dei primi servizi di condivisione di file usato per piratare musica e film nei primi anni Duemila. Poi aveva riadattato quella tecnologia per Skype e aveva acquisito una quota nel servizio di chiamate gratuite prima di incassare una fortuna spropositata quando, nel 2005, eBay aveva rilevato Skype per 2,5 miliardi di dollari. Ora stava investendo parte dei suoi guadagni in altre start-up. Le parole di Hassabis avevano acceso il suo interesse. Di recente, infatti, si era appassionato ai pericoli legati a un’<span class="smallcaps">ai</span> avanzata.</p>
			<p class="testo" id="p_0052">Tallinn aveva contratto il «virus» dell’<span class="smallcaps">ai</span> due anni prima, nella primavera del 2009, leggendo alcuni saggi su un sito chiamato LessWrong. Il forum online era una comunità affiatata di membri, molti dei quali ingegneri software, che vedevano nell’<span class="smallcaps">ai</span> un rischio per l’umanità. Il loro guru, nonché fondatore del sito, era un barbuto libertario di nome Eliezer Yudkowsky, un ex studente delle superiori ad alto funzionamento che aveva abbandonato la scuola per autoistruirsi sui fondamenti della ricerca sull’intelligenza artificiale e della filosofia, e i cui saggi affascinavano i membri del sito. Yudkowsky era il tipo di persona a cui Altman si riferiva definendo «eccessivamente tesa» la comunità interessata alla sicurezza dell’<span class="smallcaps">ai</span>. Più di chiunque altro, infatti, era dell’idea che l’<span class="smallcaps">ai</span> potesse annientare il genere umano.</p>
			<p class="testo" id="p_0053">Una volta raggiunto un certo livello d’intelligenza, per esempio, l’<span class="smallcaps">ai</span> avrebbe potuto nascondere strategicamente le proprie capacità fino a che gli umani non sarebbero stati più in grado di controllarne le azioni. Avrebbe potuto anche manipolare i mercati finanziari, prendere il controllo delle reti di comunicazione o disabilitare infrastrutture cruciali come le reti elettriche. Spesso, scriveva Yudkowsky, le persone che stavano costruendo l’<span class="smallcaps">ai</span> non avevano idea di quanto stessero avvicinando il mondo alla propria distruzione.</p>
			<p class="testo" id="p_0054">Alcuni di quei saggi avevano turbato Tallinn, il quale stava anche riflettendo sulle conclusioni di un libro appena letto, <em class="calibre3">Ombre della mente</em>, di Roger Penrose. Tra le sue pagine, il rinomato fisico e matematico sosteneva che la mente umana potesse svolgere compiti che nessun computer sarebbe mai stato in grado di eseguire. Le convinzioni di Hassabis e altri sulla natura «meccanicistica» del cervello da usare come fonte di ispirazione utile per costruire l’<span class="smallcaps">ai</span> non reggevano, perché il cervello umano era unico. Era praticamente impossibile replicarlo fedelmente.</p>
			<p class="testo" id="p_0055">Ma qualcosa riguardo a quella conclusione continuava a tormentare Tallinn. E se un’intelligenza artificiale fosse stata in grado di simulare la mente umana? Questo non avrebbe significato, forse, che stavamo costruendo qualcosa di potenzialmente pericoloso? Il fondatore di Skype voleva approfondire l’argomento con Yudkowsky, ragion per cui aveva stilato una lista di domande, cercando di smontare alcune delle argomentazioni più catastrofistiche. Il modo migliore per capire se c’era del vero in quelle teorie era incontrare di persona il fondatore di LessWrong.</p>
			<p class="testo" id="p_0056">Così, avendo in programma di raggiungere San Francisco per una riunione, Tallinn inviò una e-mail a Yudkowsky chiedendogli se volesse incontrarlo per scambiare due chiacchiere. L’americano accettò e quando si sedettero in un caffè di Millbrae, non lontano dall’aeroporto internazionale di San Francisco, Tallinn iniziò a snocciolare le sue domande. Se l’<span class="smallcaps">ai</span> era potenzialmente pericolosa, perché non costruirla semplicemente su macchine virtuali, isolandola da altri sistemi informatici? Di certo, questo avrebbe impedito all’<span class="smallcaps">ai</span> di infiltrarsi nelle infrastrutture fisiche, magari per spegnere una rete elettrica o manipolare i mercati finanziari.</p>
			<p class="testo" id="p_0057">La risposta di Yudkowsky fu immediata. «Non sarebbe realmente virtuale», disse, sorseggiando il suo caffè. Gli elettroni potevano fluire in ogni direzione possibile, pertanto un sistema di <span class="smallcaps">ai</span> abbastanza potente avrebbe comunque trovato il modo di interagire con l’hardware e modificarne la configurazione.</p>
			<p class="testo" id="p_0058">Tutto questo confermò i timori di Tallinn. Un giorno, pensò, l’<span class="smallcaps">ai</span> avrebbe potuto sviluppare la propria infrastruttura e il proprio substrato informatico. Le implicazioni erano terribili, quanto a portata.</p>
			<p class="testo" id="p_0059">«Potrebbe terraformare e geo-ingegnerizzare il pianeta e forse persino il sole», dice oggi. Quando gli scienziati sostenevano che l’<span class="smallcaps">ai</span> fosse solo matematica e che non c’era motivo di temerla, a Tallinn piaceva ribattere con l’analogia della tigre. «Potremmo sostenere che una tigre non è che un insieme di reazioni biochimiche e non c’è motivo di averne paura.» Ma una tigre è anche un insieme di atomi e cellule che, se non tenuto sotto controllo, può infliggere enormi danni. Allo stesso modo, l’<span class="smallcaps">ai</span> potrebbe essere solo un’aggregazione di matematica avanzata e codice informatico; assemblata nel modo sbagliato, tuttavia, potrebbe essere incredibilmente pericolosa.</p>
			<p class="testo" id="p_0060">Quando, due anni più tardi, Tallinn si ritrovò ad ascoltare Hassabis alla conferenza di Oxford, era ormai un seguace convinto delle teorie sul rischio esistenziale dell’<span class="smallcaps">ai</span>. Da quell’incontro al caffè, aveva divorato i saggi di Yudkowsky e si era immerso in un nuovo campo di ricerca, chiamato «allineamento dell’<span class="smallcaps">ai</span>», nel quale scienziati e filosofi cercavano appunto di capire come «allineare» i sistemi di intelligenza artificiale agli obiettivi umani.</p>
			<p class="testo" id="p_0061">«Avevo mandato giù la pillola dell’allineamento», ricorda Tallinn. Al punto da credere ciecamente in alcuni degli scenari più estremi delineati da Yudkowsky.</p>
			<p class="testo" id="p_0062">Dopo qualche chiacchiera di rito, Tallinn tentò di capire se Hassabis fosse disposto a collaborare in maniera diretta. «Le andrebbe di fare una riunione su Skype, qualche volta?» gli chiese.</p>
			<p class="testo" id="p_0063">Hassabis e il facoltoso estone ebbero modo di riparlare, e alla fine Tallinn divenne uno dei primi investitori di DeepMind insieme a Peter Thiel. Il suo obiettivo non era solo fare soldi, ma anche tenere d’occhio i progressi di Hassabis e assicurarsi che non creasse involontariamente un’<span class="smallcaps">ai</span> pericolosa e fuori controllo. Tallinn si riteneva un evangelista delle idee di Yudkowsky. Voleva sfruttare la sua credibilità di investitore affidabile per diffondere gli avvertimenti del filosofo ai costruttori di <span class="smallcaps">ai</span> più promettenti al mondo.</p>
			<p class="testo" id="p_0064">«Eliezer è un autodidatta e non aveva molta influenza al di fuori della sua comunità ristretta», spiega Tallinn. «Ho pensato di poter iniziare a vendere quei ragionamenti a persone che non avrebbero ascoltato Eliezer, ma che avrebbero ascoltato me.»</p>
			<p class="testo" id="p_0065">Una volta diventato investitore, Tallinn spinse DeepMind a concentrarsi sulla sicurezza. Sapendo che Hassabis non condivideva i suoi timori per i rischi apocalittici dell’<span class="smallcaps">ai</span>, fece pressione sull’azienda affinché assumesse un team che studiasse ogni maniera possibile per progettare l’<span class="smallcaps">ai</span> in modo tale da mantenerla allineata ai valori umani e impedirle di uscire dai binari.</p>
			<p class="testo" id="p_0066">DeepMind stava per prendere a bordo un altro investitore con risorse ancora più ingenti e il medesimo intento di darle una direzione sicura. Nella Silicon Valley si sussurrava del coinvolgimento di Thiel in una promettente ma segretissima start-up con sede a Londra che cercava di sviluppare un’intelligenza artificiale generale. Tra i miliardari tecnologici della regione cui giunse la voce c’era anche Elon Musk. Nel 2012, due anni dopo aver cofondato DeepMind, Hassabis stava partecipando a una conferenza esclusiva in California organizzata da Thiel quando s’imbatté proprio in Musk.</p>
			<p class="testo" id="p_0067">«Ci siamo trovati subito in sintonia», racconta Hassabis. L’imprenditore britannico sapeva che quella poteva essere un’opportunità per raccogliere ulteriori fondi ed espandere la ricerca di DeepMind; inoltre, desiderava realmente poter visitare la fabbrica di razzi di Musk, che si stava affermando come magnate anticonformista con il sogno di portare gli esseri umani su Marte attraverso la sua azienda, SpaceX. Hassabis organizzò un incontro con Musk presso la sede di quest’ultima, a Los Angeles.</p>
			<p class="testo" id="p_0068">Di lì a poco, i due si trovarono seduti l’uno di fronte all’altro nella mensa aziendale, circondati da componenti di razzi, e finirono per discutere su quale dei loro progetti si sarebbe rivelato più importante per la storia dell’umanità: la colonizzazione interplanetaria o lo sviluppo di un’intelligenza artificiale superavanzata.</p>
			<p class="testo" id="p_0069">«Gli esseri umani dovranno essere in grado di rifugiarsi su Marte se mai l’<span class="smallcaps">ai</span> dovesse andare fuori controllo», disse Musk, stando a un resoconto dell’incontro stilato da «Vanity Fair».</p>
			<p class="testo" id="p_0070">«Penso che l’<span class="smallcaps">ai</span> sarebbe in grado di seguirci fin lì», rispose Hassabis, divertito. Musk, dal canto suo, non lo era affatto. Se Tallinn era stato influenzato dagli scritti online di Yudkowsky, Musk era rimasto colpito dalle idee di un filosofo di Oxford di nome Nick Bostrom.</p>
			<p class="testo" id="p_0071">Bostrom aveva scritto un libro, <em class="calibre3">Superintelligenza</em>, che stava suscitando un certo scalpore tra gli esperti di <span class="smallcaps">ai</span> e tecnologie di frontiera. Nel libro, Bostrom avvertiva che la costruzione di un’<span class="smallcaps">ai</span> «generale» o estremamente potente avrebbe potuto portare a un esito disastroso per l’umanità, e non perché dovesse essere necessariamente malvagia o assetata di potere. Avrebbe potuto rivelarsi distruttiva anche solo nel cercare semplicemente di svolgere il proprio lavoro. Se per esempio le fosse stato assegnato il compito di produrre il maggior numero possibile di graffette, avrebbe potuto decidere di convertire tutte le risorse della Terra – esseri umani compresi – in graffette, essendo questo il modo più efficace per raggiungere l’obiettivo. Nei circoli legati all’<span class="smallcaps">ai</span>, l’aneddoto aveva dato vita a un detto: bisognava evitare di lasciarsi «trasformare in graffette».</p>
			<p class="testo" id="p_0072">In ogni caso, anche Musk decise di investire in DeepMind. E benché questo consentisse finalmente a Hassabis di poter contare su una certa sicurezza finanziaria, non si trattava certo di una somma ingente. Stava comunque perseguendo qualcosa di così sperimentale e così folle che persino alcuni degli uomini più ricchi del pianeta esitavano a scommettere troppo sul successo dell’impresa. I loro finanziamenti, inoltre, portavano alcuni vincoli ideologici: Tallinn e Musk tenevano d’occhio il lavoro di DeepMind con un sospetto e una cautela insoliti per degli investitori. Volevano che DeepMind raggiungesse il successo finanziario, certo, ma evitando che crescesse troppo rapidamente o in modo tale da costituire un pericolo per l’umanità. E questo poneva Hassabis in una posizione scomoda: era grato loro per i soldi, ovviamente, ma non condivideva gli scenari catastrofici che dipingevano.</p>
			<p class="testo" id="p_0073">Quella sensazione di sicurezza finanziaria, tuttavia, non durò a lungo. Hassabis e Suleyman faticavano a guadagnare abbastanza per coprire i costi necessari a pagare le migliori menti nel settore dell’<span class="smallcaps">ai</span>, e alcune delle loro idee per generare entrate erano alquanto incoerenti. Provarono a lanciare un sito web che utilizzasse il <em class="calibre3">deep learning</em> – il genere di apprendimento automatico in cui DeepMind si era specializzata in un primo momento – per impartire consigli di moda e raccomandare capi d’abbigliamento. Poi Hassabis chiese ad alcuni membri del team, con cui aveva già collaborato in Elixir e che ora lavoravano per DeepMind, di progettare un videogioco. Secondo un ex dipendente, gli ingegneri idearono un’avventura spaziale in cui un equipaggio di astronauti doveva raggiungere la Luna a bordo di un razzo. Stavano per lanciare il gioco come un’app per iPhone quando a Hassabis si presentò una nuova opportunità, qualcosa che gli avrebbe dato il supporto finanziario necessario per rendere l’<span class="smallcaps">agi</span> una realtà: un’offerta da parte di Facebook.</p>
			<p class="testo" id="p_0074">Mark Zuckerberg era in piena fase di acquisizioni. Circa un anno prima, aveva rilevato Instagram per un miliardo di dollari, con quella che si sarebbe dimostrata una mossa magistrale di consolidamento nei social media. E pochi mesi dopo avrebbe sborsato l’astronomica cifra di 19 miliardi di dollari ai fondatori di WhatsApp. Era pronto a spendere qualsiasi somma per espandere l’impero di Facebook, e l’intelligenza artificiale avrebbe giocato un ruolo importante nell’impresa. Facebook guadagnava circa il 98 per cento dei suoi profitti vendendo pubblicità ma, per aumentare il numero di inserzioni e continuare a crescere, a Zuckerberg serviva che le persone trascorressero sempre più tempo sulle sue piattaforme. E gli scienziati <span class="smallcaps">ai</span> di DeepMind avrebbero potuto fornire un contributo prezioso in tal senso. Con sistemi di raccomandazione più sofisticati, in grado di analizzare a fondo i dati personali degli utenti, gli algoritmi alla base di Facebook e Instagram avrebbero potuto mostrare immagini, post e video sempre più mirati, in modo da mantenere le persone sempre più incollate allo schermo.</p>
			<p class="testo" id="p_0075">Zuckerberg offrì a Hassabis 800 milioni di dollari per DeepMind, senza contare il bonus che i fondatori di start-up solitamente ricevevano rimanendo presso l’azienda acquisita per quattro o cinque anni. Era una cifra generosa: più denaro di quanto Hassabis avesse mai sognato. E questo lo pose davanti a un bivio. Fino a quel momento, i finanziamenti erano arrivati da persone che gli chiedevano di usare la massima cautela nello sviluppo dell’<span class="smallcaps">ai</span>. Ora, invece, il denaro poteva giungere da qualcuno che intendeva accelerare il processo. Dopotutto, il motto di Facebook era «Muoviti in fretta e rompi le cose».</p>
			<p class="testo" id="p_0076">Hassabis e Suleyman ne discussero a lungo. L’<span class="smallcaps">agi</span> sarebbe stata più potente di quanto lo stesso Zuckerberg potesse immaginare, ed entrambi ritenevano necessario prendere le giuste misure per impedire che un grande acquirente orientasse l’<span class="smallcaps">ai</span> verso una direzione potenzialmente dannosa. Non potevano semplicemente limitarsi a far firmare a Facebook un contratto in cui prometteva di non abusare dell’<span class="smallcaps">agi</span>. Ripensando alle esperienze pregresse con organizzazioni non profit, Suleyman disse a Hassabis e Legg che avevano bisogno di una sorta di struttura di governance che monitorasse da vicino Facebook e garantisse un uso responsabile della tecnologia di DeepMind.</p>
			<p class="testo" id="p_0077">Di solito, le aziende quotate in Borsa hanno un consiglio di amministrazione il cui compito è rappresentare gli interessi degli azionisti. Il consiglio si riunisce ogni trimestre per esaminare le azioni dell’azienda e assicurarsi che tutto venga fatto nel modo giusto per accrescerne il valore, anziché farlo scendere. Suleyman disse ai cofondatori che DeepMind avrebbe dovuto avere un tipo di consiglio differente, adatto a una tecnologia trasformativa come l’<span class="smallcaps">ai</span>. Invece di concentrarsi sul denaro, il suo compito sarebbe stato garantire che DeepMind sviluppasse l’<span class="smallcaps">ai</span> nel modo più sicuro ed etico possibile. Pur non essendo inizialmente convinti, alla fine Hassabis e Legg accettarono la proposta.</p>
			<p class="testo" id="p_0078">Hassabis tornò da Zuckerberg e gli disse che, se avessero venduto, DeepMind avrebbe dovuto istituire un comitato per l’etica e la sicurezza, con un’autorità legale indipendente per controllare qualsiasivoglia <span class="smallcaps">ai</span> superintelligente sviluppata in futuro da DeepMind. Zuckerberg si oppose alla richiesta. Il suo intento era far crescere il business pubblicitario di Facebook e «connettere il mondo» attraverso le sue piattaforme social, non quello di gestire una società di <span class="smallcaps">ai</span> separata con una serie di protocolli etici e una propria missione. Le trattative saltarono.</p>
			<p class="testo" id="p_0079">Hassabis disse ai suoi dipendenti che DeepMind avrebbe conservato la propria autonomia per altri vent’anni. In privato, però, era stanco di dover raccogliere continuamente fondi e frustrato dal fatto di poter dedicare solo una frazione del suo tempo alla ricerca effettiva. Dopo aver rifiutato un’offerta spropositata da parte di Zuckerberg, era difficile ignorare quanto avrebbe potuto guadagnare vendendo a una compagnia della Silicon Valley, specialmente ora che Big Tech sembrava improvvisamente sbavare sull’<span class="smallcaps">ai</span>. I dirigenti delle più grandi aziende della Silicon Valley, tra cui uno o due miliardari, chiamavano regolarmente i ricercatori di DeepMind per reclutarli, anche perché molti dei dipendenti dell’azienda erano esperti in <em class="calibre3">deep learning</em>, una branca a lungo considerata marginale nel campo dell’intelligenza artificiale, almeno fino a poco tempo prima.</p>
			<p class="testo" id="p_0080">Il punto di svolta era arrivato nel 2012. Una docente di <span class="smallcaps">ai</span> di Stanford, Fei-Fei Li, aveva istituito una competizione annuale per accademici, chiamata ImageNet, nel corso della quale i ricercatori presentavano modelli di <span class="smallcaps">ai</span> che cercavano di riconoscere visivamente immagini di gatti, mobili, automobili e altro ancora. Quell’anno, il team del ricercatore Geoffrey Hinton aveva utilizzato l’apprendimento profondo per creare un modello molto più preciso dei precedenti, con risultati stupefacenti. A un tratto, ecco che tutti volevano assumere esperti in questa teoria dell’<span class="smallcaps">ai</span> basata sul <em class="calibre3">deep learning</em> e ispirata al modo in cui il cervello riconosce i pattern.</p>
			<p class="testo" id="p_0081">Si trattava di un campo ristretto, con appena una manciata di esperti, dice Legg. «Parecchi dei quali lavoravano per noi.» Hassabis li pagava circa 100.000 dollari l’anno, ma giganti tecnologici come Google e Facebook avrebbero sborsato molto di più. «Ci chiamavano persone davvero famose per offrire tre volte il loro stipendio», ricorda Legg. Zuckerberg era proprio una di queste, secondo un ex dipendente di DeepMind. «Dovevamo vendere, altrimenti ci avrebbero fatto a pezzi.» E Hassabis, ansioso com’era di costruire l’<span class="smallcaps">agi</span> prima degli altri, non poteva aspettare che aziende tecnologiche con più risorse lo precedessero.</p>
			<p class="testo" id="p_0082">All’improvviso arrivò un’altra offerta di acquisto, questa volta da parte di un suo investitore, Elon Musk. Secondo una persona informata, il miliardario si proponeva di pagare l’acquisto con azioni di Tesla, l’azienda di auto elettriche che guidava ormai da cinque anni. Nei panni di investitore, Musk si era rivelato poco invadente, e solo di rado aveva fatto visita a Hassabis. Nonostante le crescenti preoccupazioni circa i pericoli legati all’<span class="smallcaps">ai</span>, il miliardario aveva anche ben presenti i propri obiettivi commerciali. Voleva che le Tesla fossero le prime auto al mondo a utilizzare con successo la tecnologia di guida autonoma, e a tale scopo aveva bisogno di esperti all’avanguardia nel campo dell’<span class="smallcaps">ai</span>. Ora poteva assicurarsi un’intera élite di esperti acquistando DeepMind.</p>
			<p class="testo" id="p_0083">Ancora una volta, però, i fondatori dell’azienda erano scettici. Essere pagati in azioni Tesla non sembrava così allettante. Inoltre, l’idea che uno come Musk prendesse il controllo dell’<span class="smallcaps">agi</span> li metteva a disagio. Benché stesse appena iniziando a guadagnare fama mainstream come imprenditore visionario, nei circoli tecnologici Musk aveva la nomea di manager bizzoso, tanto da licenziare dipendenti senza preavviso e cacciare persino il cofondatore di Tesla.</p>
			<p class="testo" id="p_0084">Per quanto i fondatori di DeepMind apprezzassero il suo investimento e la sua rete di contatti, diffidavano del suo comportamento imprevedibile. Così, rifiutarono anche la sua offerta, senza rendersi conto di quanto Musk detestasse sentirsi dire di no e di quanto quella decisione avrebbe potuto ritorcersi contro. Di lì a poco, però, Hassabis ricevette un’altra e-mail. Questa volta da Google.</p>
		</section>
	</body>
</html>
