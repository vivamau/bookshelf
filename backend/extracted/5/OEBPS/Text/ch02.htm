<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xml:lang="en"
      lang="en"
      xmlns="http://www.w3.org/1999/xhtml"
      xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<title>TensorFlow in Action</title>
<link rel="stylesheet" type="text/css" href="../../override_v1.css"/>
<link rel="stylesheet" type="text/css" href="../../stylesheet.css"/><link rel="stylesheet" type="text/css" href="../../page_styles.css"/>
</head>
<body>
<div id="book-content">
<div id="sbo-rt-content" class="calibre"><h1 class="tochead"><a id="pgfId-1066216"></a>2 TensorFlow 2</h1>

  <p class="co-summary-head"><a id="pgfId-1066218"></a>This chapter<a id="marker-1067945"></a> covers</p>

  <ul class="calibre9">
    <li class="co-summary-bullet"><a class="calibre8" id="pgfId-1066219"></a>What TensorFlow 2 is</li>

    <li class="co-summary-bullet"><a class="calibre8" id="pgfId-1066220"></a>Important data structures and operations in TensorFlow</li>

    <li class="co-summary-bullet"><a class="calibre8" id="pgfId-1066221"></a>Common neural network related operations in TensorFlow</li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1066222"></a>In the previous chapter, we learned that TensorFlow is an end-to-end machine learning framework predominantly used for implementing deep neural networks. TensorFlow is skillful at converting these deep neural networks to computational graphs that run faster on optimized hardware (e.g., GPUs and TPUs). But keep in mind that this is not the only use for TensorFlow. Table 2.1 delineates other areas TensorFlow supports.</p>

  <p class="fm-table-caption"><a id="pgfId-1067993"></a>Table 2.1 Various features offered in TensorFlow</p>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre12">
      <col class="calibre13" span="1" width="25%"/>
      <col class="calibre13" span="1" width="75%"/>
    </colgroup>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068031"></a>Probabilistic machine learning<a id="marker-1068032"></a></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068034"></a>TensorFlow supports implementing probabilistic machine learning models. For example, models like Bayesian neural networks can be implemented with a TensorFlow API (<span class="fm-hyperlink"><a class="url" href="https://www.tensorflow.org/probability">https://www.tensorflow.org/probability</a></span>).</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068001"></a>Computer graphics-related computations<a id="marker-1068014"></a></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068003"></a>Computer graphic computations can be mostly achieved on GPUs (e.g., simulating various lighting effects, raytracing; <span class="fm-hyperlink"><a class="url" href="https://www.tensorflow.org/graphics">https://www.tensorflow.org/graphics</a></span>).</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068005"></a>TensorFlow Hub: Reusable (pretrained) models</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068007"></a>In deep learning we usually try to leverage models that have already been trained on large amounts of data for the downstream tasks we’re interested in solving. TensorFlow Hub is a repository in which such models implemented in TensorFlow are stored (<span class="fm-hyperlink"><a class="url" href="https://www.tensorflow.org/hub">https://www.tensorflow.org/hub</a></span>).</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068009"></a>Visualize/debug TensorFlow models</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068011"></a>TensorFlow provides a dashboard for visualizing and monitoring model performance and even visualizing data (<span class="fm-hyperlink"><a class="url" href="https://www.tensorflow.org/tensorboard">https://www.tensorflow.org/tensorboard</a></span>).</p>
      </td>
    </tr>
  </table>

  <p class="body"><a class="calibre8" id="pgfId-1066250"></a>In the coming chapters, we will go on an exciting journey exploring the bells and whistles in TensorFlow and learning how to excel at things TensorFlow is good at. In other words, we will look at how to solve real-world problems with TensorFlow, such as image classification (i.e., recognizing objects in images), sentiment analysis (i.e., recognizing positive/negative tones in reviews/opinions), and so on. While solving these tasks, you will learn how to overcome real-world challenges such as overfitting and class imbalance that can easily throw a spanner in the works. This chapter specifically focuses on providing a strong foundational knowledge of TensorFlow before we head toward complex problems that can be solved with deep networks.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066252"></a>First, we will implement a neural network in both TensorFlow 2 and TensorFlow 1 and see how much TensorFlow has evolved in terms of user friendliness. Then we will learn about basic units (e.g., variables, tensors, and operations) provided in TensorFlow, which we must have a good understanding of in order to develop solutions. Finally, we will understand the details of several complex mathematical operations through a series of fun computer vision exercises.</p>

  <h2 class="fm-head" id="sigil_toc_id_24"><a id="pgfId-1066254"></a>2.1 First steps with TensorFlow 2</h2>

  <p class="body"><a class="calibre8" id="pgfId-1066256"></a>Let’s<a class="calibre8" id="marker-1066255"></a> imagine you are taking a machine learning course and have been given an assignment to implement a <i class="fm-italics">multilayer perceptron</i> (MLP<a class="calibre8" id="marker-1066257"></a><a id="marker-1071159"></a><a id="marker-1083468"></a>) (i.e., a type of neural network) and compute the final output for a given datapoint using TensorFlow. You are new to TensorFlow, so you go to the library and start studying what TensorFlow is. While you research, you realize that TensorFlow has two major versions (1 and 2) and decide to use the latest and greatest: TensorFlow 2. You’ve already installed the required libraries, as outlined in appendix A.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066259"></a>Before moving on, let’s learn about MLPs. An MLP (figure 2.1) is a simple neural network that has an input layer, one or more hidden layers, and an output layer. These networks are also called <i class="fm-italics">fully connected networks</i><a class="calibre8" id="marker-1066260"></a>.</p>

  <p class="fm-callout"><a id="pgfId-1066261"></a><span class="fm-callout-head">NOTE</span> Some research only uses the term MLP to refer to a network made of multiple perceptrons (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/y4lE">http://mng.bz/y4lE</a></span>) organized in a hierarchical structure. However, in this book, we will use the terms MLP and fully connected network interchangeably.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066265"></a>In each layer, we have weights and biases, which are used to compute the output of that layer. In our example, we have an input of size 4, a hidden layer with three nodes, and an output layer of size 2.</p>

  <p class="fm-figure"><img alt="02-01" class="calibre10" src="../../OEBPS/Images/02-01.png" width="989" height="406"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077255"></a>Figure 2.1 Depiction of a multilayer perceptron (MLP<a id="marker-1077254"></a>) or a fully connected network. There are three layers: an input layer, a hidden layer (that has weights and biases), and an output layer. The output layer produces normalized probabilities as the output using softmax activation.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066273"></a>The input values (<i class="fm-timesitalic">x</i>) are transformed to hidden values (<i class="fm-timesitalic">h</i>) using the following computation</p>

  <p class="fm-equation"><a id="pgfId-1066274"></a><i class="fm-italics">h</i> = <i class="fm-italics"><span class="fm-symbol">σ</span></i>(<i class="fm-italics">x W</i><sub class="fm-subscript">1</sub> + <i class="fm-italics">b</i><sub class="fm-subscript">1</sub>)</p>

  <p class="body"><a class="calibre8" id="pgfId-1066275"></a>where <i class="fm-timesitalic">σ</i> is the sigmoid function. The sigmoid function is a simple nonlinear element-wise transformation, as shown as in figure 2.2.</p>

  <p class="fm-figure"><img alt="02-02" class="calibre10" src="../../OEBPS/Images/02-02.png" width="753" height="511"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077289"></a>Figure 2.2 A visualization of the sigmoidal activation function for different inputs</p>

  <p class="body"><a class="calibre8" id="pgfId-1066282"></a><i class="fm-timesitalic">x</i> is a matrix of size 1 × 4 (i.e., one row and four columns), <i class="fm-timesitalic">W</i><sub class="fm-subscript">1</sub> is a matrix of size 4 × 3 (i.e., four rows and three columns), and <i class="fm-timesitalic">b</i><sub class="fm-subscript">1</sub> is 1 × 4 (i.e., one row and four columns). This gives an h of size 1 × 3. Finally, the output is computed as</p>

  <p class="fm-equation"><a id="pgfId-1066283"></a><i class="fm-italics">y</i> = <i class="fm-italics">softmax</i>(<i class="fm-italics">h W</i><sub class="fm-subscript">2</sub> + <i class="fm-italics">b</i><sub class="fm-subscript">2</sub>)</p>

  <p class="body"><a class="calibre8" id="pgfId-1066284"></a>Here, <i class="fm-timesitalic">W</i><sub class="fm-subscript">2</sub> is a 3 × 2 matrix, and <i class="fm-timesitalic">b</i><sub class="fm-subscript">2</sub> is a 1 × 2 matrix. Softmax activation normalizes the linear scores of the last layer (i.e., <i class="fm-timesitalic">h W</i><sub class="fm-subscript">2</sub> + <i class="fm-timesitalic">b</i><sub class="fm-subscript">2</sub>) to actual probabilities (i.e., values sum up to 1 along columns). Assuming an input vector x of length <i class="fm-timesitalic">K</i>, the softmax activation produces a <i class="fm-timesitalic">K</i>-long vector <i class="fm-timesitalic">y</i>. The <i class="fm-timesitalic">i</i><sup class="fm-superscript">th</sup> element of <i class="fm-timesitalic">y</i> is computed as</p>

  <p class="fm-equation"><img alt="02_02a" class="calibre10" src="../../OEBPS/Images/02_02a.png" width="144" height="87"/><br class="calibre2"/>
  <a id="pgfId-1069101"></a></p>

  <p class="body"><a class="calibre8" id="pgfId-1066289"></a>where <i class="fm-timesitalic">y<sub class="fm-subscript">i</sub></i> is the <i class="fm-timesitalic">i</i><sup class="fm-superscript">th</sup> output element and <i class="fm-timesitalic">x</i><sub class="fm-subscript">i</sub> is the <i class="fm-timesitalic">i</i><sup class="fm-superscript">th</sup> input element. As a concrete example, assume the final layer without the softmax activation produced,</p>
  <pre class="programlisting">[16, 4]</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066291"></a>Applying the softmax normalization converts these values to</p>
  <pre class="programlisting">[16/(16+4), 4/(16+4)] = [0.8, 0.2]</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066293"></a>Let’s see how this can be implemented in TensorFlow 2. You can find the code in the Jupyter notebook (<span class="fm-code-in-text">Ch02-Fundamentals-of-TensorFlow-2/2.1.Tensorflow_Fundamentals.ipynb</span>). How to install the necessary libraries and set up the development environment is delineated in appendix A. Initially, we need to import the required libraries using import statements:</p>
  <pre class="programlisting">import numpy as np
import tensorflow as tf</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066296"></a>Then we define the input to the network (<i class="fm-timesitalic">x</i>) and the variables (or parameters) (i.e., <i class="fm-timesitalic">w</i><sub class="fm-subscript">1</sub>, <i class="fm-timesitalic">b</i><sub class="fm-subscript">1</sub>, <i class="fm-timesitalic">w</i><sub class="fm-subscript">2</sub>, and <i class="fm-timesitalic">b</i><sub class="fm-subscript">2</sub>) of the network:</p>
  <pre class="programlisting">x = np.random.normal(size=[1,4]).astype('float32')
 
init = tf.keras.initializers.RandomNormal()
 
w1 = tf.Variable(init(shape=[4,3])) 
b1 = tf.Variable(init(shape=[1,3])) 
 
w2 = tf.Variable(init(shape=[3,2])) 
b2 = tf.Variable(init(shape=[1,2])) </pre>

  <p class="body"><a class="calibre8" id="pgfId-1066306"></a>Here, <i class="fm-timesitalic">x</i> is a simple NumPy array of size 1 × 4 (i.e., one row and four columns) that is filled with values from a normal distribution. Then we define the parameters of the network (i.e., weights and biases) as TensorFlow variables. A <span class="fm-code-in-text">tf.Variable</span> behaves similar to a typical Python variable. It has some value attached at the time of the definition and can change over time. <span class="fm-code-in-text">tf.Variable</span> is used to represent weights and biases of a neural network, which are changed during the optimization or the training procedure. When defining TensorFlow variables, we need to provide an initializer and a shape for the variables. Here we are using an initializer that randomly sample values from a normal distribution. Remember that <i class="fm-timesitalic">W</i><sub class="fm-subscript">1</sub> is 4 × 3 sized, <i class="fm-timesitalic">b</i><sub class="fm-subscript">1</sub> is 1 × 3 sized, <i class="fm-timesitalic">W</i><sub class="fm-subscript">2</sub> is 3 × 2 sized, and <i class="fm-timesitalic">b</i><sub class="fm-subscript">2</sub> is 1 × 2 sized, and that the <span class="fm-code-in-text">shape</span> argument for each of these is set accordingly. Next, we define the core computations of the MLP as a nice modular function. This way, we can easily reuse the function to compute hidden layer outputs of multiple layers:</p>
  <pre class="programlisting">@tf.function
def forward(x, W, b, act):
    return act(tf.matmul(x,W)+b)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066312"></a>Here, <span class="fm-code-in-text">act</span> is any nonlinear activation function of your choice (e.g., <span class="fm-code-in-text">tf.nn.sigmoid</span>). (You can look at various activation functions here: <span class="fm-hyperlink"><a class="url" href="https://www.tensorflow.org/api_docs/python/tf/nn">https://www.tensorflow.org/api_docs/python/tf/nn</a></span>. Be mindful that not all of them are activation functions. The expression <span class="fm-code-in-text">tf.matmul(x,W)+b</span><a class="calibre8" id="marker-1071027"></a> elegantly wraps the core computations we saw earlier (i.e., <i class="fm-timesitalic">x W</i><sub class="fm-subscript">1</sub> + <i class="fm-timesitalic">b</i><sub class="fm-subscript">1</sub> and <i class="fm-timesitalic">h W</i><sub class="fm-subscript">2</sub> + <i class="fm-timesitalic">b</i><sub class="fm-subscript">2</sub>) to a reusable expression. Here, <span class="fm-code-in-text">tf.matmul</span> performs the matrix multiplication operation. This computation is illustrated in figure 2.3.</p>

  <p class="fm-figure"><img alt="02-03" class="calibre10" src="../../OEBPS/Images/02-03.png" width="992" height="372"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077323"></a>Figure 2.3 The matrix multiplication and bias addition illustrated for example input, weights, and bias</p>

  <p class="body"><a class="calibre8" id="pgfId-1066320"></a>Having <span class="fm-code-in-text">@tf.function</span> on top of the function is a way for TensorFlow to know that this function contains TensorFlow code. We will discuss the purpose of <span class="fm-code-in-text">@tf.function</span> in more detail in the next section. This brings us to the final part of the code. As we have the inputs, all the parameters, and core computations defined, we can compute the final output of the network</p>
  <pre class="programlisting"># Computing h
h = forward(x, w1, b1, tf.nn.sigmoid)
 
# Computing y
y = forward(h, w2, b2, tf.nn.softmax)
 
print(y)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066329"></a>which will output</p>
  <pre class="programlisting">tf.Tensor([[0.4912673 0.5087327]], shape=(1, 2), dtype=float32)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066331"></a>Here, <span class="fm-code-in-text">h</span> and <span class="fm-code-in-text">y</span> are the resulting tensors (of type <span class="fm-code-in-text">tf.Tensor</span>) of various TensorFlow operations (e.g., <span class="fm-code-in-text">tf.matmul</span>). The exact values in the output might differ slightly (see the following listing).</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1066333"></a>Listing 2.1 Multilayer perceptron network with TensorFlow 2</p>
  <pre class="programlisting">import numpy as np                                  <span class="fm-combinumeral">❶</span>
import tensorflow as tf                             <span class="fm-combinumeral">❶</span>
 
x = np.random.normal(size=[1,4]).astype('float32')  <span class="fm-combinumeral">❷</span>
 
init = tf.keras.initializers.RandomNormal()         <span class="fm-combinumeral">❸</span>
 
w1 = tf.Variable(init(shape=[4,3]))                 <span class="fm-combinumeral">❹</span>
b1 = tf.Variable(init(shape=[1,3]))                 <span class="fm-combinumeral">❹</span>
 
w2 = tf.Variable(init(shape=[3,2]))                 <span class="fm-combinumeral">❹</span>
b2 = tf.Variable(init(shape=[1,2]))                 <span class="fm-combinumeral">❹</span>
 
@tf.function                                        <span class="fm-combinumeral">❺</span>
def forward(x, W, b, act):                          <span class="fm-combinumeral">❻</span>
    return act(tf.matmul(x,W)+b)                    <span class="fm-combinumeral">❻</span>
 
h = forward(x, w1, b1, tf.nn.sigmoid)               <span class="fm-combinumeral">❼</span>
 
y = forward(h, w2, b2, tf.nn.softmax)               <span class="fm-combinumeral">❽</span>
 
print(y)</pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1076170"></a><span class="fm-combinumeral">❶</span> Importing NumPy and TensorFlow libraries</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1076198"></a><span class="fm-combinumeral">❷</span> The input to the MLP (a NumPy array)</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1076218"></a><span class="fm-combinumeral">❸</span> The initializer used to initialize variables</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1076235"></a><span class="fm-combinumeral">❹</span> The parameters of layer 1 (w1 and b2) and layer 2 (w2 and b2)</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1076252"></a><span class="fm-combinumeral">❺</span> This line tells TensorFlow’s AutoGraph to build the graph.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1076269"></a><span class="fm-combinumeral">❻</span> MLP layer computation, which takes in an input, weights, bias, and a nonlinear activation</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1076286"></a><span class="fm-combinumeral">❼</span> Computing the first hidden layer output, h</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1076303"></a><span class="fm-combinumeral">❽</span> Computing the final output, y</p>

  <p class="body"><a class="calibre8" id="pgfId-1066364"></a>Next, we will look at what happens behind the scenes when TensorFlow runs the code.</p>

  <h3 class="fm-head1" id="sigil_toc_id_25"><a id="pgfId-1066365"></a>2.1.1 How does TensorFlow operate under the hood?</h3>

  <p class="body"><a class="calibre8" id="pgfId-1066366"></a>In a typical TensorFlow program, there are two main steps:</p>

  <ol class="calibre11">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1066367"></a>Define a data-flow graph encompassing the inputs, operations, and the outputs. In our exercise, the data-flow graph will represent how <span class="fm-code-in-text">x</span>, <span class="fm-code-in-text">w1</span>, <span class="fm-code-in-text">b1</span>, <span class="fm-code-in-text">w2</span>, <span class="fm-code-in-text">b2</span>, <span class="fm-code-in-text">h</span>, and <span class="fm-code-in-text">y</span> are related to each other.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1066368"></a>Execute the graph by feeding values to the inputs and computing outputs. For example, if we need to compute <span class="fm-code-in-text">h</span>, we will feed a value (e.g., a NumPy array) to <span class="fm-code-in-text">x</span> and get the value of <span class="fm-code-in-text">h</span>.</p>
    </li>
  </ol>

  <p class="body"><a class="calibre8" id="pgfId-1066370"></a>TensorFlow 2 uses an execution style known as <i class="fm-italics">imperative style execution</i><a class="calibre8" id="marker-1066369"></a>. In imperative style execution, declaration (defining the graph) and execution happen simultaneously. This is also known as <i class="fm-italics">eagerly executing</i> code<a class="calibre8" id="marker-1066371"></a>.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066373"></a>You might be wondering what a data-flow graph looks like. It is a term TensorFlow uses to describe the flow of computations you defined and is represented as a <i class="fm-italics">directed acyclic graph</i> (DAG<a class="calibre8" id="marker-1066374"></a><a class="calibre8" id="marker-1066375"></a>): a graph structure where arrows represent the data and nodes represent the operations. In other words, <span class="fm-code-in-text">tf.Variable</span> and <span class="fm-code-in-text">tf.Tensor</span> objects represent the edges in the graph, whereas operations (e.g., <span class="fm-code-in-text">tf.matmul</span>) represent the nodes. For example, the data-flow graph for</p>

  <p class="fm-equation"><a id="pgfId-1066376"></a><i class="fm-italics">h = x W</i><sub class="fm-subscript">1</sub> + <i class="fm-italics">b</i><sub class="fm-subscript">1</sub></p>

  <p class="body"><a class="calibre8" id="pgfId-1066377"></a>would look like figure 2.4. Then, at runtime, you could get the value of <span class="fm-code-in-text">y</span> by feeding values to <span class="fm-code-in-text">x</span>, as <span class="fm-code-in-text">y</span> is dependent on the input <span class="fm-code-in-text">x</span>.</p>

  <p class="fm-figure"><img alt="02-04" class="calibre10" src="../../OEBPS/Images/02-04.png" width="958" height="417"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077382"></a>Figure 2.4 An example computational graph. The various elements here are covered in more detail in section 2.2.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066385"></a>How does TensorFlow know to create the data-flow graph? You might have noticed the line starting with the symbol @ hanging on top of the <span class="fm-code-in-text">forward(...)</span> function<a class="calibre8" id="marker-1066386"></a>. This is known as a <i class="fm-italics">decorator</i><a class="calibre8" id="marker-1066387"></a> in Python language. The @<span class="fm-code-in-text">tf.function</span> decorator<a class="calibre8" id="marker-1066388"></a> takes in a function that performs various TensorFlow operations, traces all the steps, and turns that into a data-flow graph. How cool is that? This encourages the user to write modular code while enabling the computational advantages of a data-flow graph. This feature in TensorFlow 2 is known appropriately as AutoGraph (<span class="fm-hyperlink"><a class="url" href="https://www.tensorflow.org/guide/function">https://www.tensorflow.org/guide/function</a></span>).</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1066389"></a>What is a decorator?</p>

    <p class="fm-sidebar-text"><a id="pgfId-1066390"></a>A decorator modifies the behavior of a function by wrapping it, which happens before/after the function is invoked. A good example of a decorator is logging the inputs and outputs of a function whenever it is invoked. Here’s how you would use decorators for this:</p>
    <pre class="programlisting">def log_io(func):
    def wrapper(*args, **kwargs):
        print("args: ", args)
        print(“kwargs: “, kwargs)
        out = func(*args, **kwargs)
        print("return: ", out)
    return wrapper
 
@log_io
def easy_math(x, y):
    return x + y + ( x * y)
 
res = easy_math(2,3)</pre>

    <p class="fm-sidebar-text"><a id="pgfId-1066404"></a>This will output</p>
    <pre class="programlisting">args:  (2, 3)
kwargs:  {}
return:  11</pre>

    <p class="fm-sidebar-text"><a id="pgfId-1066410"></a>as expected. Therefore, when you add the <span class="fm-code-in-text1">@tf.function</span> decorator<a id="marker-1070185"></a>, it essentially modifies the behavior of the invoked function by building a computational graph of the computations happening within the given function.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1066413"></a>The diagram in figure 2.5 depicts the execution path of a TensorFlow 2 program. The first time the functions <a id="marker-1066414"></a><span class="fm-code-in-text">a</span><a class="calibre8" id="marker-1077412"></a><span class="fm-code-in-text">(...)</span> and <span class="fm-code-in-text">b(...)</span> are invoked, the data-flow graph is created. Then, inputs passed to the functions will be fed to the graph and obtain the outputs you are interested in.</p>

  <p class="fm-figure"><img alt="02-05" class="calibre10" src="../../OEBPS/Images/02-05.png" width="1014" height="428"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077442"></a>Figure 2.5 Typical execution of a TensorFlow 2 program. In the first run, TensorFlow traces all functions annotated with <span class="fm-code-in-figurecaption">@tf.function</span> and builds the data-flow graph. In the subsequent runs, corresponding values are fed to the graph (according to the function call) and the results are retrieved.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1066423"></a>AutoGraph</p>

    <p class="fm-sidebar-text"><a id="pgfId-1066424"></a>AutoGraph is a great feature in TensorFlow that reduces the developer’s workload by working hard behind the scene. To build true appreciation for the feature, read more at <span class="fm-hyperlink"><a class="url" href="https://www.tensorflow.org/guide/function">https://www.tensorflow.org/guide/function</a></span>. Though it is quite amazing, AutoGraph is not a silver bullet. Therefore, it is important to understand its advantages as well as its limitations and caveats:</p>

    <ul class="calibre9">
      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1066425"></a>AutoGraph will provide a performance boost if your code consists of lots of repetitive operations (e.g., training a neural network for many iterations).</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1066426"></a>AutoGraph might slow you down if you run many different operations that only run once; because you run the operation only once, building the graph is just an overhead.</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1066427"></a>Be careful of what you include inside the function you are exposing to AutoGraph. For example</p>

        <ul class="calibre16">
          <li class="fm-sidebar-bullet-sub">
            <p class="list"><a class="calibre8" id="pgfId-1066429"></a>NumPy arrays and Python lists will be converted to <span class="fm-code-in-text1">tf.constant</span> objects<a class="calibre8" id="marker-1070234"></a><a class="calibre8" id="marker-1077427"></a>.</p>
          </li>

          <li class="fm-sidebar-bullet-sub">
            <p class="list"><a class="calibre8" id="pgfId-1066430"></a><span class="fm-code-in-text1">for</span> loops will be unwrapped during function tracing, which might result in large graphs that eventually run out of memory.</p>
          </li>
        </ul>
      </li>
    </ul>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1066432"></a>TensorFlow 1, the predecessor of TensorFlow 2, used an execution style known as <i class="fm-italics"><a id="marker-1066433"></a>declarative graph-based execution</i><a class="calibre8" id="marker-1077431"></a>, which consists of two steps:</p>

  <ol class="calibre11">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1066434"></a>Explicitly define a data-flow graph using various symbolic elements (e.g., placeholder inputs, variables, and operations) of what you need to achieve. Unlike in TensorFlow 2, these do not hold values at declaration.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1066435"></a>Explicitly write code to run the defined graph and obtain or evaluate results. You can feed actual values to the previously defined symbolic elements at runtime and execute the graph.</p>
    </li>
  </ol>

  <p class="body"><a class="calibre8" id="pgfId-1066436"></a>This is very different from TensorFlow 2, which hides all the intricacies of the data-flow graph by automatically building it in the background. In TensorFlow 1, you have to explicitly build the graph and then execute it, leading to code that’s more complex and difficult to read. Table 2.2 summarizes the differences between TensorFlow 1 and TensorFlow 2.</p>

  <p class="fm-table-caption"><a id="pgfId-1068097"></a>Table 2.2 Differences between TensorFlow 1 and TensorFlow 2</p>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre12">
      <col class="calibre13" span="1" width="50%"/>
      <col class="calibre13" span="1" width="50%"/>
    </colgroup>

    <tr class="calibre14">
      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1068101"></a><b class="fm-bold">TensorFlow 1</b></p>
      </th>

      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1068103"></a><b class="fm-bold">TensorFlow 2</b></p>
      </th>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068105"></a>Does not use eager execution by default</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068107"></a>Uses eager execution by default</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068109"></a>Uses symbolic placeholders to represent inputs to the graph</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068111"></a>Directly feeds actual data (e.g., NumPy arrays) to the data-flow graph</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068113"></a>Difficult to debug as results are not evaluated imperatively</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068115"></a>Easy to debug as operations are evaluated imperatively</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068117"></a>Needs to explicitly and manually create the data-flow graph</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068119"></a>Has AutoGraph functionality, which traces TensorFlow operations and creates the graph automatically</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068121"></a>Does not encourage object-oriented programming, as it forces you to define the computational graph in advance</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068123"></a>Encourages object-oriented programming</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068125"></a>Results in poor readability of code due to having separate graph definition and runtime code</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068127"></a>Has better readability of code</p>
      </td>
    </tr>
  </table>

  <p class="body"><a class="calibre8" id="pgfId-1066469"></a>In the next section, we discuss the basic building blocks of TensorFlow that set the foundation for writing TensorFlow programs.</p>

  <p class="fm-head2"><a id="pgfId-1066470"></a>Exercise 1</p>

  <p class="body"><a class="calibre8" id="pgfId-1066471"></a>Given the following code,</p>
  <pre class="programlisting"># A
import tensorflow as tf
# B
def f1(x, y, z):
    return tf.math.add(tf.matmul(x, y) , z)
#C
w = f1(x, y, z)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066481"></a>where should the <span class="fm-code-in-text">tf.function</span> decorator<a class="calibre8" id="marker-1066479"></a><a class="calibre8" id="marker-1066480"></a> go?</p>

  <ol class="calibre11">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1066482"></a>A</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1066483"></a>B</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1066484"></a>C</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1066485"></a>Any of above</p>
    </li>
  </ol>

  <h2 class="fm-head" id="sigil_toc_id_26"><a id="pgfId-1066486"></a>2.2 TensorFlow building blocks</h2>

  <p class="body"><a class="calibre8" id="pgfId-1066488"></a>We<a class="calibre8" id="marker-1066487"></a> have seen the core differences between TensorFlow 1 and TensorFlow 2. While doing this, you were exposed to various data structures (e.g., <span class="fm-code-in-text">tf.Variable</span>) and operations (e.g., <span class="fm-code-in-text">tf.matmul</span><a class="calibre8" id="marker-1066489"></a>) exposed by the TensorFlow API. Let’s now see where and how you might use these data structures and operations.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066490"></a>In TensorFlow 2, there are three major basic elements we need to learn about:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1066491"></a><span class="fm-code-in-text">tf.Variable</span></p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1066492"></a><span class="fm-code-in-text">tf.Tensor</span></p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1066493"></a><span class="fm-code-in-text">tf.Operation</span></p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1066494"></a>You have already seen all of these being used. For example, from the previous MLP example, we have these elements, as shown in table 2.3. Having knowledge of these primitive components is helpful in understanding more abstract components, such as a Keras layer and model objects, and will be discussed later.</p>

  <p class="fm-table-caption"><a id="pgfId-1068196"></a>Table 2.3 <span class="fm-code-in-figurecaption">tf.Variable</span>, <span class="fm-code-in-figurecaption">tf.Tensor</span>, and <span class="fm-code-in-figurecaption">tf.Operation</span> entities from the MLP example</p>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre12">
      <col class="calibre13" span="1" width="50%"/>
      <col class="calibre13" span="1" width="50%"/>
    </colgroup>

    <tr class="calibre14">
      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1068200"></a><b class="fm-bold">Element</b></p>
      </th>

      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1068202"></a><b class="fm-bold">Example</b></p>
      </th>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068204"></a><span class="fm-code-in-figurecaption">tf.Variable</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068206"></a><span class="fm-code-in-figurecaption">w1</span><i class="fm-italics">,</i> <span class="fm-code-in-figurecaption">b1</span><i class="fm-italics">,</i> <span class="fm-code-in-figurecaption">w2</span> and <span class="fm-code-in-figurecaption">b2</span></p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068208"></a><span class="fm-code-in-figurecaption">tf.Tensor</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068210"></a><span class="fm-code-in-figurecaption">h</span> and <span class="fm-code-in-figurecaption">y</span></p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068212"></a><span class="fm-code-in-figurecaption">tf.Operation</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068214"></a><span class="fm-code-in-figurecaption">tf.matmul</span></p>
      </td>
    </tr>
  </table>

  <p class="body"><a class="calibre8" id="pgfId-1066515"></a>It is important to firmly grok these basic elements of TensorFlow for several reasons. The main reason is that everything you see in this book, from this point on, is built on top of these elements. For example, if you are using a high-level API like Keras to build a model, it still uses <span class="fm-code-in-text">tf.Variable</span>, <span class="fm-code-in-text">tf.Tensor</span>, and <span class="fm-code-in-text">tf.Operation</span> entities to do the computations. Therefore, it is important to know how to use these elements and what you can and cannot achieve with them. The other benefit is that the errors returned by TensorFlow are usually presented to you using these elements. So, this knowledge will also help us understand errors and resolve them quickly as we develop more complex models.</p>

  <h3 class="fm-head1" id="sigil_toc_id_27"><a id="pgfId-1066516"></a>2.2.1 Understanding tf.Variable</h3>

  <p class="body"><a class="calibre8" id="pgfId-1066519"></a>When<a class="calibre8" id="marker-1066517"></a><a class="calibre8" id="marker-1066518"></a> building a typical machine learning model, you have two types of data:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1066520"></a>Model parameters that change over time (mutable) as the model is optimized with regard to a chosen loss function</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1066521"></a>Outputs of the model that are static given data and model parameters (immutable)</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1066522"></a><span class="fm-code-in-text">tf.Variable</span> is ideal for defining model parameters, as they are initialized with some value and can change the value over time. A TensorFlow variable must have the following:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1066523"></a>A shape (size of each dimension of the variable)</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1066524"></a>An initial value (e.g., randomly initialized from values sampled from a normal distribution)</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1066525"></a>A data type (e.g., int32, float32)</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1066526"></a>You can define a TensorFlow variable as follows</p>
  <pre class="programlisting">tf.Variable(initial_value=None, trainable=None, dtype=None)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066528"></a>where</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1066529"></a><span class="fm-code-in-text">initial_value</span> contains the initial value provided to the model. This is typically provided using a variable initializer provided in the <span class="fm-code-in-text">tf.keras.initializers</span> submodule<a class="calibre8" id="marker-1066530"></a> (the full list of initializers can be found at <span class="fm-hyperlink"><a class="url" href="http://mng.bz/M2Nm">http://mng.bz/M2Nm</a></span>). For example, if you want to initialize the variable randomly with a 2D matrix having four rows and three columns using a uniform distribution, you can pass <span class="fm-code-in-text">tf.keras.initializers.RandomUniform()([4,3])</span>. You must provide a value to the <span class="fm-code-in-text">initial_value</span> argument.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1066532"></a><span class="fm-code-in-text">trainable</span> parameter<a class="calibre8" id="marker-1066531"></a> accepts a Boolean value (i.e., <span class="fm-code-in-text">True</span> or <span class="fm-code-in-text">False</span>) as the input. Setting the trainable parameter to <span class="fm-code-in-text">True</span> allows the model parameters to be changed by means of gradient descent. Setting the trainable parameter to <span class="fm-code-in-text">False</span> will freeze the layer so that the values cannot be changed using gradient descent.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1066533"></a><span class="fm-code-in-text">dtype</span> specifies the data type of the data contained in the variable. If unspecified, this defaults to the data type provided to the <span class="fm-code-in-text">initial_value</span> argument (typically <span class="fm-code-in-text">float32</span>).</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1066534"></a>Let’s see how we can define TensorFlow variables. First, make sure you have imported the following libraries:</p>
  <pre class="programlisting">import tensorflow as tf
import numpy as np</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066537"></a>You can define a TensorFlow variable with one dimension of size 4 with a constant value of 2 as follows:</p>
  <pre class="programlisting">v1 = tf.Variable(tf.constant(2.0, shape=[4]), dtype='float32')
print(v1)
 
&gt;&gt;&gt; &lt;tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([2., 2., 2., 2.], dtype=float32)&gt;</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066542"></a>Here, <span class="fm-code-in-text">tf.constant(2.0, shape=[4])</span> produces a vector of four elements having a value 2.0, which then is used as the initial value of <span class="fm-code-in-text">tf.Variable</span>. You can also define a TensorFlow variable with a NumPy array:</p>
  <pre class="programlisting">v2 = tf.Variable(np.ones(shape=[4,3]), dtype='float32')
print(v2)
 
&gt;&gt;&gt; &lt;tf.Variable 'Variable:0' shape=(4, 3) dtype=float32, numpy=
array([[1., 1., 1.],
       [1., 1., 1.],
       [1., 1., 1.],
       [1., 1., 1.]], dtype=float32)&gt;</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066551"></a>Here, <span class="fm-code-in-text">np.ones(shape=[4,3])</span> generates a matrix of shape <span class="fm-code-in-text">[4,3]</span>, and all the elements have a value of 1. The next code snippet defines a TensorFlow variable with three dimensions (3×4×5) with random normal initialization:</p>
  <pre class="programlisting">v3 = tf.Variable(tf.keras.initializers.RandomNormal()(shape=[3,4,5]), dtype='float32')
print(v3)
 
&gt;&gt;&gt; &lt;tf.Variable 'Variable:0' shape=(3, 4, 5) dtype=float32, numpy=
array([[[-0.00599647, -0.04389469, -0.03364765, -0.0044175 ,
          0.01199682],
        [ 0.05423453, -0.02812728, -0.00572744, -0.08236874,
         -0.07564012],
        [ 0.0283042 , -0.05198685,  0.04385028,  0.02636188,
          0.02409425],
        [-0.04051876,  0.03284673, -0.00593955,  0.04204708,
         -0.05000611]],
 
       ...
 
       [[-0.00781542, -0.03068716,  0.04313354, -0.08717368,
          0.07951441],
        [ 0.00467467,  0.00154883, -0.03209472, -0.00158945,
          0.03176221],
        [ 0.0317267 ,  0.00167555,  0.02544901, -0.06183815,
          0.01649506],
        [ 0.06924769,  0.02057942,  0.01060928, -0.00929202,
          0.04461157]]], dtype=float32)&gt;</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066575"></a>Here, you can see that if we print a <span class="fm-code-in-text">tf.Variable</span> it is possible to see its attributes such as the following:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1066576"></a>The name of the variable</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1066577"></a>The shape of the variable</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1066578"></a>The data type of the variable</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1066579"></a>The initial value of the variable</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1066580"></a>You can also convert your <span class="fm-code-in-text">tf.Variable</span> to a NumPy array with a single line using</p>
  <pre class="programlisting">arr = v1.numpy()</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066583"></a>You can then validate the result yourself by printing the Python variable <span class="fm-code-in-text">arr</span><a class="calibre8" id="marker-1066582"></a> using</p>
  <pre class="programlisting">print(arr) </pre>

  <p class="body"><a class="calibre8" id="pgfId-1066585"></a>which will return</p>
  <pre class="programlisting">&gt;&gt;&gt; [2. 2. 2. 2.]</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066587"></a>A key characteristic of a <span class="fm-code-in-text">tf.Variable</span> is that you can change the value of its elements as required even after it is initialized. For example, to manipulate individual elements or slices of a <span class="fm-code-in-text">tf.Variable</span>, you can use the <span class="fm-code-in-text">assign()</span> operation<a class="calibre8" id="marker-1066588"></a> as follows.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066589"></a>For the purpose of this exercise, let us assume the following TensorFlow variable, which is a matrix initialized with zeros that has four rows and three columns:</p>
  <pre class="programlisting">v = tf.Variable(np.zeros(shape=[4,3]), dtype='float32')</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066591"></a>You can change the element in the first (i.e., index 0) row and third (i.e., index 2) column as follows:</p>
  <pre class="programlisting">v = v[0,2].assign(1)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066593"></a>This will produce the following array:</p>
  <pre class="programlisting">&gt;&gt;&gt; [[0. 0. 1.]
     [0. 0. 0.]
     [0. 0. 0.]
     [0. 0. 0.]]</pre>

  <p class="fm-callout"><a id="pgfId-1066598"></a><span class="fm-callout-head">NOTE</span> Remember that Python uses zero-based indexing. This means that indexing starts from zero (not one). For example, if you want to get the second element of a vector <span class="fm-code-in-text1">vec</span>, you would use <span class="fm-code-in-text1">vec[1]</span>.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066599"></a>You can also change values using slicing as follows. Here, we are changing the values that lie in the last two rows and first two columns:</p>
  <pre class="programlisting">v = v[2:, :2].assign([[3,3],[3,3]])</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066601"></a>This results in</p>
  <pre class="programlisting">&gt;&gt;&gt; [[0. 0. 1.]
     [0. 0. 0.]
     [3. 3. 0.]
     [3. 3. 0.]]</pre>

  <p class="fm-head2"><a id="pgfId-1066606"></a>Exercise 2</p>

  <p class="body"><a class="calibre8" id="pgfId-1066607"></a>Can you write the code to create a <span class="fm-code-in-text">tf.Variable</span> that has the following values and has type <span class="fm-code-in-text">int16</span>? You can use <span class="fm-code-in-text">np.array()</span> for this<a class="calibre8" id="marker-1066608"></a><a class="calibre8" id="marker-1066609"></a> purpose.</p>
  <pre class="programlisting">1 2 3
4 3 2</pre>

  <h3 class="fm-head1" id="sigil_toc_id_28"><a id="pgfId-1066612"></a>2.2.2 Understanding tf.Tensor</h3>

  <p class="body"><a class="calibre8" id="pgfId-1066615"></a>As<a class="calibre8" id="marker-1066613"></a><a class="calibre8" id="marker-1066614"></a> we have seen, <span class="fm-code-in-text">tf.Tensor</span> is the output of performing a TensorFlow operation on some data (e.g., on a <span class="fm-code-in-text">tf.Variable</span> or a <span class="fm-code-in-text">tf.Tensor</span>). <span class="fm-code-in-text">tf.Tensor</span> objects are heavily used when defining machine learning models, as they are used to store inputs, interim outputs of layers, and final outputs of the model. So far, we have looked mostly at vectors (one dimension) and matrices (two dimension). However, there’s nothing stopping us from creating n-dimensional data structures. Such an n-dimensional data structure is known as a <i class="fm-italics">tensor</i><a class="calibre8" id="marker-1066616"></a>. Table 2.4 shows a few examples of tensors.</p>

  <p class="fm-table-caption"><a id="pgfId-1068487"></a>Table 2.4 Examples of tensors</p>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre12">
      <col class="calibre13" span="1" width="50%"/>
      <col class="calibre13" span="1" width="50%"/>
    </colgroup>

    <tr class="calibre14">
      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1068491"></a><b class="fm-bold">Description</b></p>
      </th>

      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1068493"></a><b class="fm-bold">Example</b></p>
      </th>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068495"></a>A 2D tensor with two rows and four columns</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068497"></a></p>
        <pre class="programlisting">[
 [1,3,5,7],
 [2,4,6,8]
]</pre>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068499"></a>A 4D tensor of size 2 × 3 × 2 × 1</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068501"></a></p>
        <pre class="programlisting">[
  [
    [[1],[2]],
    [[2],[3]],
    [[3],[4]]
  ],
  [
    [[1],[2]],
    [[2],[3]],
    [[3],[4]]
  ]
]</pre>
      </td>
    </tr>
  </table>

  <p class="body"><a class="calibre8" id="pgfId-1066647"></a>Tensors also have axes. Each dimension of the tensor is considered an axis. Figure 2.6 depicts the axes of a 3D tensor.</p>

  <p class="fm-figure"><img alt="02-06" class="calibre10" src="../../OEBPS/Images/02-06.png" width="383" height="178"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077471"></a>Figure 2.6 A 2 × 4 × 3 tensor with the three axes. The first axis (axis 0) is the row dimension, the second axis (axis 1) is the column axis, and the final axis (axis 2) is the depth axis.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066654"></a>Technically, a tensor can also have just a single dimension (i.e., vector) or be a scalar. An important distinction to make is how the terms <i class="fm-italics">tensor</i> and <span class="fm-code-in-text">tf.Tensor</span> are used. We will use <i class="fm-italics">tensor/vector/scalar</i><a class="calibre8" id="marker-1066655"></a> to refer to a tensor when we are discussing mathematical aspects of our models. We will refer to any data-related output produced by our TensorFlow code as a <span class="fm-code-in-text">tf.Tensor</span>.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066656"></a>Next we will discuss a few instances where you will end up with a <span class="fm-code-in-text">tf.Tensor</span>. For example, you can produce a <span class="fm-code-in-text">tf.Tensor</span> by multiplying a <span class="fm-code-in-text">tf.Variable</span> with a constant:</p>
  <pre class="programlisting">v = tf.Variable(np.ones(shape=[4,3]), dtype='float32')
b = v * 3.0</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066659"></a>If you analyze the type of the object produced after the previous operation using <span class="fm-code-in-text">print(type(b).__name__)</span>, you will see the following output:</p>
  <pre class="programlisting">&gt;&gt;&gt; EagerTensor</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066662"></a><span class="fm-code-in-text">EagerTensor</span><a class="calibre8" id="marker-1066661"></a> is a class inherited from <span class="fm-code-in-text">tf.Tensor.</span> It is a special type of <span class="fm-code-in-text">tf.Tensor</span>, the value of which is evaluated eagerly (i.e., immediately after defined). You can verify that <span class="fm-code-in-text">EagerTensor</span> is, in fact, a <span class="fm-code-in-text">tf.Tensor</span> by executing the following command:</p>
  <pre class="programlisting">assert isinstance(b, tf.Tensor)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066664"></a>You can also produce a <span class="fm-code-in-text">tf.Tensor</span> by adding a <span class="fm-code-in-text">tf.Tensor</span> to another <span class="fm-code-in-text">tf.Tensor</span></p>
  <pre class="programlisting">a = tf.constant(2, shape=[4], dtype='float32')
b = tf.constant(3, shape=[4], dtype='float32')
c = tf.add(a,b)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066668"></a>where <span class="fm-code-in-text">print(c)</span> will yield</p>
  <pre class="programlisting">&gt;&gt;&gt; [5. 5. 5. 5]</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066670"></a>Here, <span class="fm-code-in-text">tf.constant()</span> is used to produce <span class="fm-code-in-text">tf.Tensor</span> objects <span class="fm-code-in-text">a</span> and <span class="fm-code-in-text">b</span>. By adding <span class="fm-code-in-text">a</span> and <span class="fm-code-in-text">b</span>, you will get a tensor <span class="fm-code-in-text">c</span> of type <span class="fm-code-in-text">tf.Tensor</span>. As before, you can validate this claim by running</p>
  <pre class="programlisting">assert isinstance(c, tf.Tensor)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066672"></a>The key difference between a <span class="fm-code-in-text">tf.Variable</span> and a <span class="fm-code-in-text">tf.Tensor</span> is that <span class="fm-code-in-text">tf.Variable</span> allows its values to change even after the variable is initialized (known as a mutable structure). However, once you initialize a <span class="fm-code-in-text">tf.Tensor</span>, you cannot change it during the lifetime of the execution (known as an <i class="fm-italics">immutable data structure</i><a class="calibre8" id="marker-1066673"></a>). <span class="fm-code-in-text">tf.Variable</span> is a mutable data structure, whereas <span class="fm-code-in-text">tf.Tensor</span> is an immutable data structure.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066674"></a>Let’s see what happens if you try to change the value of a <span class="fm-code-in-text">tf.Tensor</span> after it’s initialized:</p>
  <pre class="programlisting">a = tf.constant(2, shape=[4], dtype='float32')
a = a[0].assign(2.0)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066677"></a>You will get the following error:</p>
  <pre class="programlisting">---------------------------------------------------------------------------
 
AttributeError                            Traceback (most recent call last)
 
&lt;ipython-input-19-6e4e6e519741&gt; in &lt;module&gt;()
      1 a = tf.constant(2, shape=[4], dtype='float32')
----&gt; 2 a = a[0].assign(2.0)
 
AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066687"></a>Clearly, TensorFlow isn’t amused by our rebellious act of trying to modify <span class="fm-code-in-text">tf.Tensor</span> objects.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1066688"></a>Tensor Zoo</p>

    <p class="fm-sidebar-text"><a id="pgfId-1066689"></a>TensorFlow has an arsenal of different Tensor types for attacking various problems. Here are a few different Tensor types available in TensorFlow:</p>

    <p class="fm-sidebar-text"><br class="calibre2"/></p>

    <p class="fm-sidebar-text"><a id="pgfId-1066690"></a><span class="fm-code-in-text1">RaggedTensor</span>—A type of data used for variable sequence-length data sets that cannot be represented as a matrix efficiently</p>

    <p class="fm-sidebar-text"><a id="pgfId-1066691"></a><span class="fm-code-in-text1">TensorArray</span>—A dynamic-sized data structure that can start small and stretch as more data is added (similar to a Python list)</p>

    <p class="fm-sidebar-text"><a id="pgfId-1066692"></a><span class="fm-code-in-text1">SparseTensor</span>—A type of data used to represent sparse data (e.g., a user-by-movie rating matrix)</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1066694"></a>In the next subsection, we will discuss some of the popular TensorFlow operations.</p>

  <p class="fm-head2"><a id="pgfId-1066695"></a>Exercise 3</p>

  <p class="body"><a class="calibre8" id="pgfId-1066696"></a>Can you write the code to create a <span class="fm-code-in-text">tf.Tensor</span> that is initialized with values sampled from a normal distribution and that has the shape 4 × 1 × 5? You can use <span class="fm-code-in-text">np.random .normal()</span> for this<a class="calibre8" id="marker-1066697"></a><a class="calibre8" id="marker-1066698"></a> purpose.</p>

  <h3 class="fm-head1" id="sigil_toc_id_29"><a id="pgfId-1066699"></a>2.2.3 Understanding tf.Operation</h3>

  <p class="body"><a class="calibre8" id="pgfId-1066702"></a>The<a class="calibre8" id="marker-1066700"></a><a class="calibre8" id="marker-1066701"></a> backbone of TensorFlow that allows you to do useful things with the data are the operations available. For example, one of the core operations in a deep network is matrix multiplication, which makes TensorFlow a great tool for implementing core operations. Like matrix multiplication, TensorFlow offers a wide range of low-level operations that can be used in TensorFlow. A full list of operations available via the TensorFlow API can be found at <span class="fm-hyperlink"><a class="url" href="http://mng.bz/aDWY">http://mng.bz/aDWY</a></span>.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066703"></a>Let’s discuss some popular arithmetic operations you have at your disposal. First, you have basic arithmetic operations such as addition, subtraction, multiplication, and division. You can perform these just like you would with normal Python variables. To demonstrate this, let’s assume the following vectors:</p>
  <pre class="programlisting">import tensorflow as tf
import numpy as np
 
a = tf.constant(4, shape=[4], dtype='float32')
b = tf.constant(2, shape=[4], dtype='float32')</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066709"></a>We can look at what <span class="fm-code-in-text">a</span> and <span class="fm-code-in-text">b</span> look like by executing the following</p>
  <pre class="programlisting">print(a)
print(b)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066712"></a>which gives</p>
  <pre class="programlisting">&gt;&gt;&gt; tf.Tensor([4. 4. 4. 4.], shape=(4,), dtype=float32)
&gt;&gt;&gt; tf.Tensor([2. 2. 2. 2.], shape=(4,), dtype=float32)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066715"></a>Performing addition on <span class="fm-code-in-text">a</span> and <span class="fm-code-in-text">b</span></p>
  <pre class="programlisting">c = a+b
print(c)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066718"></a>gives</p>
  <pre class="programlisting">&gt;&gt;&gt; tf.Tensor([6. 6. 6. 6.], shape=(4,), dtype=float32)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066720"></a>Performing multiplication on <span class="fm-code-in-text">a</span> and <span class="fm-code-in-text">b</span></p>
  <pre class="programlisting">e = a*b
print(e)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066723"></a>gives</p>
  <pre class="programlisting">&gt;&gt;&gt; tf.Tensor([8. 8. 8. 8.], shape=(4,), dtype=float32)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066725"></a>You can also do logical comparisons between tensors. Assuming</p>
  <pre class="programlisting">a = tf.constant([[1,2,3],[4,5,6]])
b = tf.constant([[5,4,3],[3,2,1]])</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066728"></a>and checking for element-wise equality</p>
  <pre class="programlisting">equal_check = (a==b)
print(equal_check)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066731"></a>gives</p>
  <pre class="programlisting">&gt;&gt;&gt; tf.Tensor(
    [[False False  True]
     [False False False]], shape=(2, 3), dtype=bool) </pre>

  <p class="body"><a class="calibre8" id="pgfId-1066735"></a>Checking less than or equal elements</p>
  <pre class="programlisting">leq_check = (a&lt;=b)
print(leq_check)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066738"></a>gives</p>
  <pre class="programlisting">&gt;&gt;&gt; tf.Tensor(
    [[ True  True  True]
     [False False False]], shape=(2, 3), dtype=bool)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066742"></a>Next, you have reduction operators that allow you to reduce a tensor (e.g., minimum/ maximum/sum/product) on a specific axis or all axes:</p>
  <pre class="programlisting">a = tf.constant(np.random.normal(size=[5,4,3]), dtype='float32')</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066744"></a>Here, <span class="fm-code-in-text">a</span> is a <span class="fm-code-in-text">tf.Tensor</span> that looks like this:</p>
  <pre class="programlisting">&gt;&gt;&gt; tf.Tensor(
    [[[-0.7665215   0.9611947   1.456347  ]
      [-0.52979267 -0.2647674  -0.57217133]
      [-0.7511135   2.2282166   0.6573406 ]
      [-1.1323775   0.3301812   0.1310132 ]]
     ...
     [[ 0.42760614  0.17308706 -0.90879506]
      [ 0.5347165   2.569637    1.3013649 ]
      [ 0.95198756 -0.74183583 -1.2316796 ]
      [-0.03830088  1.1367576  -1.2704859 ]]], shape=(5, 4, 3), dtype=float32)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066755"></a>Let’s first get the sum of all elements of this tensor. In other words, reduce the tensor on all axes:</p>
  <pre class="programlisting">red_a1 = tf.reduce_sum(a)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066757"></a>This produces</p>
  <pre class="programlisting">&gt;&gt;&gt; -4.504758</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066759"></a>Next, let’s get the product on axis 0 (i.e., element-wise product of each row of <span class="fm-code-in-text">a</span>):</p>
  <pre class="programlisting">red_a2 = tf.reduce_prod(a, axis=0)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066761"></a>This produces</p>
  <pre class="programlisting">&gt;&gt;&gt; [[-0.04612858  0.45068324  0.02033644]
     [-0.27674386 -0.03757533 -0.33719817]
     [-1.4913832  -2.1016302  -0.39335614]
     [-0.00213956  0.14960718  0.01671476]]</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066766"></a>We will now get the minimum over multiple axes (i.e., 0 and 1):</p>
  <pre class="programlisting">red_a3 = tf.reduce_min(a, axis=[0,1])</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066768"></a>This produces</p>
  <pre class="programlisting">&gt;&gt;&gt; [-1.6531237 -1.6245098 -1.4723392]</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066770"></a>You can see that whenever you perform a reduction operation on a certain dimension, you are losing that dimension. For example, if you have a tensor of size [6,4,2] and reduce that tensor on axis 1 (i.e., second axis), you will have a tensor of size [6,2]. In certain instances, you need to keep this dimension there while reducing the tensor (resulting in a [6,1,2]-shaped tensor). One such instance is to make your tensor broadcast compatible with another tensor (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/g4Zn">http://mng.bz/g4Zn</a></span>). <i class="fm-italics">Broadcasting</i><a class="calibre8" id="marker-1066771"></a> is a term used to describe how scientific computation tools (e.g., NumPy/TensorFlow) treat tensors during arithmetic operations. In such situations, you can set the <span class="fm-code-in-text">keepdims</span> parameter<a class="calibre8" id="marker-1066772"></a> to <span class="fm-code-in-text">True</span> (which defaults to <span class="fm-code-in-text">False</span>). You can see the difference in the shape of the final output</p>
  <pre class="programlisting"># Reducing with keepdims=False
red_a1 = tf.reduce_min(a, axis=1)
print(red_a1.shape)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066776"></a>which produces</p>
  <pre class="programlisting">&gt;&gt;&gt; [5,3]
 
# Reducing with keepdims=True
red_a2 = tf.reduce_min(a, axis=1, keepdims=True)
print(red_a2.shape)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066782"></a>This produces</p>
  <pre class="programlisting">&gt;&gt;&gt; red_a2.shape = [5,1,3]</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066784"></a>Several other important functions are outlined in table 2.5.</p>

  <p class="fm-table-caption"><a id="pgfId-1068614"></a>Table 2.5 Mathematical functions offered in TensorFlow</p>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre12">
      <col class="calibre13" span="1" width="15%"/>
      <col class="calibre13" span="1" width="15%"/>
      <col class="calibre13" span="1" width="70%"/>
    </colgroup>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="3">
        <p class="fm-table-body"><a id="pgfId-1068914"></a><span class="fm-code-in-figurecaption">tf.argmax</span><a id="marker-1068913"></a></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068916"></a>Description</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068918"></a>Computes the index of a maximum value on a given axis. For example, the following example shows how to compute <span class="fm-code-in-figurecaption">tf.argmax</span> on axis 0.</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068628"></a>Usage</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068630"></a><span class="fm-code-in-figurecaption">d = tf.constant([[1,2,3],[3,4,5],[6,5,4]])d_max1 = tf.argmax(d, axis=0)</span></p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068634"></a>Result</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068636"></a><span class="fm-code-in-figurecaption">tf.Tensor ([2,2,0])</span></p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="3">
        <p class="fm-table-body"><a id="pgfId-1068638"></a><span class="fm-code-in-figurecaption">tf.argmin</span><a id="marker-1068832"></a></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068640"></a>Description</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068642"></a>Computes the index of a minimum value on a given axis. For example, the following example shows how to compute <span class="fm-code-in-figurecaption">tf.argmin</span> on axis 1.</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068646"></a>Usage</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068648"></a><span class="fm-code-in-figurecaption">d = tf.constant([[1,2,3],[3,4,5],[6,5,4]])d_min1 = tf.argmin(d, axis=1)</span></p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068652"></a>Result</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068654"></a><span class="fm-code-in-figurecaption">tf.Tensor([[0],[0],[0]])</span></p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="3">
        <p class="fm-table-body"><a id="pgfId-1068656"></a><span class="fm-code-in-figurecaption">tf.cumsum</span><a id="marker-1068851"></a></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068658"></a>Description</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068660"></a>Computes the cumulative sum of a vector or a tensor on a given axis</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068664"></a>Usage</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068666"></a><span class="fm-code-in-figurecaption">e = tf.constant([1,2,3,4,5])e_cumsum = tf.cumsum(e)</span></p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068670"></a>Result</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1068672"></a><span class="fm-code-in-figurecaption">tf.Tensor([1,3,6,10,15])</span></p>
      </td>
    </tr>
  </table>

  <p class="body"><a class="calibre8" id="pgfId-1066849"></a>We conclude our discussion about basic primitives of TensorFlow here. Next we will discuss some of the computations that are commonly used in neural network models.</p>

  <p class="fm-head2"><a id="pgfId-1066850"></a>Exercise 4</p>

  <p class="body"><a class="calibre8" id="pgfId-1066851"></a>There is another function for computing mean called <span class="fm-code-in-text">tf.reduce_mean()</span>. Given the <span class="fm-code-in-text">tf.Tensor</span> object <span class="fm-code-in-text">a,</span> which contains the following values, can you compute the mean for<a class="calibre8" id="marker-1066852"></a><a class="calibre8" id="marker-1066853"></a> each<a class="calibre8" id="marker-1066854"></a> column?</p>
  <pre class="programlisting">0.5 0.2 0.7
0.2 0.3 0.4
0.9 0.1 0.1</pre>

  <h2 class="fm-head" id="sigil_toc_id_30"><a id="pgfId-1066858"></a>2.3 Neural network-related computations in TensorFlow</h2>

  <p class="body"><a class="calibre8" id="pgfId-1066861"></a>Here<a class="calibre8" id="marker-1066859"></a><a class="calibre8" id="marker-1066860"></a> we will talk about some key low-level operations that underpin deep neural networks. Let’s say you are taking a computer vision class at school. For your assignment, you have to manipulate an image using various mathematical operations to achieve various effects. We will be using the famous image of a baboon (figure 2.7), which is a popular choice for computer vision problems.</p>

  <p class="fm-figure"><img alt="02-07" class="calibre10" src="../../OEBPS/Images/02-07.png" width="380" height="380"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077505"></a>Figure 2.7 Image of a baboon</p>

  <h3 class="fm-head1" id="sigil_toc_id_31"><a id="pgfId-1066868"></a>2.3.1 Matrix multiplication</h3>

  <p class="body"><a class="calibre8" id="pgfId-1066872"></a>Your<a class="calibre8" id="marker-1066869"></a><a class="calibre8" id="marker-1066870"></a><a class="calibre8" id="marker-1066871"></a> first task is to convert the image from RGB to grayscale. For this, you must employ matrix multiplication. Let’s first understand what matrix multiplication is.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1066873"></a>Story of Lena</p>

    <p class="fm-sidebar-text"><a id="pgfId-1066874"></a>Though we are using an image of a baboon for the exercises, there’s a long-standing tradition of using Lena’s (a Swedish model) photo to demonstrate various computer vision algorithms. There is a very interesting backstory behind how this became a norm for computer vision problems, which you can read at <span class="fm-hyperlink"><a class="url" href="http://mng.bz/enrZ">http://mng.bz/enrZ</a></span>.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1066877"></a>You perform matrix multiplication between two tensors using the <span class="fm-code-in-text">tf.matmul()</span> function<a class="calibre8" id="marker-1066876"></a>. For two matrices, <span class="fm-code-in-text">tf.matmul()</span> performs matrix multiplication (e.g., if you have <span class="fm-code-in-text">a</span> of size <span class="fm-code-in-text">[4,3]</span> and <span class="fm-code-in-text">b</span> of size <span class="fm-code-in-text">[3,2]</span>, matrix multiplication results in a <span class="fm-code-in-text">[4,2]</span> tensor. Figure 2.8 illustrates the matrix multiplication operation.</p>

  <p class="fm-figure"><img alt="02-08" class="calibre10" src="../../OEBPS/Images/02-08.png" width="503" height="381"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077539"></a>Figure 2.8 Matrix multiplication between a 4 × 3 matrix and 3 × 2 matrix, resulting in a 4 × 2 matrix</p>

  <p class="body"><a class="calibre8" id="pgfId-1066884"></a>More generally, if you have an <span class="fm-code-in-text">n x m</span> matrix (<span class="fm-code-in-text">a</span>) and a <span class="fm-code-in-text">m x p</span> matrix (<span class="fm-code-in-text">b</span>), the result of matrix multiplication c is given by</p>

  <p class="fm-equation"><img alt="02_08a" class="calibre10" src="../../OEBPS/Images/02_08a.png" width="163" height="83"/><br class="calibre2"/>
  <a id="pgfId-1069119"></a></p>

  <p class="body"><a class="calibre8" id="pgfId-1066889"></a>However, if you have high-dimensional tensors <span class="fm-code-in-text">a</span> and <span class="fm-code-in-text">b</span>, the sum product over the last axis of <span class="fm-code-in-text">a</span> and second-to-last axis of <span class="fm-code-in-text">b</span> will be performed. Both <span class="fm-code-in-text">a</span> and <span class="fm-code-in-text">b</span> tensors need to have identical dimensionality except for the last two axes. For example, if you have a tensor <span class="fm-code-in-text">a</span> of size <span class="fm-code-in-text">[3,5,7]</span> and <span class="fm-code-in-text">b</span> of size <span class="fm-code-in-text">[3,7,8]</span>, the result would be a <span class="fm-code-in-text">[3,5,8]</span>-sized tensor.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066890"></a>Coming back to our problem, given three RGB pixels, you can convert it to a grayscale pixel using</p>

  <p class="fm-equation"><a id="pgfId-1066891"></a>0.3 * R + 0.59 * G + 0.11 * B</p>

  <p class="body"><a class="calibre8" id="pgfId-1066892"></a>This is a common operation for converting any RGB image to grayscale (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/p2M0">http://mng.bz/p2M0</a></span>), which can be important depending on the problem at hand. For example, to recognize digits from images, color is not so important. By converting images to grayscale, you are essentially helping the model by reducing the size of the input (one channel instead of three) and by removing noisy features (i.e., color information).</p>

  <p class="body"><a class="calibre8" id="pgfId-1066893"></a>Given a 512 × 512 × 3 image, if you multiply that with a 3 × 1 array representing the weights provided, you will get the grayscale image of size 512 × 512 × 1. Then we need to remove the last dimension of the grayscale image (as it is one), and we end up with a matrix of size 512 × 512. For this you can use the <span class="fm-code-in-text">tf.squeeze()</span> function<a class="calibre8" id="marker-1066894"></a>, which removes any dimensions that are of size one (see the next listing).</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1066896"></a>Listing 2.2 Converting an RGB image to grayscale using matrix multiplication</p>
  <pre class="programlisting">from PIL import Image                                          <span class="fm-combinumeral">❶</span>
import tensorflow as tf
import numpy as np
 
x_rgb = np.array(Image.open("baboon.jpg")).astype('float32')   <span class="fm-combinumeral">❷</span>
x_rgb = tf.constant(x_rgb)                                     <span class="fm-combinumeral">❸</span>
 
grays = tf.constant([[0.3], [0.59] ,[0.11]])                   <span class="fm-combinumeral">❹</span>
 
x = tf.matmul(x_rgb, grays)                                    <span class="fm-combinumeral">❺</span>
x = tf.squeeze(x)                                              <span class="fm-combinumeral">❻</span></pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1075714"></a><span class="fm-combinumeral">❶</span> PIL is a Python library for basic image manipulation</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1075750"></a><span class="fm-combinumeral">❷</span> The RGB image of size 512 × 512 × 3 loaded as a NumPy array</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1075767"></a><span class="fm-combinumeral">❸</span> The NumPy array is converted to a tf.Tensor.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1075784"></a><span class="fm-combinumeral">❹</span> The RGB weights as a 3 × 1 array</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1075801"></a><span class="fm-combinumeral">❺</span> Performing matrix multiplication to get the black-and-white image</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1075715"></a><span class="fm-combinumeral">❻</span> Getting rid of the last dimension, which is 1</p>

  <p class="body"><a class="calibre8" id="pgfId-1066914"></a>Matrix multiplication is an important operation in fully connected networks as well. To go from an input layer to a hidden layer, we employ matrix multiplication and add operation. For the moment, we will ignore the nonlinear activation, as it is just an element-wise transformation. Figure 2.9 visualizes the hidden layer computation of the MLP you built<a class="calibre8" id="marker-1071632"></a><a class="calibre8" id="marker-1071633"></a><a class="calibre8" id="marker-1071634"></a> earlier.</p>

  <p class="fm-figure"><img alt="02-09" class="calibre10" src="../../OEBPS/Images/02-09.png" width="864" height="328"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077585"></a>Figure 2.9 An illustration of the computations taking place in a hidden layer. x is the input (1 × 4), W is the weight matrix (4 × 3), b is the bias (1 × 3), and finally, h is the output (1 × 3).</p>

  <h3 class="fm-head1" id="sigil_toc_id_32"><a id="pgfId-1066924"></a>2.3.2 Convolution operation</h3>

  <p class="body"><a class="calibre8" id="pgfId-1066928"></a>The<a class="calibre8" id="marker-1066925"></a><a class="calibre8" id="marker-1066926"></a><a class="calibre8" id="marker-1066927"></a> next task is to implement an edge-detection algorithm. Knowing that you can detect edges using the convolution operation, you also want to show your skills off by achieving this with TensorFlow. The good news is, you can!</p>

  <p class="body"><a class="calibre8" id="pgfId-1066929"></a>The convolution operation is essential in convolutional neural networks, which are deep networks heavily utilized for image-related machine learning tasks (e.g., image classification, object detection). A convolution operation shifts a <i class="fm-italics">window</i> (also known as a <i class="fm-italics">filter</i> or a <i class="fm-italics">kernel</i>) over the data while producing a single value at every position. The convolution window will have some value at each location. And at a given position, the values in the convolution window are element-wise multiplied and summed over with what’s overlapping with that window in the data to produce the final value for that location. The convolution operation is shown in figure 2.10.</p>

  <p class="fm-figure"><img alt="02-10" class="calibre10" src="../../OEBPS/Images/02-10.png" width="700" height="450"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077619"></a>Figure 2.10 Computational steps of the convolution operation</p>

  <p class="body"><a class="calibre8" id="pgfId-1066936"></a>Depending on the values you choose for the convolution window, you can produce some unique effects. You can try out some popular kernels at <span class="fm-hyperlink"><a class="url" href="https://setosa.io/ev/image-kernels/">https://setosa.io/ev/image-kernels/</a></span>. Edge detection is also a popular computer vision technique that can be achieved using the convolution operation. TensorFlow provides the <span class="fm-code-in-text">tf.nn.convolution()</span> function<a class="calibre8" id="marker-1066937"></a> to perform convolution.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066938"></a>Initially, we have our black-and-white image of the baboon stored as a <span class="fm-code-in-text">tf.Tensor</span> in the variable <span class="fm-code-in-text">x</span>. <span class="fm-code-in-text">x</span> is a matrix of size 512 × 512. Let’s create a new variable <span class="fm-code-in-text">y</span> from this:</p>
  <pre class="programlisting">y = tf.constant(x)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066940"></a>Next, let’s define our edge detection filter. We will use an edge detection filter known as an <i class="fm-italics">approximate Laplacian filter</i>, which is a 3 × 3 matrix filled with value -1 except for the middle-most value, which is 8. Note how the sum of the kernel is zero:</p>
  <pre class="programlisting">filter = tf.Variable(np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]).astype('float32'))</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066944"></a>Next, we need to reshape <span class="fm-code-in-text">y</span> and <span class="fm-code-in-text">filter</span>, because the <span class="fm-code-in-text">tf.nn.convolution()</span> function<a class="calibre8" id="marker-1066943"></a> accepts a very specifically shaped input and a filter. The first constraint is that your <span class="fm-code-in-text">y</span> and <span class="fm-code-in-text">filter</span> should have the same rank. Rank here refers to the number of dimensionalities in the data. Here we have rank 2 tensors and will perform 2D convolution. To perform 2D convolution, both the input and the kernel need to be of rank 4. Therefore, we need to reshape the input and the kernel in a few steps:</p>

  <ol class="calibre11">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1066945"></a>Add two more dimensions at the beginning and end of the input. The dimension at the beginning represents the batch dimension, and the last dimension represents the channel dimension (e.g., RGB channels of an image). Though the values will be 1 in our example, we still need those dimensions to be present (e.g., an image of size <span class="fm-code-in-text">[512,512]</span> will be reshaped to <span class="fm-code-in-text">[1,512,512,1]</span>).</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1066946"></a>Add two more dimensions of size 1 at the end of the filter. These new dimensions represent the incoming and outgoing channels. We have a single channel (i.e., grayscale) coming in, and we want to produce a single channel (i.e., grayscale) as well (e.g., a kernel of size <span class="fm-code-in-text">[3,3]</span> will be reshaped to <span class="fm-code-in-text">[3,3,1,1]</span>).</p>
    </li>
  </ol>

  <p class="fm-callout"><a id="pgfId-1066947"></a><span class="fm-callout-head">NOTE</span> Rank of a tensor refers to the number of dimensions of that tensor. This is different from the rank of a matrix.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066948"></a>Don’t worry if you don’t fully understand why we added these additional dimensions. This will make more sense when we discuss the convolution operation in the context of convolutional neural networks in a later chapter. For now, you only need to understand the high-level behavior of the convolution operation. In TensorFlow, you can reshape <span class="fm-code-in-text">y</span> and <span class="fm-code-in-text">filter</span> as follows:</p>
  <pre class="programlisting">y_reshaped = tf.reshape(y, [1,512,512,1])
filter_reshaped = tf.reshape(filter, [3,3,1,1])</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066951"></a>Here, <span class="fm-code-in-text">y</span> is a 512 × 512 tensor. The expression <span class="fm-code-in-text">tf.reshape(y, [1,512,512,1])</span> converts <span class="fm-code-in-text">y</span> (i.e., a 2D tenor) to a 4D tensor of size 1 × 512 × 512 × 1. Similarly, the <span class="fm-code-in-text">filter</span> (i.e., a 2D tensor of size 3 × 3) is reshaped to a 4D tensor of size 3 × 3 × 1 × 1. Note that the total number of elements is unchanged during the reshaping. Now you can compute the convolution output as follows:</p>
  <pre class="programlisting">y_conv = tf.nn.convolution(y_reshaped, filter_reshaped)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066953"></a>You can visualize the result of edge detection and compare that to the original image, as shown in figure 2.11.</p>

  <p class="fm-figure"><img alt="02-11" class="calibre10" src="../../OEBPS/Images/02-11.png" width="703" height="356"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077653"></a>Figure 2.11 Original black-and-white image versus result of edge detection</p>

  <p class="body"><a class="calibre8" id="pgfId-1066963"></a>In the next section, we will discuss another operation known as the pooling<a class="calibre8" id="marker-1066960"></a><a class="calibre8" id="marker-1066961"></a><a class="calibre8" id="marker-1066962"></a> operation.</p>

  <h3 class="fm-head1" id="sigil_toc_id_33"><a id="pgfId-1066964"></a>2.3.3 Pooling operation</h3>

  <p class="body"><a class="calibre8" id="pgfId-1066968"></a>We<a class="calibre8" id="marker-1066965"></a><a class="calibre8" id="marker-1066966"></a><a class="calibre8" id="marker-1066967"></a> are off to the next task, which is to resize the image resultant after edge detection by halving the width and height of the image. For example, if we have a 512 × 512 image and need to rescale it to 256 × 256, the <i class="fm-italics">pooling operation</i> is the best way to achieve this easily. The pooling (or sub-sampling) operation is commonly used in convolutional neural networks for this reason: to reduce the size of the output so fewer parameters can be used to learn from data.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1066969"></a>Why is it called the pooling operation?</p>

    <p class="fm-sidebar-text"><a id="pgfId-1066970"></a>The reason why the sub-sampling operation is also called “pooling” probably has its roots in the word’s meaning, as well as in statistics. The word <i class="fm-italics">pooling</i> is used to describe combining things into a single entity, which is exactly what is done in this operation (e.g., by means of averaging or taking maximum). In statistics, you will find the term <i class="fm-italics">pooled variance</i><a id="marker-1075071"></a>, which is a weighted average of the variance between two populations (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/OGdO">http://mng.bz/OGdO</a></span>), essentially combining two variances into a single variance.</p>

    <p class="fm-sidebar-text"><br class="calibre2"/></p>

    <p class="fm-sidebar-text"><a id="pgfId-1066973"></a>In TensorFlow, you can call the <span class="fm-code-in-text1">tf.nn.max_pool()</span> function<a id="marker-1070359"></a><a id="marker-1076904"></a> to perform max pooling and <span class="fm-code-in-text1">tf.nn.avg_pool()</span> for average pooling:</p>
    <pre class="programlisting">z_avg = tf.nn.avg_pool(y_conv, (1,2,2,1), strides=(1,2,2,1), padding='VALID')
z_max = tf.nn.max_pool(y_conv, (1,2,2,1), strides=(1,2,2,1), padding='VALID')</pre>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1066978"></a>The pooling operation is another commonly found operation in convolutional neural networks and works similarly to the convolution operation. But unlike the convolution operation, the pooling operation does not have values in the kernel. At a given location, it takes either the average or maximum value of what’s overlapping the kernel in the data. The operation that produces the average at a given location is known as average pooling, whereas the operation that produces the maximum is known as max pooling. Figure 2.12 illustrates the max pooling operation.</p>

  <p class="fm-figure"><img alt="02-12" class="calibre10" src="../../OEBPS/Images/02-12.png" width="581" height="461"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077687"></a>Figure 2.12 Max-pooling operation. The pooling window goes from one position to another on the image, while producing a single value (i.e., maximum value in the image overlapping the pooling window) at a time.</p>

  <p class="body"><a class="calibre8" id="pgfId-1066985"></a>We have <span class="fm-code-in-text">y_conv</span>, which is a 4D tensor having the shape <span class="fm-code-in-text">[1,510,510,1]</span>. You might notice that the dimensions are slightly smaller than the original image size (i.e., 512). This is because, when doing convolution with a window of size <span class="fm-code-in-text">c x c</span> (without extra padding) on an image having <span class="fm-code-in-text">h</span> height and <span class="fm-code-in-text">w</span> width, the resulting image has the dimensions <span class="fm-code-in-text">h-c+1</span> and <span class="fm-code-in-text">w-c+1</span>. We can perform pooling as shown. You can perform either average pooling or max pooling with the following functions:</p>
  <pre class="programlisting">z_avg = tf.nn.avg_pool(y_conv, (1,2,2,1), strides=(1,2,2,1), padding='VALID')
z_max = tf.nn.max_pool(y_conv, (1,2,2,1), strides=(1,2,2,1), padding='VALID')</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066989"></a>This will result in two images, <span class="fm-code-in-text">z_avg</span> and <span class="fm-code-in-text">z_max</span>; both have the shape <span class="fm-code-in-text">[1,255,255,1]</span>. In order to keep just the height and width dimensions and remove redundant dimensions of size 1, we use the <span class="fm-code-in-text">tf.squeeze()</span> function<a class="calibre8" id="marker-1066990"></a>:</p>
  <pre class="programlisting">z_avg = np.squeeze(z_avg.numpy())
z_max = np.squeeze(z_max.numpy())</pre>

  <p class="body"><a class="calibre8" id="pgfId-1066994"></a>You can plot <span class="fm-code-in-text">z_avg</span> and <span class="fm-code-in-text">z_max</span> using <span class="fm-code-in-text">matplotlib</span> (a plotting library in Python) and get the result shown in figure 2.13. The code is provided in the notebook.</p>

  <p class="fm-figure"><img alt="02-13" class="calibre10" src="../../OEBPS/Images/02-13.png" width="803" height="261"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1077782"></a>Figure 2.13 Result after edge detection versus result after average or max pooling</p>

  <p class="body"><a class="calibre8" id="pgfId-1067001"></a>Figure 2.13 shows the different effects we get with different types of pooling. If you look closely, you will see that average pooling results in more consistent and continuous lines, whereas max pooling results in a noisier image.</p>

  <p class="body"><a class="calibre8" id="pgfId-1067002"></a>Note that, unlike in the convolution operation, we are not providing a filter (or a kernel), as the pooling operation doesn’t have a kernel. But we need to pass in the dimensions of the window. These dimensions represent the corresponding dimensions of the input (i.e., it is a [batch dimension, height, width, channels] window). In addition to that, we are also passing two arguments, stride and padding. We will discuss these in detail in a later chapter.</p>

  <p class="fm-head2"><a id="pgfId-1067003"></a>Exercise 5</p>

  <p class="body"><a class="calibre8" id="pgfId-1067004"></a>You are given a grayscale image <span class="fm-code-in-text">img</span> of size 256 × 256 and a convolution filter <span class="fm-code-in-text">f</span> of size 5 × 5. Can you write the <span class="fm-code-in-text">tf.reshape()</span> function<a class="calibre8" id="marker-1067005"></a> calls and the <span class="fm-code-in-text">tf.nn.convolution()</span> operation? What would be the size of the output?</p>

  <p class="body"><a class="calibre8" id="pgfId-1067006"></a>Great work! Now you know most common operations used in deep learning networks. We will end our discussion about TensorFlow basics here. In the next chapter, we will discuss a high-level API available in TensorFlow called Keras, which is particularly useful for<a class="calibre8" id="marker-1067007"></a><a class="calibre8" id="marker-1067008"></a><a class="calibre8" id="marker-1067009"></a> model building.</p>

  <h2 class="fm-head" id="sigil_toc_id_34"><a id="pgfId-1067010"></a>Summary</h2>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1067011"></a>TensorFlow is an end-to-end machine learning framework.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1067014"></a>TensorFlow provides an ecosystem facilitating model prototyping, model<a class="calibre8" id="marker-1067012"></a><a class="calibre8" id="marker-1067013"></a> building, model monitoring, and model serving.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1067015"></a>TensorFlow 1 uses declarative graph execution style (define then run), whereas TensorFlow 2 uses imperative graph execution style (define by run).</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1067016"></a>TensorFlow provides three main building blocks: <span class="fm-code-in-text">tf.Variable</span> (for values that change over time), <span class="fm-code-in-text">tf.Tensor</span> (values that are fixed over time), and <span class="fm-code-in-text">tf.Operation</span> (transformations performed on <span class="fm-code-in-text">tf.Variable</span> and <span class="fm-code-in-text">tf.Tensor</span> objects).</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1067017"></a>TensorFlow provides several operations that are used to build neural networks such as <span class="fm-code-in-text">tf.matmul</span>, <span class="fm-code-in-text">tf.nn.convolution</span>, and <span class="fm-code-in-text">tf.nn.max_pool.</span></p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1067018"></a>You can use <span class="fm-code-in-text">tf.matmul</span> to convert an RGB image to grayscale.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1067019"></a>You can use <span class="fm-code-in-text">tf.nn.convolution</span> to detect edges in an image.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1067020"></a>You can use <span class="fm-code-in-text">tf.nn.max_pool</span> to resize an image.</p>
    </li>
  </ul>

  <h2 class="fm-head" id="sigil_toc_id_35"><a id="pgfId-1067021"></a>Answers to exercises</h2>

  <p class="body"><a class="calibre8" id="pgfId-1067022"></a><b class="fm-bold">Exercise 1:</b> 2</p>

  <p class="body"><a class="calibre8" id="pgfId-1067023"></a><b class="fm-bold">Exercise 2:</b> <span class="fm-code-in-text">tf.Variable(np.array([[1,2,3],[4,3,2]], dtype=”int16”)</span></p>

  <p class="body"><a class="calibre8" id="pgfId-1067024"></a><b class="fm-bold">Exercise 3:</b> <span class="fm-code-in-text">tf.constant(np.random.normal(size=[4,1,5]))</span></p>

  <p class="body"><a class="calibre8" id="pgfId-1067025"></a><b class="fm-bold">Exercise 4:</b> <span class="fm-code-in-text">tf.reduce_mean(a, axis=1)</span></p>

  <p class="body"><a class="calibre8" id="pgfId-1067026"></a><b class="fm-bold">Exercise 5:</b></p>
  <pre class="programlisting">img_reshaped = tf.reshape(img, [1,256,256,1])
f_reshaped = tf.reshape(f, [5,5,1,1])
y = tf.nn.convolution(img_reshaped, f_reshaped)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1067030"></a>The shape of the final output would be <span class="fm-code-in-text">[1,252,252,1]</span>. The resulting size of the convolution operation is image size - convolution window<a class="calibre8" id="marker-1067031"></a> size + 1.</p>
</div>
</div>
</body>
</html>