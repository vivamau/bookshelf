<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xml:lang="en"
      lang="en"
      xmlns="http://www.w3.org/1999/xhtml"
      xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<title>TensorFlow in Action</title>
<link rel="stylesheet" type="text/css" href="../../override_v1.css"/>
<link rel="stylesheet" type="text/css" href="../../stylesheet.css"/><link rel="stylesheet" type="text/css" href="../../page_styles.css"/>
</head>
<body>
<div id="book-content">
<div id="sbo-rt-content" class="calibre"><h1 class="tochead"><a id="pgfId-1184314"></a>15 TFX: MLOps and deploying models with TensorFlow</h1>

  <p class="co-summary-head"><a id="pgfId-1184316"></a>This chapter <a id="marker-1187112"></a>covers</p>

  <ul class="calibre9">
    <li class="co-summary-bullet"><a class="calibre8" id="pgfId-1184317"></a>Writing an end-to-end data pipeline using TFX (TensorFlow-Extended)</li>

    <li class="co-summary-bullet"><a class="calibre8" id="pgfId-1184318"></a>Training a simple neural network through the TFX Trainer API</li>

    <li class="co-summary-bullet"><a class="calibre8" id="pgfId-1184319"></a>Using Docker to containerize model serving (inference) and present it as a service</li>

    <li class="co-summary-bullet"><a class="calibre8" id="pgfId-1184320"></a>Deploying the model on your local machine so it can be used through an API</li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1184321"></a>In chapter 14, we looked at a very versatile tool that comes with TensorFlow: the TensorBoard. TensorBoard is a visualization tool that helps you understand data and models better. Among other things, it facilitates</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1184322"></a>Monitoring and tracking model performance</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184323"></a>Visualizing data inputs to models (e.g., images, audio)</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1184324"></a>Profiling models to understand their performance or memory bottlenecks</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1184325"></a>We learned how we can use the TensorBoard to visualize high-dimensional data like images and word vectors. We looked at how we can incorporate Keras callbacks to send information to the TensorBoard to visualize model performance (accuracy and loss) and custom metrics. We then analyzed the execution of the model using the CUDA profiling tool kit to understand execution patterns and memory bottlenecks.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184327"></a>In this chapter, we will explore a new domain of machine learning that has gained an enormous amount of attention in the recent past: MLOps. MLOps is derived from the terms ML and DevOps (derived from development and operations). According to Amazon Web Services, “DevOps is the combination of cultural philosophies, practices, and tools that increases an organization’s ability to deliver applications and services at high velocity: evolving and improving products at a faster pace than organizations using traditional software development and infrastructure management processes.” There is another term that goes hand in hand with MLOps, which is productionization of models. It is somewhat difficult to discriminate between the two terms as they overlap and occasionally are used interchangeably, but I like to think of these two things as follows: MLOps defines a workflow that will automate most of the steps, from collecting data to delivering a model trained on that data, with very little human intervention. Productionization is deploying a trained model (on a private server or cloud), enabling customers to use the model for its designed purpose in a robust fashion. It can include tasks such as designing scalable APIs that can scale to serve thousands of requests per second. In other words, MLOps is the journey that gets you to the destination, which is the productionization of a model.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184328"></a>Let’s discuss why it is important to have a (mostly) automated pipeline to develop machine learning models. To realize the value of it, you have to think in scale. For companies like Google, Facebook, and Amazon, machine learning is deeply rooted in the products they offer. This means hundreds if not thousands of models produce predictions every second. Moreover, with a few billion users, they can’t afford their models to go stale, which means continuously training/fine-tuning the existing models as new data is collected. MLOps can take care of this problem. MLOps can be used to ingest the collected data, train models, automatically evaluate models, and push them to the production environment if they pass a predefined validation check. A validation check is important to ensure models meet expected performance standards and to safeguard against rogue underperforming models (e.g., a rogue model can be generated due to large changes in new incoming training data, a new untested hyperparameter change that is pushed, etc.). Finally, the model is pushed to a production environment, which is accessed through a Web API to retrieve predictions for an input. Specifically, the API will provide certain endpoints (in the form of URLs) to the user that the user can visit (optionally with parameters needed to complete the request). Having said that, even for a smaller company that is relying on machine learning models, MLOps can greatly standardize and speed up the workflows of data scientists and machine learning engineers. This will greatly reduce the time data scientists and machine learning engineers spend creating such workflows from the ground up every time they work on a new project. Read more about MLOps at <span class="fm-hyperlink"><a class="url" href="http://mng.bz/Pnd9">http://mng.bz/Pnd9</a></span>.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184330"></a>How can we do MLOps in TensorFlow? Look no further than TFX (TensorFlow Extended). TFX is a library that gives you all the bells and whistles needed to implement a machine learning pipeline that will ingest data, transform data into features, train a model, and push the model to a designated production environment. This is done by defining a series of components that perform very specific tasks. In the coming sections, we will look at how to use TFX to achieve this.</p>

  <h2 class="fm-head" id="sigil_toc_id_190"><a id="pgfId-1184333"></a>15.1 Writing a data pipeline with TFX</h2>

  <p class="body"><a class="calibre8" id="pgfId-1184336"></a>Imagine <a class="calibre8" id="marker-1184334"></a>you are developing a system to predict the severity of a forest fire given the weather conditions. You have been given a data set from past observed forest fires and asked to make a model. To make sure you can provide the model as a service, you decide to create a workflow to ingest data and train a model using TFX. The first step in this is to create a data pipeline that can read the data (in CSV format) and convert it to features. As part of this pipeline, you will have a data reader (that generates examples from CSV), show summary statistics of the fields, learn the schema of the data, and convert it to a proper format the model understands.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1184337"></a>Important information about the environment</p>

    <p class="fm-sidebar-text"><a id="pgfId-1205356"></a>To run the code for this chapter, we highly recommend using a Linux environment (e.g., Ubuntu), and the instructions will be provided for that environment. TFX is not tested against a Windows environment (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/J2Y0">http://mng.bz/J2Y0</a></span>). Another important thing to note is that we will be using a slightly older version of TFX (1.6.0). At the time of writing, the latest version is 1.9.0. This is because a crucial component necessary to run TFX in interactive environments such as notebooks is broken in versions after 1.6.0. Additionally, later on in the chapter we will use a technology called Docker. It can be quite difficult to get Docker to behave in the way we need on Windows due to the highly restricted access to resources. Additionally, for this chapter, we will define a new Anaconda environment. To do that follow the following instructions:</p>

    <ul class="calibre9">
      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1184341"></a>Open a terminal window and move <span class="fm-code-in-text1">cd</span> into the <span class="fm-code-in-text1">Ch15-TFX-for-MLOps-in-TF2</span> directory in the code repository.</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1184342"></a>If you have an already activated Anaconda virtual environment (e.g., manning.tf2), deactivate it by running <span class="fm-code-in-text1">conda deactivate manning.tf2</span>.</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1184343"></a>Run <span class="fm-code-in-text1">conda create -n manning.tf2.tfx python=3.6</span> to create a new virtual Anaconda environment.</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1184344"></a>Run <span class="fm-code-in-text1">conda activate manning.tf2.tfx</span> to activate the new environment.</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1184345"></a>Run <span class="fm-code-in-text1">pip install --use-deprecated=legacy-resolver -r requirements.txt</span>.</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1184346"></a>Run <span class="fm-code-in-text1">jupyter notebook</span>.</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1184347"></a>Open the <span class="fm-code-in-text1">tfx/15.1_MLOps_with_tensorflow.ipynb</span> notebook.</p>
      </li>
    </ul>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1184349"></a>The first thing to do is download the data sets (listing 15.1). We will use a data set that has recorded historical forest fires in the Montesinho park in Portugal. The data set is freely available at <span class="fm-hyperlink"><a class="url" href="http://archive.ics.uci.edu/ml/datasets/Forest+Fires">http://archive.ics.uci.edu/ml/datasets/Forest+Fires</a></span>. It is is a CSV file with the following features:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1184351"></a><i class="fm-italics">X</i>—x-axis spatial coordinate within the Montesinho park map</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184352"></a><i class="fm-italics">Y</i>—y-axis spatial coordinate within the Montesinho park map</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184353"></a><i class="fm-italics">month</i>—Month of the year</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184354"></a><i class="fm-italics">day</i>—Day of the week</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184356"></a><i class="fm-italics">Fine Fuel Moisture Code</i> (FFMC)—Represents fuel moisture of forest litter fuels under the shade of a forest canopy</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184357"></a><i class="fm-italics">DMC</i>—A numerical rating of the average moisture content of soil</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184358"></a><i class="fm-italics">Drought Code</i> (DC)—Represents the depth of dryness in the soil</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184359"></a><i class="fm-italics">Initial Spread Index</i> (ISI)—An expected rate of fire spread</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184360"></a><i class="fm-italics">temp</i>—Temperature in Celsius degrees</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184361"></a><i class="fm-italics">RH</i>—Relative humidity in %</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184362"></a><i class="fm-italics">wind</i>—Wind speed in km/h</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184363"></a><i class="fm-italics">rain</i>—Outside rain in mm/m2</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1184364"></a><i class="fm-italics">area</i>—The burnt area of the forest (in hectares)</p>
    </li>
  </ul>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1184365"></a>Selecting features for a machine learning model</p>

    <p class="fm-sidebar-text"><a id="pgfId-1184366"></a>Feature selection for a machine learning model is not a trivial task. Often you have to understand features, inter-feature correlation, feature-target correlation, and so on before making a good judgment call on whether a feature should be used. Therefore, one should not use all the given features of a model blindly. In this case, however, as the focus is more on MLOps and less on data-science decisions, we will use all features. Using all of these features will later lend itself to explaining various options that are available when defining an MLOps pipeline.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1184368"></a>Our task will be to predict the burnt area, given all the other features. Note that predicting a continuous value such as the area warrants a regression model. Therefore, this is a regression problem, not a classification problem.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1184370"></a>Listing 15.1 Downloading the data set</p>
  <pre class="programlisting">import os
import requests
import tarfile
 
import shutil
 
if not os.path.exists(os.path.join('data', 'csv', 'forestfires.csv')):    <span class="fm-combinumeral">❶</span>
    url = "http:/ /archive.ics.uci.edu/ml/machine-learning-databases/forest-
<span class="fm-code-continuation-arrow">➥</span> fires/forestfires.csv"
    r = requests.get(url)                                                 <span class="fm-combinumeral">❷</span>
 
    if not os.path.exists(os.path.join('data', 'csv')):                   <span class="fm-combinumeral">❸</span>
        os.makedirs(os.path.join('data', 'csv'))                          <span class="fm-combinumeral">❸</span>
    
    with open(os.path.join('data', 'csv', 'forestfires.csv'), 'wb') as f: <span class="fm-combinumeral">❸</span>
        f.write(r.content)                                                <span class="fm-combinumeral">❸</span>
else:
    print("The forestfires.csv file already exists.")
    
  
if not os.path.exists(os.path.join('data', 'forestfires.names')):         <span class="fm-combinumeral">❹</span>
    
    url = "http:/ /archive.ics.uci.edu/ml/machine-learning-databases/forest-
<span class="fm-code-continuation-arrow">➥</span> fires/forestfires.names"
    r = requests.get(url)                                                 <span class="fm-combinumeral">❹</span>
 
    if not os.path.exists('data'):                                        <span class="fm-combinumeral">❺</span>
        os.makedirs('data')                                               <span class="fm-combinumeral">❺</span>
    
    with open(os.path.join('data', 'forestfires.names'), 'wb') as f:      <span class="fm-combinumeral">❺</span>
        f.write(r.content)                                                <span class="fm-combinumeral">❺</span>
        
else:
    print("The forestfires.names file already exists.")</pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1212870"></a><span class="fm-combinumeral">❶</span> If the data file is not downloaded, download the file.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1212898"></a><span class="fm-combinumeral">❷</span> This line downloads a file given by a URL.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1212915"></a><span class="fm-combinumeral">❸</span> Create the necessary folders and write the downloaded data into it.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1212932"></a><span class="fm-combinumeral">❹</span> If the file containing the data set description is not downloaded, download it.</p>

  <p class="fm-code-annotation-mob"><a class="calibre8" id="pgfId-1212949"></a><span class="fm-combinumeral">❺</span> Create the necessary directories and write the data into them.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184411"></a>Here, we download two files: forestfires.csv and forestfires.names. forestfires.csv contains the data in a comma-separated format, where the first line is the header followed by data in the rest of the file. forestfires.names contains more information about the data, in case you want to understand more about it. Next, we will separate a small test data set to do manual testing on later. Having a dedicated test set that is not seen by the model at any stage will tell us how well the model has generalized. This will be 5% of the original data set. The other 95% will be left for training and validation data:</p>
  <pre class="programlisting">import pandas as pd
 
df = pd.read_csv(
    os.path.join('data', 'csv', 'forestfires.csv'), index_col=None, 
<span class="fm-code-continuation-arrow">➥</span> header=0
)
train_df = df.sample(frac=0.95, random_state=random_seed)
test_df = df.loc[~df.index.isin(train_df.index), :]
 
train_path = os.path.join('data','csv','train')
os.makedirs(train_path, exist_ok=True)
test_path = os.path.join('data','csv','test')
os.makedirs(test_path, exist_ok=True)
 
train_df.to_csv(
    os.path.join(train_path, 'forestfires.csv'), index=False, header=True
)
test_df.to_csv(
    os.path.join(test_path, 'forestfires.csv'), index=False, header=True
)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184433"></a>We will now start with the TFX pipeline. The first step is to define a root directory for storing pipeline artifacts. What are pipeline artifacts, you might ask? When running the TFX pipeline, it stores interim results of various stages in a directory (under a certain subdirectory structure). One example of this is that when you read the data from the CSV file, the TFX pipeline will split the data into train and validation subsets, convert those examples to <span class="fm-code-in-text">TFRecord</span> objects<a class="calibre8" id="marker-1184434"></a> (i.e., an object type used by TensorFlow internally for data), and store the data as compressed files:</p>
  <pre class="programlisting">_pipeline_root = os.path.join(
    os.getcwd(), 'pipeline', 'examples', 'forest_fires_pipeline'
)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184438"></a>TFX uses <span class="fm-code-in-text">Abseil</span> for logging purposes. <span class="fm-code-in-text">Abseil</span> is an open-source collection of C++ libraries drawn from Google’s internal codebase. It provides facilities for logging, command-line argument parsing, and so forth. If you are interested, read more about the library at <span class="fm-hyperlink"><a class="url" href="https://abseil.io/docs/python/">https://abseil.io/docs/python/</a></span>. We will set the logging level to <span class="fm-code-in-text">INFO</span> so that we will see logging statements at the <span class="fm-code-in-text">INFO</span> level or higher. Logging is an important functionality to have, as we can glean lots of insights, including what steps ran successfully and what errors were thrown:</p>
  <pre class="programlisting">absl.logging.set_verbosity(absl.logging.INFO)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184441"></a>After the initial housekeeping, we will define an <span class="fm-code-in-text">InteractiveContext</span>:</p>
  <pre class="programlisting">from tfx.orchestration.experimental.interactive.interactive_context import 
<span class="fm-code-continuation-arrow">➥</span> InteractiveContext
 
context = InteractiveContext(
    pipeline_name = "forest_fires", pipeline_root=_pipeline_root
)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1201425"></a>TFX runs pipelines in a context. The context is used to run various steps you define in the pipeline. It also serves a very important purpose, which is to manage states between different steps as we are progressing through the pipeline. In order to manage transitions between states and make sure the pipeline operates as expected, it also maintains a metadata store (a small-scale database). The metadata store contains various information, such as an execution order, the final state of the components, and resulting errors. You can read about metadata in the following sidebar.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1184442"></a>What’s in the metadata?</p>

    <p class="fm-sidebar-text"><a id="pgfId-1184443"></a>As soon as you create your <span class="fm-code-in-text1">InteractiveContext</span>, you will see a database called <span class="fm-code-in-text1">metadata.sqlite</span> in the pipeline root. This is an SQLite database (<span class="fm-hyperlink"><a class="url" href="https://www.sqlite.org/index.html">https://www .sqlite.org/index.html</a></span>), a lightweight, fast SQL database designed for small amounts of data and incoming requests. This database will log important information about inputs, outputs, and execution-related outputs (the component’s run identifier, errors). This information can be used to debug your TFX pipeline. Metadata can be thought of as data that is not a direct input or an output but is still necessary to execute components correctly with greater transparency. Metadata can be immensely helpful for debugging complex TFX pipelines with many components interconnected in many different ways. You can read more about this at <span class="fm-hyperlink"><a class="url" href="https://www.tensorflow.org/tfx/guide/mlmd">https://www.tensorflow.org/tfx/guide /mlmd</a></span>.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1184452"></a>We’re off to defining the pipeline. The primary purpose of the pipeline in this section is to</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1184453"></a>Load the data from a CSV file and split to training and validation data</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184454"></a>Learn the schema of the data (e.g., various columns, data types, min/max bounds, etc.)</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184455"></a>Display summary statistics and graphs about the distribution of various features</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1184456"></a>Transform the raw columns to features, which may require special intermediate processing steps</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1184457"></a>These steps are a lead-up to model training and deployment. Each of these tasks will be a single component in the pipeline, and we will discuss these in more detail when the time comes.</p>

  <h3 class="fm-head1" id="sigil_toc_id_191"><a id="pgfId-1184458"></a>15.1.1 Loading data from CSV files</h3>

  <p class="body"><a class="calibre8" id="pgfId-1184462"></a>The <a class="calibre8" id="marker-1184459"></a>first step is to define a component to read examples from the CSV file and split the data to train and eval. For that, you can use the <span class="fm-code-in-text">tfx.components.CsvExampleGen</span> object<a class="calibre8" id="marker-1184463"></a>. All we need to do is provide the directory containing the data to the <span class="fm-code-in-text">input_base</span> argument:</p>
  <pre class="programlisting">from tfx.components import CsvExampleGen
 
example_gen = CsvExampleGen(input_base=os.path.join('data', 'csv', 'train'))</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184469"></a>Then we use the previously defined <span class="fm-code-in-text">InteractiveContext</span> to run the example generator:</p>
  <pre class="programlisting">context.run(example_gen)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184473"></a>Let’s look at what this step produces. To see the data, let’s go to the <span class="fm-code-in-text">_pipeline_root</span> directory (e.g., Ch15-TFX-for-MLOps-in-TF2/tfx/pipeline). It should have a directory/ file structure similar to what’s shown in figure 15.1.</p>

  <p class="fm-figure"><img alt="15-01" class="calibre10" src="../../OEBPS/Images/15-01.png" width="764" height="300"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1214102"></a>Figure 15.1 The directory/file structure after running the CsvExampleGen</p>

  <p class="body"><a class="calibre8" id="pgfId-1184480"></a>You will see two GZip files (i.e., with a .gz extension) created within the pipeline. You will notice that there are two sub-directories in the CsvExampleGen folder: Split-train and Split-eval, which contain training and validation data, respectively. When you run the notebook cell containing the previous code, you will also see an output HTML table displaying the inputs and outputs of the TFX component (figure 15.2).</p>

  <p class="fm-figure"><img alt="15-02" class="calibre10" src="../../OEBPS/Images/15-02.png" width="1014" height="1028"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1214137"></a>Figure 15.2 Output HTML table generated by running the CsvExampleGen component</p>

  <p class="body"><a class="calibre8" id="pgfId-1184487"></a>There are a few things worth noting. To start, you will see the <span class="fm-code-in-text">execution_id</span>, which is the value produced by a counter that keeps track of the number of times you run TFX components. In other words, every time you run a TFX component (like CsvExampleGen), the counter goes up by 1. If you go down further, you can see some important information about how the CsvExampleGen has split your data. If you look under component &gt; CsvExampleGen &gt; exec_properties &gt; output_config, you will see something like</p>
  <pre class="programlisting">"split_config": { 
    "splits": [ 
        { "hash_buckets": 2, "name": "train" }, 
        { "hash_buckets": 1, "name": "eval" } 
    ] 
} </pre>

  <p class="body"><a class="calibre8" id="pgfId-1184495"></a>This says that the data set has been split into two sets: <span class="fm-code-in-text">train</span> and <span class="fm-code-in-text">eval</span>. The <span class="fm-code-in-text">train</span> set is roughly two-thirds of the original data, and the <span class="fm-code-in-text">eval</span> set is around one-third of the original data. This information is inferred by looking at the <span class="fm-code-in-text">hash_buckets</span> property. TFX uses hashing to split the data into <span class="fm-code-in-text">train</span> and <span class="fm-code-in-text">eval</span>. By default, it will define three hash buckets. Then TFX uses the values in each record to generate a hash for that record. The values in the record are passed to a hashing function to generate a hash. The generated hash is then used to assign that example to a bucket. For example, if the hash is 7, then TFX can easily find the bucket with 7%, 3 = 1, meaning it will be assigned to the second bucket (as buckets are zero indexed). You can access the elements in CsvExampleGen as follows.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1184498"></a>More on hashing</p>

    <p class="fm-sidebar-text"><a id="pgfId-1184499"></a>There are many hashing functions, such as MD5, SHA1, and so forth. You can read more about hashing functions at <span class="fm-hyperlink"><a class="url" href="https://blog.jscrambler.com/hashing-algorithms/">https://blog.jscrambler.com/hashing-algorithms/</a></span>. In TensorFlow, there are two different functions that can be used to generate hashes: <span class="fm-code-in-text1">tf.strings.to_hash_bucket_fast</span> (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/woJq">http://mng.bz/woJq</a></span>) and <span class="fm-code-in-text1">tf.strings.to_ hash_bucket_strong</span> (). The strong hash function is slower but is more robust against malicious attacks that may manipulate inputs in order to control the generated hash value.</p>
  </div>
  <pre class="programlisting">artifact = example_gen.outputs['examples'].get()[0]
 
print("Artifact split names: {}".format(artifact.split_names))
print("Artifact URI: {}".format(artifact.uri)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184507"></a>This will print the following output:</p>
  <pre class="programlisting">Artifact split names: ["train", "eval"]
Artifact URI: &lt;path to project&gt;/Ch15-TFX-for-MLOps-in-
<span class="fm-code-continuation-arrow">➥</span> TF2/tfx/pipeline/examples/forest_fires_pipeline/CsvExampleGen/examples/1</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184510"></a>Earlier we said that TFX stores the interim outputs as we progress through the pipeline. We saw that the CsvExampleGen component has stored the data as .gz files. It in fact stores the examples found in the CSV file as <span class="fm-code-in-text">TFRecord</span> objects. A <span class="fm-code-in-text">TFRecord</span> is used to store data as byte streams. As <span class="fm-code-in-text">TFRecord</span> is a common method for storing data when working with TensorFlow; these records can be retrieved easily as a <span class="fm-code-in-text">tf.data.Dataset</span>, and the data can be inspected. The next listing shows how this can be done.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1184512"></a>Listing 15.2 Printing the data stored by the CsvExampleGen</p>
  <pre class="programlisting">train_uri = os.path.join(
    example_gen.outputs['examples'].get()[0].uri, 'Split-train'       <span class="fm-combinumeral">❶</span>
) 
 
tfrecord_filenames = [
    os.path.join(train_uri, name) for name in os.listdir(train_uri)   <span class="fm-combinumeral">❷</span>
]
 
dataset = tf.data.TFRecordDataset(
    tfrecord_filenames, compression_type="GZIP"
)                                                                     <span class="fm-combinumeral">❸</span>
 
for tfrecord in dataset.take(2):                                      <span class="fm-combinumeral">❹</span>
  serialized_example = tfrecord.numpy()                               <span class="fm-combinumeral">❺</span>
  example = tf.train.Example()                                        <span class="fm-combinumeral">❻</span>
  example.ParseFromString(serialized_example)                         <span class="fm-combinumeral">❼</span>
  print(example)                                                      <span class="fm-combinumeral">❽</span></pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1212260"></a><span class="fm-combinumeral">❶</span> Get the URL of the output artifact representing the training examples, which is a directory.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1212291"></a><span class="fm-combinumeral">❷</span> Get the list of files in this directory (all compressed TFRecord files).</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1212308"></a><span class="fm-combinumeral">❸</span> Create a TFRecordDataset to read these files. The GZip (extension .gz) has a set of TFRecord objects.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1212325"></a><span class="fm-combinumeral">❹</span> Iterate over the first two records (can be any number less than or equal to the size of the data set).</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1212342"></a><span class="fm-combinumeral">❺</span> Get the byte stream from the TFRecord (containing one example).</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1212359"></a><span class="fm-combinumeral">❻</span> Define a tf.train.Example object that knows how to parse the byte stream.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1212376"></a><span class="fm-combinumeral">❼</span> Parse the byte stream to a proper readable example.</p>

  <p class="fm-code-annotation-mob"><a class="calibre8" id="pgfId-1212393"></a><span class="fm-combinumeral">❽</span> Print the data.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184539"></a>If you run this code, you will see the following:</p>
  <pre class="programlisting">features {
  feature {
    key: "DC"
    value {
      float_list {
        value: 605.7999877929688
      }
    }
  }
  ...
  feature {
    key: "RH"
    value {
      int64_list {
        value: 43
      }
    }
  }
  feature {
    key: "X"
    value {
      int64_list {
        value: 5
      }
    }
  }
  ...
  feature {
    key: "area"
    value {
      float_list {
        value: 2.0
      }
    }
  }
  feature {
    key: "day"
    value {
      bytes_list {
        value: "tue"
      }
    }
  }
  ...
}
 
...</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184589"></a><span class="fm-code-in-text">tf.train.Example</span> keeps the data as a collection of features, where each feature has a key (column descriptor) and a value. You will see all of the features for a given example. For example, the <span class="fm-code-in-text">DC</span> feature has a floating value of 605.799, feature <span class="fm-code-in-text">RH</span> has an int value of 43, feature <span class="fm-code-in-text">area</span> has a floating value of 2.0, and feature <span class="fm-code-in-text">day</span> has a <span class="fm-code-in-text">bytes_list</span> (used to store strings) value of <span class="fm-code-in-text">"tue"</span> (i.e., Tuesday).</p>

  <p class="body"><a class="calibre8" id="pgfId-1184591"></a>Before moving to the next section, let’s remind ourselves what our objective is: to develop a model that can predict the fire spread (in hectares) given all the other features in the data set. This problem is framed as a regression <a class="calibre8" id="marker-1184592"></a>problem.</p>

  <h3 class="fm-head1" id="sigil_toc_id_192"><a id="pgfId-1184595"></a>15.1.2 Generating basic statistics from the data</h3>

  <p class="body"><a class="calibre8" id="pgfId-1184599"></a>As <a class="calibre8" id="marker-1184596"></a><a class="calibre8" id="marker-1184598"></a>the next step, we will understand the data better<a class="calibre8" id="marker-1204661"></a>. This is known as exploratory data analysis (EDA). EDA is not typically well defined and very much depends on the problem you are solving and the data. And you have to factor in the limited time you usually have until the delivery of a project. In other words, you cannot test everything and have to prioritize what you want to test and what you want to assume. For the structured data we are tackling here, a great place to start is understanding type (numerical versus categorical) and the distribution of values of the various columns present. TFX provides you a component just for that. <span class="fm-code-in-text">StatisticsGen</span> will automatically generate those statistics for you. We will soon see in more detail what sort of insights this module provides:</p>
  <pre class="programlisting">from tfx.components import StatisticsGen
 
statistics_gen = StatisticsGen(
    examples=example_gen.outputs['examples'])
 
context.run(statistics_gen)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184607"></a>This will produce an HTML table similar to what you saw after running CsvExampleGen (figure 15.3).</p>

  <p class="fm-figure"><img alt="15-03" class="calibre10" src="../../OEBPS/Images/15-03.png" width="1050" height="611"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1214178"></a>Figure 15.3 The output provided by the <span class="fm-code-in-figurecaption">StatisticsGen</span> component</p>

  <p class="body"><a class="calibre8" id="pgfId-1184615"></a>However, to retrieve the most valuable output of this step, you have to run the following line:</p>
  <pre class="programlisting">context.show(statistics_gen.outputs['statistics'])</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184619"></a>This will create the following files in the pipeline root (figure 15.4).</p>

  <p class="fm-figure"><img alt="15-04" class="calibre10" src="../../OEBPS/Images/15-04.png" width="1014" height="386"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1214212"></a>Figure 15.4 The directory/file structure after running <span class="fm-code-in-figurecaption">StatisticsGen</span></p>

  <p class="body"><a class="calibre8" id="pgfId-1184626"></a>Figure 15.5 shows the valuable collection of information about data provided by TFX. The output graph shown in figure 15.5 is a goldmine containing rich information about the data we’re dealing with. It provides you a basic yet holistic suite of graphs that provides lots of information about the columns present in the data. Let’s go from top to bottom. At the top, you have options to sort and filter the outputs shown in figure 15.5. For example, you can change the order of the graphs, select graphs based on data types, or filter them by a regular expression.</p>

  <p class="fm-figure"><img alt="15-05" class="calibre10" src="../../OEBPS/Images/15-05.png" width="1072" height="794"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1214247"></a>Figure 15.5 The summary statistics graphs generated for the data by the <span class="fm-code-in-figurecaption">StatisticsGen</span> component</p>

  <p class="body"><a class="calibre8" id="pgfId-1184634"></a>By default, <span class="fm-code-in-text">StatisticsGen</span> will generate graphs for both <span class="fm-code-in-text">train</span> and <span class="fm-code-in-text">eval</span> data sets. Then each <span class="fm-code-in-text">train</span> and <span class="fm-code-in-text">eval</span> section will have several subsections; in this case, we have a section for numerical columns and categorical columns.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184635"></a>On the left, you can see some numerical statistics and assessments of a feature, whereas on the right side, you can see a visual representation of how a feature is distributed. For example, take the FFMC feature in the training set. We can see that it has 333 examples and 0% have missing values for that feature. It has a mean of ~90 and a standard deviation of 6.34. In the graph, you can see that the distribution is quite skewed. Almost all values are concentrated around the 80-90 range. You will see later how this might create problems for us and how we will solve them.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184636"></a>In the categorical section, you can see the values of the <span class="fm-code-in-text">day</span> and <span class="fm-code-in-text">month</span> features. For example, the <span class="fm-code-in-text">day</span> feature has seven unique values and 0% missing. The most frequent value (i.e., mode) of the <span class="fm-code-in-text">day</span> feature appears 60 times. Note that the day is represented as a bar graph and the month is represented as a line graph because for features with unique values above a threshold, a line graph is used to make the graph clear and less <a class="calibre8" id="marker-1184637"></a><a class="calibre8" id="marker-1184639"></a>cluttered<a class="calibre8" id="marker-1204666"></a>.</p>

  <h3 class="fm-head1" id="sigil_toc_id_193"><a id="pgfId-1184640"></a>15.1.3 Inferring the schema from data</h3>

  <p class="body"><a class="calibre8" id="pgfId-1184645"></a>Thus <a class="calibre8" id="marker-1184641"></a>far, we have loaded the data from a CSV file and explored the basic statistics of the data set. The next big step is to infer the schema of the data. TFX can automatically derive the schema of the data once the data is provided. If you have worked with databases, the schema derived is the same as a database schema. It can be thought of as a blueprint for the data, expressing the structure and important attributes of data. It can also be thought of as a set of rules that dictate what the data should look like. For example, if you have the schema, you can classify whether a given record is valid by referring to the schema.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184647"></a>Without further ado, let’s create a <span class="fm-code-in-text">SchemaGen</span> object<a class="calibre8" id="marker-1184646"></a>. The <span class="fm-code-in-text">SchemaGen</span> requires the output of the previous step (i.e., output of the <span class="fm-code-in-text">StatisticsGen</span>) and a Boolean argument named <span class="fm-code-in-text">infer_feature_shape</span>:</p>
  <pre class="programlisting">from tfx.components import SchemaGen
 
schema_gen = SchemaGen(
    statistics=statistics_gen.outputs[‘statistics’],
    infer_feature_shape=False)
 
context.run(schema_gen)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184655"></a>Here, we set the <span class="fm-code-in-text">infer_feature_shape</span> to <span class="fm-code-in-text">False</span>, as we will do some transformations to the features down the road. Therefore, we will have the flexibility to manipulate the feature shapes more freely. However, setting this argument (<span class="fm-code-in-text">infer_feature_shape</span>) means an important change for a downstream step (called the transform step). When <span class="fm-code-in-text">infer_feature_shape</span> is set to <span class="fm-code-in-text">False</span>, the tensors passed to the transform step are represented as <span class="fm-code-in-text">tf.SparseTensor</span> objects<a class="calibre8" id="marker-1184656"></a>, not <span class="fm-code-in-text">tf.Tensor</span> objects<a class="calibre8" id="marker-1184657"></a>. If set to <span class="fm-code-in-text">True</span>, it will need to be a <span class="fm-code-in-text">tf.Tensor</span> object with a known shape. Next, to see the output of the <span class="fm-code-in-text">SchemaGen</span>, you can do</p>
  <pre class="programlisting">context.show(schema_gen.outputs['schema'])</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184661"></a>which will produce the output shown in table 15.1.</p>

  <p class="fm-table-caption"><a id="pgfId-1190434"></a>Table 15.1 The schema output generated by TFX</p>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre12">
      <col class="calibre13" span="1" width="20%"/>
      <col class="calibre13" span="1" width="20%"/>
      <col class="calibre13" span="1" width="20%"/>
      <col class="calibre13" span="1" width="20%"/>
      <col class="calibre13" span="1" width="20%"/>
    </colgroup>

    <tr class="calibre14">
      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1190444"></a><b class="fm-bold">Feature name</b></p>
      </th>

      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1190446"></a><b class="fm-bold">Type</b></p>
      </th>

      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1190448"></a><b class="fm-bold">Presence</b></p>
      </th>

      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1190450"></a><b class="fm-bold">Valency</b></p>
      </th>

      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1190452"></a><b class="fm-bold">Domain</b></p>
      </th>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190454"></a><b class="fm-bold">‘day’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190456"></a>STRING</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190458"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190460"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190462"></a>‘day’</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190464"></a><b class="fm-bold">‘month’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190466"></a>STRING</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190468"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190470"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190472"></a>‘month’</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190474"></a><b class="fm-bold">‘DC’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190476"></a>FLOAT</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190478"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190480"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190482"></a>-</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190484"></a><b class="fm-bold">‘DMC’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190486"></a>FLOAT</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190488"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190490"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190492"></a>-</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190494"></a><b class="fm-bold">‘FFMC’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190496"></a>FLOAT</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190498"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190500"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190502"></a>-</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190504"></a><b class="fm-bold">‘ISI’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190506"></a>FLOAT</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190508"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190510"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190512"></a>-</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190514"></a><b class="fm-bold">‘RH’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190516"></a>INT</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190518"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190520"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190522"></a>-</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190524"></a><b class="fm-bold">‘X’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190526"></a>INT</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190528"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190530"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190532"></a>-</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190534"></a><b class="fm-bold">‘Y’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190536"></a>INT</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190538"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190540"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190542"></a>-</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190544"></a><b class="fm-bold">‘area’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190546"></a>FLOAT</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190548"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190550"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190552"></a>-</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190554"></a><b class="fm-bold">‘rain’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190556"></a>FLOAT</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190558"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190560"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190562"></a>-</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190564"></a><b class="fm-bold">‘temp’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190566"></a>FLOAT</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190568"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190570"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190572"></a>-</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191090"></a><b class="fm-bold">‘wind’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190576"></a>FLOAT</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190578"></a>required</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190580"></a>single</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1190582"></a> </p>
      </td>
    </tr>
  </table>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre12">
      <col class="calibre13" span="1" width="7.7%"/>
      <col class="calibre13" span="1" width="7.7%"/>
      <col class="calibre13" span="1" width="7.7%"/>
      <col class="calibre13" span="1" width="7.7%"/>
      <col class="calibre13" span="1" width="7.7%"/>
      <col class="calibre13" span="1" width="7.7%"/>
      <col class="calibre13" span="1" width="7.7%"/>
      <col class="calibre13" span="1" width="7.7%"/>
      <col class="calibre13" span="1" width="7.7%"/>
      <col class="calibre13" span="1" width="7.7%"/>
      <col class="calibre13" span="1" width="7.7%"/>
      <col class="calibre13" span="1" width="7.7%"/>
      <col class="calibre13" span="1" width="7.7%"/>
    </colgroup>

    <tr class="calibre14">
      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1191866"></a><b class="fm-bold">Domain</b></p>
      </th>

      <th class="fm-contenttable1" colspan="12" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1191868"></a><b class="fm-bold">Values</b></p>
      </th>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191892"></a><b class="fm-bold">‘day’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191894"></a> </p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191896"></a> </p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191898"></a> </p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191900"></a> </p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191902"></a> </p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191904"></a>‘fri’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191906"></a>‘mon’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191908"></a>‘sat’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191910"></a>‘sun’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191912"></a>‘thu’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191914"></a>‘tue’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191916"></a>‘wed’</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191918"></a><b class="fm-bold">‘month’</b></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191920"></a>‘apr’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191922"></a>‘aug’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191924"></a>‘dec’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191926"></a>‘feb’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191928"></a>‘jan’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191930"></a>‘jul’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191932"></a>‘jun’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191934"></a>‘mar’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191936"></a>‘may’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191938"></a>‘oct’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191940"></a>‘sep’</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1191942"></a>‘nov’</p>
      </td>
    </tr>
  </table>

  <p class="body"><a class="calibre8" id="pgfId-1184668"></a><span class="fm-code-in-text">Domain</span> defines the constraints of a given feature. We list some of the most popular domains defined in TFX:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1184669"></a><i class="fm-italics">Integer domain values</i> (e.g., defines minimum/maximum of an integer feature)</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184670"></a><i class="fm-italics">Float domain values</i> (e.g., defines minimum/maximum of a floating-value feature)</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184671"></a><i class="fm-italics">String domain value</i> (e.g., defines allowed values/tokens for a string features)</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184672"></a><i class="fm-italics">Boolean domain values</i> (e.g., can be used to define custom values for true/false states)</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184673"></a><i class="fm-italics">Struct domain values</i> (e.g., can be used to define recursive domains [a domain within a domain] or domains with multiple features)</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184674"></a><i class="fm-italics">Natural language domain values</i> (e.g., defines a vocabulary [allowed collection of tokens] for a related language feature)</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184675"></a><i class="fm-italics">Image domain values</i> (e.g., can be used to restrict the maximum byte size of images)</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184676"></a><i class="fm-italics">Time domain values</i> (e.g., can be used to define data/time features)</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1184677"></a><i class="fm-italics">Time of day domain values</i> (e.g., can be used to define a time without a date)</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1184678"></a>The list of domains is available in a file called schema.proto. schema.proto is defined at <span class="fm-hyperlink"><a class="url" href="http://mng.bz/7yp9">http://mng.bz/7yp9</a></span>. These files are defined using a library called <span class="fm-code-in-text">Protobuf</span>. <span class="fm-code-in-text">Protobuf</span> is a library designed for object serialization. You can read the following sidebar to learn more about the <span class="fm-code-in-text">Protobuf</span> library<a class="calibre8" id="marker-1184679"></a>.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1184680"></a>Protobuf library</p>

    <p class="fm-sidebar-text"><a id="pgfId-1184681"></a><span class="fm-code-in-text1">Protobuf</span> is an object serialization/deserialization library developed by Google. The object that needs to be serialized is defined as a <span class="fm-code-in-text1">Protobuf</span> message. The template of a message is defined with a .proto file. Then, to deserialize, <span class="fm-code-in-text1">Protobuf</span> provides functions such as <span class="fm-code-in-text1">ParseFromString</span><a id="marker-1187718"></a><span class="fm-code-in-text1">()</span>. To read more about the library, refer to <span class="fm-hyperlink"><a class="url" href="http://mng.bz/R45P">http://mng.bz/R45P</a></span>.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1184688"></a>Next, we will see how we can convert data to <a class="calibre8" id="marker-1184684"></a>features.</p>

  <h3 class="fm-head1" id="sigil_toc_id_194"><a id="pgfId-1184689"></a>15.1.4 Converting data to features</h3>

  <p class="body"><a class="calibre8" id="pgfId-1184693"></a>We <a class="calibre8" id="marker-1184690"></a>have reached the final stage of our data-processing pipeline. The final step is to convert the columns we have extracted to features that are meaningful to our model. We are going to create three types of features:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1184695"></a><i class="fm-italics">Dense floating-point features</i>—Values are presented as floating-point numbers (e.g., temperature). This means the value is passed as it is (with an optional normalizing step; e.g., Z-score normalization) to create a feature.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184697"></a><i class="fm-italics">Bucketized features</i><a class="calibre8" id="marker-1184696"></a>—Numerical values that are binned according to predefined binning intervals. This means the value will be converted to a bin index, depending on which bin the value falls into (e.g., we can bucketize relative humidity to three values: low [-inf, 33), medium [33, 66), and high [66, inf)).</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1184699"></a><i class="fm-italics">Categorical features</i><a class="calibre8" id="marker-1184698"></a> (integer-based or string-based)—Value is chosen from a predefined set of values (e.g., day or month). If the value is not already an integer index (e.g., day as a string), it will be converted to an integer index using a vocabulary that maps each word to an index (e.g., <span class="fm-code-in-text">"mon"</span> is mapped to 0, <span class="fm-code-in-text">"tue"</span> is mapped to 1, etc.).</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1184700"></a>We will introduce one of these feature transformations to each of the fields in the data set:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1184701"></a><i class="fm-italics">X</i> (spatial coordinate)—Presented as a floating-point value</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184702"></a><i class="fm-italics">Y</i> (spatial coordinate)—Presented as a floating-point value</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184703"></a><i class="fm-italics">wind</i> (wind speed)—Presented as a floating-point value</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184704"></a><i class="fm-italics">rain</i> (outside rain)—Presented as a floating-point value</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184705"></a><i class="fm-italics">FFMC</i> (fuel moisture)—Presented as a floating-point value</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184706"></a><i class="fm-italics">DMC</i> (average moisture content)—Presented as a floating-point value</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184707"></a><i class="fm-italics">DC</i> (depth of dryness in the soil)—Presented as a floating-point value</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184708"></a><i class="fm-italics">ISI</i> (expected rate of fire spread)—Presented as a floating-point value</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184709"></a><i class="fm-italics">temp</i> (temperature)—Presented as a floating-point value</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184710"></a><i class="fm-italics">RH</i> (relative humidity)—Presented as a bucketized value</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184711"></a><i class="fm-italics">month</i>—Presented as a categorical feature</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184712"></a><i class="fm-italics">day</i>—Presented as a categorical feature</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1184713"></a><i class="fm-italics">area</i> (the burned area)—The label feature kept as a numerical value</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1184714"></a>We are first going to define some constants, which will help us to keep track of which feature is assigned to which category. Additionally, we will keep variable specific properties (e.g., maximum number of classes for categorical features; see the next listing).</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1184716"></a>Listing 15.3 Defining feature-related constants for the feature transformation step</p>
  <pre class="programlisting">%%writefile forest_fires_constants.py                              <span class="fm-combinumeral">❶</span>
 
VOCAB_FEATURE_KEYS = ['day','month']                               <span class="fm-combinumeral">❷</span>
 
MAX_CATEGORICAL_FEATURE_VALUES = [7, 12]                           <span class="fm-combinumeral">❸</span>
 
 
DENSE_FLOAT_FEATURE_KEYS = [
    'DC', 'DMC', 'FFMC', 'ISI', 'rain', 'temp', 'wind', 'X', 'Y'   <span class="fm-combinumeral">❹</span>
]
 
BUCKET_FEATURE_KEYS = ['RH']                                       <span class="fm-combinumeral">❺</span>
 
BUCKET_FEATURE_BOUNDARIES = [(33, 66)]                             <span class="fm-combinumeral">❻</span>
 
LABEL_KEY = 'area'                                                 <span class="fm-combinumeral">❼</span>
 
 
def transformed_name(key):                                         <span class="fm-combinumeral">❽</span>
    
    return key + '_xf'</pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1211644"></a><span class="fm-combinumeral">❶</span> This command will write the content of this cell to a file (read the sidebar for more information).</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1211665"></a><span class="fm-combinumeral">❷</span> Vocabulary-based (or string-based) categorical features.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1211682"></a><span class="fm-combinumeral">❸</span> Categorical features are assumed to each have a maximum value in the data set.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1211699"></a><span class="fm-combinumeral">❹</span> Dense features (these will go to the model as they are, or normalized)</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1211716"></a><span class="fm-combinumeral">❺</span> Bucketized features</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1211733"></a><span class="fm-combinumeral">❻</span> The bucket boundaries for bucketized features (e.g., the feature RH will be bucketed to three bins: [0, 33), [33, 66), [66, inf)).</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1211750"></a><span class="fm-combinumeral">❼</span> Label features will be kept as numerical features as we are solving a regression problem.</p>

  <p class="fm-code-annotation-mob"><a class="calibre8" id="pgfId-1211767"></a><span class="fm-combinumeral">❽</span> Define a function that will add a suffix to the feature name. This will help us to distinguish the generated features from original data columns.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184746"></a>The reason we are writing these notebook cells as Python scripts (or Python modules) is because TFX expects some parts of the code it needs to run as a Python module.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1184747"></a>%%writefile magic command</p>

    <p class="fm-sidebar-text"><a id="pgfId-1184748"></a><span class="fm-code-in-text1">%%writefile</span> is a Jupyter magic command (similar to <span class="fm-code-in-text1">%%tensorboard</span>). It will cause the Jupyter notebook to write the content in a cell to a new file (e.g., a Python module/script). This is a great way to create isolated Python modules from notebook cells. Notebooks are great for experimenting, but for production-level code, Python scripts are better. For example, our TFX pipeline expects certain functions (e.g., how to preprocess raw columns to features) to be independent Python modules. We can conveniently use the <span class="fm-code-in-text1">%%writefile</span> command to achieve that.</p>

    <p class="fm-sidebar-text"><br class="calibre2"/></p>

    <p class="fm-sidebar-text"><a id="pgfId-1184749"></a>This command must be specified as the very top command in the cell you want to be written out to a file.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1184751"></a>Next, we will write another module called forest_fires_transform.py, which will have a preprocessing function (called <span class="fm-code-in-text">preprocessing_fn</span>) that defines how each data column should be treated in order to become a feature (see the next listing).</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1184753"></a>Listing 15.4 Defining a Python module to convert raw data to features</p>
  <pre class="programlisting">%%writefile forest_fires_transform.py                                      <span class="fm-combinumeral">❶</span>
 
import tensorflow as tf
import tensorflow_transform as tft
 
import forest_fires_constants                                              <span class="fm-combinumeral">❷</span>
 
_DENSE_FLOAT_FEATURE_KEYS = forest_fires_constants.DENSE_FLOAT_FEATURE_KEYS<span class="fm-combinumeral">❸</span>
_VOCAB_FEATURE_KEYS = forest_fires_constants.VOCAB_FEATURE_KEYS            <span class="fm-combinumeral">❸</span>
_BUCKET_FEATURE_KEYS = forest_fires_constants.BUCKET_FEATURE_KEYS          <span class="fm-combinumeral">❸</span>
_BUCKET_FEATURE_BOUNDARIES = 
<span class="fm-code-continuation-arrow">➥</span> forest_fires_constants.BUCKET_FEATURE_BOUNDARIES                        <span class="fm-combinumeral">❸</span>
_LABEL_KEY = forest_fires_constants.LABEL_KEY                              <span class="fm-combinumeral">❸</span>
_transformed_name = forest_fires_constants.transformed_name                <span class="fm-combinumeral">❸</span>
 
 
def preprocessing_fn(inputs):                                              <span class="fm-combinumeral">❹</span>
  
  outputs = {}
    
  for key in _DENSE_FLOAT_FEATURE_KEYS:                                    <span class="fm-combinumeral">❺</span>
    outputs[_transformed_name(key)] = tft.scale_to_z_score(                <span class="fm-combinumeral">❻</span>
        sparse_to_dense(inputs[key])                                       <span class="fm-combinumeral">❼</span>
    )
 
  for key in _VOCAB_FEATURE_KEYS:
    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(    <span class="fm-combinumeral">❽</span>
        sparse_to_dense(inputs[key]),
        num_oov_buckets=1)
 
  for key, boundary in zip(_BUCKET_FEATURE_KEYS,                           <span class="fm-combinumeral">❾</span>
<span class="fm-code-continuation-arrow">➥</span> _BUCKET_FEATURE_BOUNDARIES):                                            <span class="fm-combinumeral">❾</span>
    outputs[_transformed_name(key)] = tft.apply_buckets(                   <span class="fm-combinumeral">❾</span>
        sparse_to_dense(inputs[key]), bucket_boundaries=[boundary]         <span class="fm-combinumeral">❾</span>
    )                                                                      <span class="fm-combinumeral">❾</span>
 
  outputs[_transformed_name(_LABEL_KEY)] = 
<span class="fm-code-continuation-arrow">➥</span> sparse_to_dense(inputs[_LABEL_KEY])                                     <span class="fm-combinumeral">❿</span>
 
  return outputs
 
def sparse_to_dense(x):                                                    <span class="fm-combinumeral">⓫</span>
    
    return tf.squeeze(
        tf.sparse.to_dense(
            tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1])
        ),
        axis=1
    )</pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210679"></a><span class="fm-combinumeral">❶</span> The content in this code listing will be written to a separate Python module.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210700"></a><span class="fm-combinumeral">❷</span> Imports the feature constants defined previously</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210717"></a><span class="fm-combinumeral">❸</span> Imports all the constants defined in the forest_fires_constants module</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210734"></a><span class="fm-combinumeral">❹</span> This is a must-have callback function for the tf.transform library to convert raw columns to features.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210751"></a><span class="fm-combinumeral">❺</span> Treats all the dense features</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210768"></a><span class="fm-combinumeral">❻</span> Perform Z-score-based scaling (or normalization) on dense features</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210785"></a><span class="fm-combinumeral">❼</span> Because infer_feature_shape is set to False in the SchemaGen step, we have sparse tensors as inputs. They need to be converted to dense tensors.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210802"></a><span class="fm-combinumeral">❽</span> For the vocabulary-based features, build the vocabulary and convert each token to an integer ID.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210819"></a><span class="fm-combinumeral">❾</span> For the to-be-bucketized features, using the bucket boundaries defined, bucketize the features.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210836"></a><span class="fm-combinumeral">❿</span> The label feature is simply converted to dense without any other feature transformations.</p>

  <p class="fm-code-annotation-mob"><a class="calibre8" id="pgfId-1210853"></a><span class="fm-combinumeral">⓫</span> A utility function for converting sparse tensors to dense tensors</p>

  <p class="body"><a class="calibre8" id="pgfId-1184812"></a>You can see that this file is written as forest_fires_transform.py. It defines a <span class="fm-code-in-text">preprocessing_fn()</span>, which takes an argument called <span class="fm-code-in-text">inputs</span>. <span class="fm-code-in-text">inputs</span> is a dictionary mapping from feature keys to columns of data found in the CSV, flowing from the <span class="fm-code-in-text">example_gen</span> output. Finally, it returns a dictionary with feature keys mapped to transformed features using the <span class="fm-code-in-text">tensorflow_transform</span> library<a class="calibre8" id="marker-1184813"></a>. In the middle of the method, you can see the preprocessing function doing three important jobs.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184814"></a>First, it reads all dense features (whose names are stored in <span class="fm-code-in-text">_DENSE_FLOAT_FEATURE_KEYS</span>) and normalizes the values using z-score. The z-score normalizes a column <i class="fm-italics">x</i> as</p>

  <p class="fm-equation"><img alt="15_05a" class="calibre10" src="../../OEBPS/Images/15_05a.png" width="104" height="66"/><br class="calibre2"/>
  <a id="pgfId-1192455"></a></p>

  <p class="body"><a class="calibre8" id="pgfId-1192457"></a>where <span class="fm-symbol1">μ</span>(<i class="fm-italics">x</i>) is mean value of the column and <span class="fm-symbol1">σ</span>(<i class="fm-italics">x</i>) is the standard deviation of the column. To normalize data, you can call the function <span class="fm-code-in-text">scale_to_z_score</span><a class="calibre8" id="marker-1192525"></a><span class="fm-code-in-text">()</span> in the <span class="fm-code-in-text">tensorflow_transform</span> library. You can read the sidebar on <span class="fm-code-in-text">tensorflow_transform</span> to understand more about what the library offers. Then the function stores each feature in the outputs under a new key (via the _<span class="fm-code-in-text">transformed_name</span> function) derived from the original feature name (the new key is generated by appending <span class="fm-code-in-text">_xf</span> to the end of the original feature name).</p>

  <p class="body"><a class="calibre8" id="pgfId-1184836"></a>Next, it treats the vocabulary-based categorical features (where names are stored in <span class="fm-code-in-text">_VOCAB_FEATURE_KEYS</span>) by converting each string to an index using a dictionary. The dictionary maps each string to an index and is learned from the provided training data automatically. This is similar to how we used the Keras Tokenizer object to learn a dictionary that we used to convert words to word IDs. In the <span class="fm-code-in-text">tensorflow_transform</span> library you have the handy <span class="fm-code-in-text">compute_and_apply_vocabulary()</span> function. To the <span class="fm-code-in-text">compute_and_apply_vocabulary()</span><i class="fm-italics">function, we can pass</i> <span class="fm-code-in-text">num_oov_buckets=1</span> <i class="fm-italics">in order to assign any unseen strings to a special category (apart from the ones already assigned to known categories).</i></p>

  <p class="body"><a class="calibre8" id="pgfId-1184838"></a>Afterward, the function tackles the to-be-bucketized features. Bucketization is the process of applying a continuous value to a bucket, where a bucket is defined by a set of boundaries. Bucketizing features can be achieved effortlessly with the <span class="fm-code-in-text">apply_buckets()</span> function<a class="calibre8" id="marker-1184839"></a>, which takes the feature (provided in the <span class="fm-code-in-text">inputs</span> dictionary) and bucket boundaries as the input arguments.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184840"></a>Finally, we keep the column containing the label as it is. With that, we define the <span class="fm-code-in-text">Transform</span> component<a class="calibre8" id="marker-1184841"></a> (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/mOGr">http://mng.bz/mOGr</a></span>).</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1184842"></a>tensorflow_transform: Converting raw data to features</p>

    <p class="fm-sidebar-text"><a id="pgfId-1184843"></a><span class="fm-code-in-text1">tensorflow_transform</span> is a sub-library in TensorFlow primarily focused on feature transformations. It offers a variety of functions to compute things:</p>

    <ul class="calibre9">
      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1184844"></a>Bucketizing features (e.g., binning a range of values to a predefined set of bins)</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1184845"></a>Bag-of-words features from a string column</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1184846"></a>Covariance matrices of a data set</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1184847"></a>Mean, standard deviation, min, max, count, and so forth of columns</p>
      </li>
    </ul>

    <p class="fm-sidebar-text"><a id="pgfId-1184848"></a>You can read more about the functions this library offers at <span class="fm-hyperlink"><a class="url" href="http://mng.bz/5QgB">http://mng.bz/5QgB</a></span>.</p>
  </div>
  <pre class="programlisting">from tfx.components import Transform
 
transform = Transform(
    examples=example_gen.outputs['examples'],
    schema=schema_gen.outputs['schema'],
    module_file=os.path.abspath('forest_fires_transform.py'),
)
 
context.run(transform)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184859"></a>The <span class="fm-code-in-text">Transform</span> component takes three inputs:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1184861"></a>Output examples of the <span class="fm-code-in-text">CsvExampleGen</span> component<a class="calibre8" id="marker-1184860"></a></p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1184862"></a>Schema from the <span class="fm-code-in-text">SchemaGen</span></p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1184864"></a>The Python module that defines the <span class="fm-code-in-text">preprocessing_fn()</span> function for transforming data to features</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1184865"></a>One thing we must do when it comes to multi-component pipelines, like a TFX pipeline, is check every interim output whenever we can. It’s a much better choice than leaving things to chance and praying things work out fine (which is normally never the case). So, let’s inspect the output by printing some of the data saved to the disk after running the <span class="fm-code-in-text">Transform</span> step (see the next listing). The code for printing the data will be similar to when we printed the data when using the CsvExampleGen component.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1184867"></a>Listing 15.5 Inspecting the outputs produced by the TFX <span class="fm-code-in-listingcaption">Transform</span> step</p>
  <pre class="programlisting">import forest_fires_constants
 
_DENSE_FLOAT_FEATURE_KEYS = forest_fires_constants.DENSE_FLOAT_FEATURE_KEYS
_VOCAB_FEATURE_KEYS = forest_fires_constants.VOCAB_FEATURE_KEYS
_BUCKET_FEATURE_KEYS = forest_fires_constants.BUCKET_FEATURE_KEYS
_LABEL_KEY = forest_fires_constants.LABEL_KEY
 
# Get the URI of the output artifact representing the training examples, which is a directory
train_uri = os.path.join(
    transform.outputs['transformed_examples'].get()[0].uri, 'Split-train'
)
tfrecord_filenames = [
    os.path.join(train_uri, name) for name in os.listdir(train_uri)        <span class="fm-combinumeral">❶</span>
]
 
dataset = tf.data.TFRecordDataset(
    tfrecord_filenames, compression_type="GZIP"
)                                                                          <span class="fm-combinumeral">❷</span>
 
 
example_records = []                                                       <span class="fm-combinumeral">❸</span>
float_features = [
    _transformed_name(f) for f in _DENSE_FLOAT_FEATURE_KEYS + [_LABEL_KEY] <span class="fm-combinumeral">❹</span>
]
int_features = [
    _transformed_name(f) for f in _BUCKET_FEATURE_KEYS + 
<span class="fm-code-continuation-arrow">➥</span> _VOCAB_FEATURE_KEYS                                                     <span class="fm-combinumeral">❹</span>
]
for tfrecord in dataset.take(5):                                           <span class="fm-combinumeral">❺</span>
  serialized_example = tfrecord.numpy()                                    <span class="fm-combinumeral">❻</span>
  example = tf.train.Example()                                             <span class="fm-combinumeral">❻</span>
  example.ParseFromString(serialized_example)                              <span class="fm-combinumeral">❻</span>
  record = [
    example.features.feature[f].int64_list.value for f in int_features     <span class="fm-combinumeral">❼</span>
  ] + [
    example.features.feature[f].float_list.value for f in float_features   <span class="fm-combinumeral">❼</span>
  ]
  example_records.append(record)                                           <span class="fm-combinumeral">❽</span>
  print(example)
  print("="*50)</pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1209939"></a><span class="fm-combinumeral">❶</span> Get the list of files in this directory (all compressed TFRecord files).</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1209960"></a><span class="fm-combinumeral">❷</span> Create a TFRecordDataset to read these files.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1209977"></a><span class="fm-combinumeral">❸</span> Used to store the retrieved feature values (for later inspection)</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1209994"></a><span class="fm-combinumeral">❹</span> Dense (i.e., float) and integer (i.e., vocab-based and bucketized) features</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210011"></a><span class="fm-combinumeral">❺</span> Get the first five examples in the data set.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210028"></a><span class="fm-combinumeral">❻</span> Get a tf record and convert that to a readable tf.train.Example.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1210048"></a><span class="fm-combinumeral">❼</span> We will extract the values of the features from the tf.train.Example object for subsequent inspections.</p>

  <p class="fm-code-annotation-mob"><a class="calibre8" id="pgfId-1210065"></a><span class="fm-combinumeral">❽</span> Append the extracted values as a record (i.e., tuple of values) to example_records.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184916"></a>The code explained will print the data after feature transformation. Each example stores integer values in the attribute path, example.features.feature[&lt;feature name&gt;] .int64_list.value, whereas the floating values are stored at example.features.feature [&lt;feature name&gt;].float_list.value. This will print examples such as</p>
  <pre class="programlisting">features {
  feature {
    key: "DC_xf"
    value {
      float_list {
        value: 0.4196213185787201
      }
    }
  }
 
  ...
 
  feature {
    key: "RH_xf"
    value {
      int64_list {
        value: 0
      }
    }
  }
 
  ...
 
  feature {
    key: "area_xf"
    value {
      float_list {
        value: 2.7699999809265137
      }
    }
  }
 
  ...
}</pre>

  <p class="body"><a class="calibre8" id="pgfId-1184953"></a>Note that we are using the <span class="fm-code-in-text">_transformed_name()</span> function<a class="calibre8" id="marker-1184952"></a> to obtain the transformed feature names. We can see that the floating-point values (<span class="fm-code-in-text">DC_xf</span>) are normalized using z-score normalization, vocabulary-based features (<span class="fm-code-in-text">day_xf</span>) are converted to an integer, and bucketized features (<span class="fm-code-in-text">RH_xf</span>) are presented as integers.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1184954"></a>Rule of thumb: Check your pipeline whenever possible</p>

    <p class="fm-sidebar-text"><a id="pgfId-1184955"></a>When using components offered by third-party libraries like TFX, there is very low visibility into what is actually taking place under the hood. This is exacerbated by the fact that TFX is not a highly matured tool and is in the process of development. Therefore, we always try to incorporate pieces of code that probe into these components, which will help us to sanity-check inputs and outputs of these components.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1184957"></a>In the next section, we will train a simple regression model as a part of the pipeline we’ve been creating.</p>

  <p class="fm-head2"><a id="pgfId-1184958"></a>Exercise 1</p>

  <p class="body"><a class="calibre8" id="pgfId-1184959"></a>Let’s say that, instead of the previously defined feature transformations, you want to do the following:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1184960"></a><i class="fm-italics">DC</i>—Scale data to a range of [0, 1]</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1184961"></a><i class="fm-italics">temp</i>—Bucketize with the boundaries (-inf, 20], (20, 30] and (30, inf)</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1184962"></a>Once the features are transformed, add them to a dictionary named <span class="fm-code-in-text">outputs</span>, where each feature is keyed by the transformed feature name. Assume you can obtain the transformed feature name for temp by calling, <span class="fm-code-in-text">_transformed_name(‘temp’).</span> How would you use the <span class="fm-code-in-text">tensorflow_transform</span> library to achieve this? You can use the <span class="fm-code-in-text">scale_to_0_1()</span> and <span class="fm-code-in-text">apply_buckets()</span> functions to <a class="calibre8" id="marker-1184963"></a>achieve <a class="calibre8" id="marker-1184966"></a>this.</p>

  <h2 class="fm-head" id="sigil_toc_id_195"><a id="pgfId-1184968"></a>15.2 Training a simple regression neural network: TFX Trainer API</h2>

  <p class="body"><a class="calibre8" id="pgfId-1184973"></a>You <a class="calibre8" id="marker-1184969"></a><a class="calibre8" id="marker-1184970"></a><a class="calibre8" id="marker-1184971"></a><a class="calibre8" id="marker-1184972"></a>have defined a TFX data pipeline that can convert examples in a CSV file to model-ready features. Now you will train a model on this data. You will use TFX to define a model trainer, which will take a simple two-layer fully connected regression model and train that on the data flowing from the data pipeline. Finally, you will predict using the model on some sample evaluation data.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184974"></a>With a well-defined data pipeline defined using TFX, we’re at the cusp of training a model with the data flowing from that pipeline. Training a model with TFX can be slightly demanding at first sight due to the rigid structure of functions and data it expects. However, once you are familiar with the format you need to adhere to, it gets easier.</p>

  <p class="body"><a class="calibre8" id="pgfId-1184975"></a>We will go through this section in three stages. First, let’s examine how we can define a Keras model to suit the output features we have defined in the TFX <span class="fm-code-in-text">Transform</span> component. Ultimately, the model will receive the output of the <span class="fm-code-in-text">Transform</span> component. Next, we will look at how we can write a function that encapsulates model training. This function will use the model defined and, along with several user-defined arguments, train the model and save it to a desired path. The saved model cannot be just any model; it has to have what are known as <i class="fm-italics">signatures</i> in TensorFlow. These signatures dictate what the inputs to the model and outputs of the model look like when it’s finally used via an API. The API is served via a server that exposes a network port for the client to communicate with the API. Figure 15.6 depicts how the API ties in with the model.</p>

  <p class="fm-figure"><img alt="15-06" class="calibre10" src="../../OEBPS/Images/15-06.png" width="1081" height="842"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1214281"></a>Figure 15.6 How the model interacts with the API, the TensorFlow server, and the client</p>

  <p class="body"><a class="calibre8" id="pgfId-1184982"></a>Let’s understand what is taking place in figure 15.6. First, an HTTP client sends a request to the server. The server (i.e., a TensorFlow serving server) that is listening for any incoming requests will read the request and direct that to the required model signature. Once the data is received by the model signature, it will perform necessary processing on the data, run it through the model, and produce the output (e.g., predictions). Once the predictions are available, they will be returned by the server to the client. We will discuss the API and the server side in detail in a separate section. In this section, our focus is on the model.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1184983"></a>What is a signature in TensorFlow serving?</p>

    <p class="fm-sidebar-text"><a id="pgfId-1184984"></a>In real life, the purpose of a signature is to uniquely identify a person. Similarly, TensorFlow uses signatures to uniquely determine how a model should behave when an input is passed to the model via a HTTP request. A signature has a key and a value. The key is a unique identifier that defines to which exact URL that signature will be activated. The value is defined as a TensorFlow function (i.e., a function decorated with <span class="fm-code-in-text1">@tf.function</span>). This function will define how an input is handled and passed to the model to obtain the final desired result. You don’t need to worry about the details at this point. We have a separate section dedicated to learning about signatures.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1184986"></a>We will circle back to signatures in a separate subsection to understand them in more detail. Finally, we will visually inspect model predictions by loading the model and feeding some data into it.</p>

  <h3 class="fm-head1" id="sigil_toc_id_196"><a id="pgfId-1184987"></a>15.2.1 Defining a Keras model</h3>

  <p class="body"><a class="calibre8" id="pgfId-1184993"></a>The <a class="calibre8" id="marker-1184988"></a><a class="calibre8" id="marker-1184989"></a><a class="calibre8" id="marker-1184990"></a><a class="calibre8" id="marker-1184992"></a>cornerstone for training the model with TFX is defining a model. There are two ways to define models for TFX: using the Estimator API or using the Keras API. We are going to go with the Keras API, as the Estimator API is not recommended for TensorFlow 2 (see the following sidebar for more details).</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1184994"></a>Estimator API vs. Keras API</p>

    <p class="fm-sidebar-text"><a id="pgfId-1184995"></a>My view is that going forward, Keras is probably going to be the go-to API for building models, and the Estimator API could perhaps be deprecated. The TensorFlow website says the following:</p>

    <p class="fm-sidebar-text"><a class="calibre8" id="pgfId-1184996"></a>Estimators are not recommended for new code. Estimators run v1.Session-style code which is more difficult to write correctly, and can behave unexpectedly, especially when combined with TF 2 code. Estimators do fall under our compatibility guarantees but will receive no fixes other than security vulnerabilities. See the migration guide for details.</p>

    <p class="fm-sidebar-text"><br class="calibre2"/></p>

    <p class="fm-sidebar-text"><a class="calibre8" id="pgfId-1184997"></a>Source: <span class="fm-hyperlink"><a class="url" href="https://www.tensorflow.org/tfx/tutorials/tfx/components">https://www.tensorflow.org/tfx/tutorials/tfx/components</a></span></p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1185000"></a>We are first going to create a function called <span class="fm-code-in-text">_build_keras_model()</span>, which will do two things. First, it will create <span class="fm-code-in-text">tf.feature_column</span>-type objects<a class="calibre8" id="marker-1185001"></a> for all the features we have defined in our <span class="fm-code-in-text">Transform</span> step. <span class="fm-code-in-text">tf.feature_column</span> is a feature representation standard and is accepted by models defined in TensorFlow. It is a handy tool for defining data in a column-oriented fashion (i.e., each feature represented as a column). Columnar representation is very suitable for structured data, where each column typically is an independent predictor for the target variable. Let’s examine a few specific <span class="fm-code-in-text">tf.feature_column</span> types<a class="calibre8" id="marker-1185002"></a> that are found in TensorFlow:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185003"></a><span class="fm-code-in-text">tf.feature_column.numeric_column</span>—Used to represent dense floating-point fields like temperature.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185004"></a><span class="fm-code-in-text">tf.feature_column.categorical_column_with_identity</span>—Used to represent categorical fields or bucketized fields where the value is an integer index pointing to a category or a bucket, such as day or month. Because the value passed to the column itself is the category ID, the term “identity” is used.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185005"></a><span class="fm-code-in-text">tf.feature_column.indicator_column</span>—Converts a <span class="fm-code-in-text">tf.feature_column.categorical_column_with_identity</span> to a one-hot encoded representation.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185006"></a><span class="fm-code-in-text">tf.feature_column.embedding_column</span>—Can be used to generate an embedding from an integer-based column like <span class="fm-code-in-text">tf.feature_column.categorical_column_with_identity</span><i class="fm-italics">. It maintains an embedding layer internally and will return the corresponding embedding, given an integer ID.</i></p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185007"></a>To see the full list, refer to <span class="fm-hyperlink"><a class="url" href="http://mng.bz/6Xeo">http://mng.bz/6Xeo</a></span>. Here, we will use the top three types of <span class="fm-code-in-text">tf.feature_columns</span> as inputs to our to-be defined model. The following listing outlines how <span class="fm-code-in-text">tf.feature_columns</span> are used as inputs.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1185010"></a>Listing 15.6 Building the Keras model using feature columns</p>
  <pre class="programlisting">def _build_keras_model() -&gt; tf.keras.Model:                     <span class="fm-combinumeral">❶</span>
  
  real_valued_columns = [                                       <span class="fm-combinumeral">❷</span>
      tf.feature_column.numeric_column(key=key, shape=(1,))
      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)
  ]
  
  categorical_columns = [                                       <span class="fm-combinumeral">❸</span>
      tf.feature_column.indicator_column(
          tf.feature_column.categorical_column_with_identity(
              key, 
              num_buckets=len(boundaries)+1
          )
      ) for key, boundaries in zip(
          _transformed_names(_BUCKET_FEATURE_KEYS),
          _BUCKET_FEATURE_BOUNDARIES
      )
  ]
    
  categorical_columns += [                                      <span class="fm-combinumeral">❹</span>
      tf.feature_column.indicator_column(
          tf.feature_column.categorical_column_with_identity( 
              key,
              num_buckets=num_buckets,
              default_value=num_buckets-1
          )
      ) for key, num_buckets in zip(
              _transformed_names(_VOCAB_FEATURE_KEYS),
              _MAX_CATEGORICAL_FEATURE_VALUES
      )      
  ]
 
  model = _dnn_regressor(                                       <span class="fm-combinumeral">❺</span>
      columns=real_valued_columns+categorical_columns,          <span class="fm-combinumeral">❻</span>
      dnn_hidden_units=[128, 64]                                <span class="fm-combinumeral">❼</span>
  )
 
  return model</pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1209475"></a><span class="fm-combinumeral">❶</span> Define the function signature. It returns a Keras model as the output.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1209503"></a><span class="fm-combinumeral">❷</span> Create tf.feature_column objects for dense features.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1209520"></a><span class="fm-combinumeral">❸</span> Create tf.feature_column objects for the bucketized features.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1209537"></a><span class="fm-combinumeral">❹</span> Create tf.feature_column objects for the categorical features.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1209554"></a><span class="fm-combinumeral">❺</span> Define a deep regressor model using the function.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1209571"></a><span class="fm-combinumeral">❻</span> Uses the columns defined above</p>

  <p class="fm-code-annotation-mob"><a class="calibre8" id="pgfId-1209588"></a><span class="fm-combinumeral">❼</span> It will have two intermediate layers: 128 nodes and 64 nodes.</p>

  <p class="body"><a class="calibre8" id="pgfId-1185057"></a>Let’s look at the first set of feature columns stored in <span class="fm-code-in-text">real_valued_columns</span>. We take transformed names of the original keys of dense floating-point valued columns, and for each column, we create a <span class="fm-code-in-text">tf.feature_column.numeric_column</span>. You can see that we are passing</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185058"></a><i class="fm-italics">A key</i> (string)—Name of the feature</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185059"></a><i class="fm-italics">A shape</i> (a list/tuple)—Full shape will be derived as [batch size] + shape</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185060"></a>For example, the column <span class="fm-code-in-text">temp</span> will have the key as <span class="fm-code-in-text">temp_xf</span> and shape as <span class="fm-code-in-text">(1,)</span>, meaning that the full shape is <span class="fm-code-in-text">[batch size, 1]</span>. This shape of <span class="fm-code-in-text">[batch size, 1]</span> makes sense since each dense feature has a single value per record (meaning that we don’t need a feature dimensionality in the shape). Let’s go through a toy example to see a <span class="fm-code-in-text">tf.feature_column.numeric_column</span> in action:</p>
  <pre class="programlisting">a = tf.feature_column.numeric_column("a")
x = tf.keras.layers.DenseFeatures(a)({'a': [0.5, 0.6]})
print(x)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185065"></a>This will output</p>
  <pre class="programlisting">tf.Tensor(
[[0.5]
 [0.6]], shape=(2, 1), dtype=float32)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185069"></a>When defining <span class="fm-code-in-text">tf.feature_column.categorical_column_with_identity</span> for the bucketized features, you need to pass</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185070"></a>A <span class="fm-code-in-text">key</span> (string)—Name of the feature</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185071"></a><span class="fm-code-in-text">num_buckets</span> (int)—Number of buckets in the bucketized feature</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185073"></a>For instance, the <span class="fm-code-in-text">RH</span> feature that was bucketized will have the key <span class="fm-code-in-text">RH_xf</span> and <span class="fm-code-in-text">num_buckets = 3</span>, where the buckets are [[-inf, 33), [33, 66), [66, inf]]. Since we defined the bucket boundary for <span class="fm-code-in-text">RH</span> as (33, 66), <span class="fm-code-in-text">num_buckets</span> is defined as <span class="fm-code-in-text">len(boundaries) +1</span> = 3. Finally, each categorical feature is wrapped in a <span class="fm-code-in-text">tf.feature_column.indicator_column</span> to convert each feature to one-hot encoded representation. Again, we can do a quick experiment to see the effects of these feature columns as follows:</p>
  <pre class="programlisting">b = tf.feature_column.indicator_column(
    tf.feature_column.categorical_column_with_identity('b', num_buckets=10)
)
y = tf.keras.layers.DenseFeatures(b)({'b': [5, 2]})
print(y)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185079"></a>This will produce</p>
  <pre class="programlisting">tf.Tensor(
[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]], shape=(2, 10), dtype=float32)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185083"></a>Finally, the vocabulary-based categorical features are treated similarly to the bucketized features. For each feature, we get the feature name and the maximum number of categories and define a <span class="fm-code-in-text">tf.feature_column.categorical_column_with_identity</span> column with</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185084"></a><span class="fm-code-in-text">key</span> (string)—Name of the feature.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185085"></a><span class="fm-code-in-text">num_buckets</span> (int)—Number of categories.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185086"></a><span class="fm-code-in-text">default_value</span> (int)—If a previously unseen category is encountered, it will be assigned this value.</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185087"></a>Here, <span class="fm-code-in-text">default_value</span> is an important part. It will dictate what happens to any unseen categories that might appear in the testing data and that weren’t a part of the training data. The vocabulary-based categorical features in our problem were day and month, which can only have 7 and 12 distinct values. But there could be situations where the training set only has 11 months and the test set has 12 months. To tackle this, we will assign any unseen category to the last category ID (i.e., <span class="fm-code-in-text">num_buckets</span> - 1) available to us.</p>

  <p class="body"><a class="calibre8" id="pgfId-1185088"></a>We now have a collection of well-defined data columns that are wrapped in <span class="fm-code-in-text">tf.feature_column</span> objects<a class="calibre8" id="marker-1185089"></a> ready to be fed to a model. Finally, we see a function called <span class="fm-code-in-text">_dnn_regressor()</span> that will create a Keras model, which is shown in the next listing, and pass the columns we create and some other hyperparameters. Let’s now discuss the specifics of this function.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1185092"></a>Listing 15.7 Defining the regression neural network</p>
  <pre class="programlisting">def _dnn_regressor(columns, dnn_hidden_units):                            <span class="fm-combinumeral">❶</span>
 
 
  input_layers = {
      colname: tf.keras.layers.Input(
          name=colname, shape=(), dtype=tf.float32
      )                                                                   <span class="fm-combinumeral">❷</span>
      for colname in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)
  }
  input_layers.update({
      colname: tf.keras.layers.Input(
          name=colname, shape=(), dtype='int32'
      )                                                                   <span class="fm-combinumeral">❸</span>
      for colname in _transformed_names(_VOCAB_FEATURE_KEYS)
  })
  input_layers.update({
      colname: tf.keras.layers.Input(
          name=colname, shape=(), dtype='int32'
      )                                                                   <span class="fm-combinumeral">❹</span>
      for colname in _transformed_names(_BUCKET_FEATURE_KEYS)
  })  
 
  output = tf.keras.layers.DenseFeatures(columns)(input_layers)           <span class="fm-combinumeral">❺</span>
  for numnodes in dnn_hidden_units:
    output = tf.keras.layers.Dense(numnodes, activation='tanh')(output)   <span class="fm-combinumeral">❻</span>
  
  output = tf.keras.layers.Dense(1)(output)                               <span class="fm-combinumeral">❼</span>
 
  model = tf.keras.Model(input_layers, output)                            <span class="fm-combinumeral">❽</span>
  model.compile(
      loss='mean_squared_error',                                          <span class="fm-combinumeral">❾</span>
      optimizer=tf.keras.optimizers.Adam(lr=0.001)
  )
  model.summary(print_fn=absl.logging.info)                               <span class="fm-combinumeral">❿</span>
 
  return model</pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208606"></a><span class="fm-combinumeral">❶</span> Define a function that takes a bunch of columns and a list of hidden dimensions as the input.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208627"></a><span class="fm-combinumeral">❷</span> Inputs to the model: an input dictionary where the key is the feature name and the value is a Keras Input layer</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208654"></a><span class="fm-combinumeral">❸</span> Update the dictionary by creating Input layers for vocabulary-based categorical features.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208671"></a><span class="fm-combinumeral">❹</span> Update the dictionary by creating Input layers for bucketized features.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208688"></a><span class="fm-combinumeral">❺</span> As input layers are defined as a dictionary, we use the DenseFeatures layer to generate a single tensor output.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208705"></a><span class="fm-combinumeral">❻</span> We recursively compute the output by creating a sequence of Dense layers.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208722"></a><span class="fm-combinumeral">❼</span> Create a final regression layer that has one output node and a linear activation.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208739"></a><span class="fm-combinumeral">❽</span> Define the model using inputs and outputs.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208756"></a><span class="fm-combinumeral">❾</span> Compile the model. Note how it uses the mean squared error as the loss function.</p>

  <p class="fm-code-annotation-mob"><a class="calibre8" id="pgfId-1208773"></a><span class="fm-combinumeral">❿</span> Print a summary of the model through the absl logger we defined at the beginning.</p>

  <p class="body"><a class="calibre8" id="pgfId-1185139"></a>We have defined the data in a columnar fashion, where each column is a TensorFlow feature column. Once the data defined in this way, we use a special layer called <span class="fm-code-in-text">tf.keras.layers.DenseFeatures</span><a class="calibre8" id="marker-1185140"></a> <i class="fm-italics">to process this data. The</i> <span class="fm-code-in-text">DenseFeatures</span> <i class="fm-italics">layer</i><a class="calibre8" id="marker-1185141"></a> accepts</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185142"></a>A list of feature columns</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185145"></a>A dictionary of <span class="fm-code-in-text">tf.keras.layers.Input</span> layers<a class="calibre8" id="marker-1185143"></a>, where each <span class="fm-code-in-text">Input</span> layer<a class="calibre8" id="marker-1185144"></a> is keyed with a column name found in the list of feature columns</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185146"></a>With this data, the <span class="fm-code-in-text">DenseFeatures</span> layer can map each <span class="fm-code-in-text">Input</span> layer to the corresponding feature column and produce a single tensor output at the end (stored in the variable <span class="fm-code-in-text">output</span>) (figure 15.7).</p>

  <p class="fm-figure"><img alt="15-07" class="calibre10" src="../../OEBPS/Images/15-07.png" width="1014" height="747"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1214315"></a>Figure 15.7 Overview of the functionality of the <span class="fm-code-in-figurecaption">DenseFeatures</span> layer</p>

  <p class="body"><a class="calibre8" id="pgfId-1185153"></a>Then we recursively compute the output by flowing the data through several hidden layers. The sizes of these hidden layers (a list of integers) are passed in as an argument to the function. We will use tanh nonlinear activation for the hidden layers. The final hidden output goes to a single node regression layer that has a linear activation.</p>

  <p class="body"><a class="calibre8" id="pgfId-1185154"></a>Finally, we compile the model with the Adam optimizer and mean-squared loss as the loss function. It is important to note that we have to use a regression-compatible loss function for the model. The mean-squared error is a very common loss function chosen for regression problems.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1185155"></a>Type hinting in Python</p>

    <p class="fm-sidebar-text"><a id="pgfId-1185156"></a>You will see some functions defined differently than we have done in the past. For example, functions are defined as</p>
    <pre class="programlisting">def _build_keras_model() -&gt; tf.keras.Model:</pre>

    <p class="fm-sidebar-text"><a id="pgfId-1185158"></a>or</p>
    <pre class="programlisting">def run_fn(fn_args: tfx.components.FnArgs):</pre>

    <p class="fm-sidebar-text"><a id="pgfId-1185160"></a>This is visual type-hinting and is available in Python. This means that the types are not enforced by the Python interpreter in any way; rather, they are a visual cue to make sure the developer uses the correct types of inputs and outputs. When defining arguments in a function, you can define the type of the data expected for that argument using the syntax <span class="fm-code-in-text1">def &lt;function&gt;(&lt;argument&gt;: &lt;type&gt;):</span>. For example, in the function <span class="fm-code-in-text1">run_fn()</span>, the first argument <span class="fm-code-in-text1">fn_args</span> must be of type <span class="fm-code-in-text1">tfx.components .FnArgs</span>.</p>

    <p class="fm-sidebar-text"><br class="calibre2"/></p>

    <p class="fm-sidebar-text"><a id="pgfId-1185162"></a>Then you can also define the output returned by the function as <span class="fm-code-in-text1">def &lt;function&gt; (&lt;argument&gt;: &lt;type&gt;) -&gt; &lt;return type&gt;:</span>. For example, the returned object by <span class="fm-code-in-text1">_build_keras_model()</span> function must be a <span class="fm-code-in-text1">tf.keras.Model</span> object<a id="marker-1188010"></a>.</p>

    <p class="fm-sidebar-text"><br class="calibre2"/></p>

    <p class="fm-sidebar-text"><a id="pgfId-1185164"></a>Some objects require complex data types that need to be created using multiple data types or custom data types (e.g., a list of strings). For this, you can use a built-in Python library called <span class="fm-code-in-text1">typing</span><a id="marker-1188012"></a>. <span class="fm-code-in-text1">typing</span> allows you to define data types conveniently. For more information, refer to <span class="fm-hyperlink"><a class="url" href="https://docs.python.org/3/library/typing.html">https://docs.python.org/3/library/typing.html</a></span>.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1185167"></a>In listing 15.8, we define a function that, given a set of training data filenames and evaluation data filenames, generates <span class="fm-code-in-text">tf.data.Dataset</span> objects<a class="calibre8" id="marker-1185168"></a> for training and evaluation data. We define this special function as <span class="fm-code-in-text">_input_fn()</span>. <span class="fm-code-in-text">_input_fn()</span> takes in three things:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185170"></a><span class="fm-code-in-text">file_pattern</span>—A set of file paths, where files contain data</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185171"></a><span class="fm-code-in-text">data_accessor</span>—A special object in TFX that creates a <span class="fm-code-in-text">tf.data.Dataset</span> by taking in a list of filenames and other configuration</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185172"></a><span class="fm-code-in-text">batch_size</span>—An integer specifying the size of a batch of data</p>
    </li>
  </ul>

  <p class="fm-code-listing-caption"><a id="pgfId-1185174"></a>Listing 15.8 A function to generate a <span class="fm-code-in-listingcaption">tf.data.Dataset</span> using the input files</p>
  <pre class="programlisting">from typing import List, Text                                <span class="fm-combinumeral">❶</span>
 
def _input_fn(file_pattern: List[Text],                      <span class="fm-combinumeral">❷</span>
              data_accessor: tfx.components.DataAccessor,    <span class="fm-combinumeral">❸</span>
              tf_transform_output: tft.TFTransformOutput,    <span class="fm-combinumeral">❹</span>
              batch_size: int = 200) -&gt; tf.data.Dataset:     <span class="fm-combinumeral">❺</span>
 
  return data_accessor.tf_dataset_factory(
      file_pattern,
      tfxio.TensorFlowDatasetOptions(
          batch_size=batch_size, label_key=_transformed_name(_LABEL_KEY)),
      tf_transform_output.transformed_metadata.schema)</pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208303"></a><span class="fm-combinumeral">❶</span> The typing library defines the type of inputs to the function.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208324"></a><span class="fm-combinumeral">❷</span> List of paths or patterns of input tfrecord files. It is a list of objects of type Text (i.e., strings).</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208341"></a><span class="fm-combinumeral">❸</span> DataAccessor for converting input to RecordBatch</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1208358"></a><span class="fm-combinumeral">❹</span> A TFTransformOutput</p>

  <p class="fm-code-annotation-mob"><a class="calibre8" id="pgfId-1208375"></a><span class="fm-combinumeral">❺</span> Represents the number of consecutive elements of the returned data set to combine in a single batch</p>

  <p class="body"><a class="calibre8" id="pgfId-1185193"></a>You can see how we are using type hints for the arguments as well as the return object. The function returns a <span class="fm-code-in-text">tf.data.Dataset</span> obtained by calling the <span class="fm-code-in-text">tf_dataset_factory()</span> function<a class="calibre8" id="marker-1198317"></a> with a list of file paths and data set options like batch size and label key. The label key is important for the <span class="fm-code-in-text">data_accessor</span> to determine input fields and the target. You can see that the data accessor takes in the schema from the <span class="fm-code-in-text">Transform</span> step as well. This helps the <span class="fm-code-in-text">data_accessor</span> to transform the raw examples to features and then separate the inputs and the label. With all the key functions explained, we now move on to see how all of these will be orchestrated in order to do the model <a class="calibre8" id="marker-1198318"></a><a class="calibre8" id="marker-1198319"></a><a class="calibre8" id="marker-1198320"></a><a class="calibre8" id="marker-1198322"></a>training.</p>

  <h3 class="fm-head1" id="sigil_toc_id_197"><a id="pgfId-1185200"></a>15.2.2 Defining the model training</h3>

  <p class="body"><a class="calibre8" id="pgfId-1185206"></a>The <a class="calibre8" id="marker-1185201"></a><a class="calibre8" id="marker-1185202"></a><a class="calibre8" id="marker-1185203"></a><a class="calibre8" id="marker-1185204"></a><a class="calibre8" id="marker-1185205"></a>main task that’s standing between us and a train model is the actual training of the model. The TFX component responsible for training the model (known as <span class="fm-code-in-text">Trainer</span>) expects a special function named <span class="fm-code-in-text">run_fn()</span> that will tell how the model should be trained and eventually saved (listing 15.9). This function takes in a special type of object called <span class="fm-code-in-text">FnArgs</span><a class="calibre8" id="marker-1185207"></a>, a utility object in TensorFlow that can be used to declare model training-related user-defined arguments that need to be passed to a model training function.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1185209"></a>Listing 15.9 Running the Keras model training with the data</p>
  <pre class="programlisting">def run_fn(fn_args: tfx.components.FnArgs):                        <span class="fm-combinumeral">❶</span>
 
  absl.logging.info("="*50)
  absl.logging.info("Printing the tfx.components.FnArgs object")   <span class="fm-combinumeral">❷</span>
  absl.logging.info(fn_args)                                       <span class="fm-combinumeral">❷</span>
  absl.logging.info("="*50)
 
  tf_transform_output = tft.TFTransformOutput(
    fn_args.transform_graph_path
  )                                                                <span class="fm-combinumeral">❸</span>
 
  train_dataset = _input_fn(
    fn_args.train_files, fn_args.data_accessor, tf_transform_output, 
<span class="fm-code-continuation-arrow">➥</span> 40                                                              <span class="fm-combinumeral">❹</span>
  )
  eval_dataset = _input_fn(
    fn_args.eval_files, fn_args.data_accessor, tf_transform_output, 
<span class="fm-code-continuation-arrow">➥</span> 40                                                              <span class="fm-combinumeral">❹</span>
  )
  model = _build_keras_model()                                     <span class="fm-combinumeral">❺</span>
  
  csv_write_dir = os.path.join(
    fn_args.model_run_dir,'model_performance'
)                                                                  <span class="fm-combinumeral">❻</span>
  os.makedirs(csv_write_dir, exist_ok=True)
 
  csv_callback = tf.keras.callbacks.CSVLogger(
    os.path.join(csv_write_dir, 'performance.csv'), append=False   <span class="fm-combinumeral">❼</span>
  )
 
  model.fit(                                                       <span class="fm-combinumeral">❽</span>
      train_dataset,
      steps_per_epoch=fn_args.train_steps,
      validation_data=eval_dataset,
      validation_steps=fn_args.eval_steps,
      epochs=10,
      callbacks=[csv_callback]
  )
 
  signatures = {                                                   <span class="fm-combinumeral">❾</span>
      'serving_default':
          _get_serve_tf_examples_fn(
              model, tf_transform_output
          ).get_concrete_function(
              tf.TensorSpec(
                  shape=[None],
                  dtype=tf.string,
                  name='examples'
              )
          ),
      
  }
  model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)                                        <span class="fm-combinumeral">❿</span></pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1207449"></a><span class="fm-combinumeral">❶</span> Define a function called run_fn that takes a tfx.components.FnArgs object as the input.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1207470"></a><span class="fm-combinumeral">❷</span> Log the values in the fn_args object.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1207487"></a><span class="fm-combinumeral">❸</span> Load the tensorflow_transform graph.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1207504"></a><span class="fm-combinumeral">❹</span> Convert the data in the CSV files to tf.data.Dataset objects using the function _input_fn (discussed soon).</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1207521"></a><span class="fm-combinumeral">❺</span> Build the Keras model using the previously defined function.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1207541"></a><span class="fm-combinumeral">❻</span> Define a directory to store CSV logs produced by the Keras callback CSVLogger.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1207558"></a><span class="fm-combinumeral">❼</span> Define the CSVLogger callback.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1207575"></a><span class="fm-combinumeral">❽</span> Fit the model using the data sets created and the hyperparameters present in the fn_args object.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1207592"></a><span class="fm-combinumeral">❾</span> Define signatures for the model. Signatures tell the model what to do when data is sent via an API call when the model is deployed.</p>

  <p class="fm-code-annotation-mob"><a class="calibre8" id="pgfId-1207609"></a><span class="fm-combinumeral">❿</span> Save the model to the disk.</p>

  <p class="body"><a class="calibre8" id="pgfId-1185275"></a>Let’s first check the method signature of the <span class="fm-code-in-text">run_fn()</span>. <span class="fm-code-in-text">run_fn()</span> takes in a single argument of type <span class="fm-code-in-text">FnArgs</span><a class="calibre8" id="marker-1185276"></a> as the input. As mentioned earlier, <span class="fm-code-in-text">FnArgs</span> is a utility object that stores a collection of key-value pairs that are useful for model training. Most of the elements in this object are populated by the TFX component itself. However, you also have the flexibility to pass some of the values. We will define some of the most important attributes in this object. But we will learn more about the full list of attributes once we see the full output produced by the TFX Trainer component. Table 15.2 provides you a taste of what is stored in this object. Don’t worry if you don’t fully understand the purpose of these elements. It will be clearer as we go through the chapter. Once we run the Trainer component, it will display the values used for every one of these attributes, as we have included logging statements to log the <span class="fm-code-in-text">fn_args</span> object. This will help us to contextualize these properties with the example we’re running and understand them more clearly.</p>

  <p class="fm-table-caption"><a id="pgfId-1192828"></a>Table 15.2 An overview of the attributes stored in the <span class="fm-code-in-figurecaption">fn_args</span>-type object</p>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre12">
      <col class="calibre13" span="1" width="33.33%"/>
      <col class="calibre13" span="1" width="33.33%"/>
      <col class="calibre13" span="1" width="33.33%"/>
    </colgroup>

    <tr class="calibre14">
      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1192834"></a><b class="fm-bold">Attribute</b></p>
      </th>

      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1192836"></a><b class="fm-bold">Description</b></p>
      </th>

      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1192838"></a><b class="fm-bold">Example</b></p>
      </th>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192840"></a><span class="fm-code-in-figurecaption">train_files</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192842"></a>A list of train filenames</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192844"></a><span class="fm-code-in-figurecaption">['.../Transform/transformed_examples/16/Split-train/*'],</span></p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192846"></a><span class="fm-code-in-figurecaption">eval_files</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192848"></a>A list of evaluation/validation filenames</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192850"></a><span class="fm-code-in-figurecaption">['.../Transform/transformed_examples/16/Split-eval/*']</span></p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192852"></a><span class="fm-code-in-figurecaption">train_steps</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192854"></a>Number of training steps</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192856"></a>100</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192858"></a><span class="fm-code-in-figurecaption">eval_steps</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192860"></a>Number of evaluation/validation steps</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192862"></a>100</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192864"></a><span class="fm-code-in-figurecaption">schema_path</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192866"></a>Path to the schema generated by the TFX component <span class="fm-code-in-figurecaption">SchemaGen</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192868"></a><span class="fm-code-in-figurecaption">'.../SchemaGen/schema/15/schema.pbtxt'</span></p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192870"></a><span class="fm-code-in-figurecaption">transform_graph_path</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192872"></a>Path to the transform graph generated by the TFX component <span class="fm-code-in-figurecaption">Transform</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192874"></a><span class="fm-code-in-figurecaption">'.../SchemaGen/schema/15/schema.pbtxt'</span></p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192876"></a><span class="fm-code-in-figurecaption">serve_model_dir</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192878"></a>Output directory where the serve-able model will be saved</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192880"></a><span class="fm-code-in-figurecaption">'.../Trainer/model/17/Format-Serving'</span></p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192882"></a><span class="fm-code-in-figurecaption">model_run_dir</span></p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192884"></a>Output directory where the model is saved</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1192886"></a><span class="fm-code-in-figurecaption">'.../Trainer/model_run/17'</span></p>
      </td>
    </tr>
  </table>

  <p class="body"><a class="calibre8" id="pgfId-1185338"></a>The first important task done by this function is generating <span class="fm-code-in-text">tf.data.Dataset</span> objects for training and evaluation data. We have defined a special function called <span class="fm-code-in-text">_input_fn()</span> that achieves this (listing 15.8).</p>

  <p class="body"><a class="calibre8" id="pgfId-1185339"></a>Once the data sets are defined, we define the Keras model using the <span class="fm-code-in-text">_build_keras_model()</span> function we discussed earlier. Then we define a <span class="fm-code-in-text">CSVLogger</span> callback<a class="calibre8" id="marker-1192935"></a> to log the performance metrics over epochs, as we did earlier. As a brief review, the <span class="fm-code-in-text">tf.keras.callbacks.CSVLogger</span> creates a CSV file with all the losses and metrics defined during model compilation, logged every epoch. We will use the <span class="fm-code-in-text">fn_arg</span> object’s <span class="fm-code-in-text">model_run_dir</span> attribute to create a path for the CSV file inside the model creation directory. This will make sure that if we run multiple training trials, each will have its own CSV file saved along with the model. After that, we call the <span class="fm-code-in-text">model.fit()</span> function<a class="calibre8" id="marker-1192937"></a> as we have done countless times. The arguments we have used are straightforward, so we will not discuss them in detail and lengthen this discussion <a class="calibre8" id="marker-1192938"></a><a class="calibre8" id="marker-1192939"></a><a class="calibre8" id="marker-1192940"></a><a class="calibre8" id="marker-1192941"></a><a class="calibre8" id="marker-1192942"></a>unnecessarily.</p>

  <h3 class="fm-head1" id="sigil_toc_id_198"><a id="pgfId-1185348"></a>15.2.3 SignatureDefs: Defining how models are used outside TensorFlow</h3>

  <p class="body"><a class="calibre8" id="pgfId-1185354"></a>Once <a class="calibre8" id="marker-1185349"></a><a class="calibre8" id="marker-1185350"></a><a class="calibre8" id="marker-1185351"></a><a class="calibre8" id="marker-1185352"></a><a class="calibre8" id="marker-1185353"></a>the model is trained, we have to store the model on disk so that it can be reused later. The objective of storing this model is to use this via a web-based API (i.e., a REST API) to query the model using inputs and get predictions out. This is typically how machine learning models are used to serve customers in an online environment. For models to understand web-based requests, we need to define things called <span class="fm-code-in-text">SignatureDefs</span>. A signature defines things like what an input or target to the model looks like (e.g., data type). You can see that we have defined a dictionary called <span class="fm-code-in-text">signatures</span> and passed it as an argument to <span class="fm-code-in-text">model.save()</span>(listing 15.9).</p>

  <p class="body"><a class="calibre8" id="pgfId-1185356"></a>The <span class="fm-code-in-text">signatures</span> dictionary<a class="calibre8" id="marker-1185355"></a> should have key-value pairs, where key is a signature name and value is a function decorated with the <span class="fm-code-in-text">@tf.function</span> decorator<a class="calibre8" id="marker-1185357"></a>. If you want a quick refresher on what this decorator does, read the following sidebar.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1185358"></a>The @tf.function decorator</p>

    <p class="fm-sidebar-text"><a id="pgfId-1185359"></a>The <span class="fm-code-in-text1">@tf.function</span> decorator takes in a function that performs various TensorFlow operations with TensorFlow operands, and then traces all the steps and turns that into a data-flow graph. In most cases, TensorFlow requires a data-flow graph showing how inputs and outputs are connected between operations. Though in TensorFlow 1.x you had to explicitly build this graph, TensorFlow 2.x onward doesn’t encumber the developer with this responsibility. Whenever a function is decorated with the <span class="fm-code-in-text1">@tf.function</span> decorator, it builds the data-flow graph for us.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1185361"></a>It is also important to note that you cannot use arbitrary names as signature names. TensorFlow has a set of defined signature names, depending on your needs. These are defined in a special constant module in TensorFlow (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/o2Kd">http://mng.bz/o2Kd</a></span>). There are four signatures to choose from:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185362"></a><span class="fm-code-in-text">PREDICT_METHOD_NAME</span> (value: <span class="fm-code-in-text">'tensorflow/serving/predict'</span>)—This signature is used to predict the target for incoming inputs. This does not expect the target to be present.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185363"></a><span class="fm-code-in-text">REGRESS_METHOD_NAME</span> (value: <span class="fm-code-in-text">'tensorflow/serving/regress'</span>)—This signature can be used to regress from an example. It expects both an input and an output (i.e., target value) to be present in the HTTP request body.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185364"></a><span class="fm-code-in-text">CLASSIFY_METHOD_NAME</span> (value: <span class="fm-code-in-text">'tensorflow/serving/classify'</span>)—This is similar to <span class="fm-code-in-text">REGRESS_METHOD_NAME</span>, except for classification. This signature can be used to classify an example. It expects both an input and an output (i.e., target value) to be present in the HTTP.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185365"></a><span class="fm-code-in-text">DEFAULT_SERVING_SIGNATURE_DEF_KEY</span> (value: <span class="fm-code-in-text">'serving_default'</span>)—This is the default signature name. A model should at least have the default serving signature in order to be used via an API. If none of the other signatures are defined, requests will go through this signature.</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185366"></a>We will only define the default signature here. Signatures take a TensorFlow function (i.e., a function decorated with <span class="fm-code-in-text">@tf.function</span>) as a value. Therefore, we need to define a function (which we will call <span class="fm-code-in-text">_get_serve_tf_examples_fn()</span> ) that will tell TensorFlow what to do with an input (see the next listing).</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1185368"></a>Listing 15.10 Parsing examples sent through API requests and predicting from them</p>
  <pre class="programlisting">def _get_serve_tf_examples_fn(model, tf_transform_output):            <span class="fm-combinumeral">❶</span>
 
  model.tft_layer = tf_transform_output.transform_features_layer()    <span class="fm-combinumeral">❷</span>
 
  @tf.function
  def serve_tf_examples_fn(serialized_tf_examples):                   <span class="fm-combinumeral">❸</span>
    """Returns the output to be used in the serving signature."""
    feature_spec = tf_transform_output.raw_feature_spec()             <span class="fm-combinumeral">❹</span>
    feature_spec.pop(_LABEL_KEY)                                      <span class="fm-combinumeral">❺</span>
    parsed_features = tf.io.parse_example(serialized_tf_examples, 
<span class="fm-code-continuation-arrow">➥</span> feature_spec)                                                      <span class="fm-combinumeral">❻</span>
    transformed_features = model.tft_layer(parsed_features)           <span class="fm-combinumeral">❼</span>
    return model(transformed_features)                                <span class="fm-combinumeral">❽</span>
 
  return serve_tf_examples_fn                                         <span class="fm-combinumeral">❾</span></pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206863"></a><span class="fm-combinumeral">❶</span> Returns a function that parses a serialized tf.Example and applies feature transformations</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206894"></a><span class="fm-combinumeral">❷</span> Get the feature transformations to be performed as a Keras layer.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206911"></a><span class="fm-combinumeral">❸</span> The function decorated with @tf.function to be returned</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206928"></a><span class="fm-combinumeral">❹</span> Get the raw column specifications.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206945"></a><span class="fm-combinumeral">❺</span> Remove the feature spec for the label as we do not want that during predictions.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206962"></a><span class="fm-combinumeral">❻</span> Parse the serialized example using the feature specifications.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206979"></a><span class="fm-combinumeral">❼</span> Convert raw columns to features using the layer defined.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206996"></a><span class="fm-combinumeral">❽</span> Return the output of the model after feeding the transformed features.</p>

  <p class="fm-code-annotation-mob"><a class="calibre8" id="pgfId-1207013"></a><span class="fm-combinumeral">❾</span> Return the TensorFlow function.</p>

  <p class="body"><a class="calibre8" id="pgfId-1185393"></a>The first important thing to note is that <span class="fm-code-in-text">_get_serve_tf_examples_fn()</span> returns a function (i.e., <span class="fm-code-in-text">serve_tf_examples_fn</span>), which is a TensorFlow function. The <span class="fm-code-in-text">_get_serve_tf_examples_fn()</span> accepts two inputs:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185394"></a><span class="fm-code-in-text">Model</span>—The Keras model we built during training time</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185395"></a><span class="fm-code-in-text">tf_transform_output</span>—The transformation graph to convert raw data to features</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185396"></a>This returned function should instruct TensorFlow on what to do with the data that came in through an API request once the model is deployed. The returned function takes serialized examples as inputs, parses them to be in the correct format as per the model input specifications, generates the output, and returns it. We will not dive too deeply into what the inputs and outputs are of this function, as we will not call it directly, but rather access TFX, which will access it when an API call is made.</p>

  <p class="body"><a class="calibre8" id="pgfId-1185397"></a>In this process, the function first gets a raw feature specifications map, which is a dictionary of column names mapped to a <span class="fm-code-in-text">Feature</span> type. The <span class="fm-code-in-text">Feature</span> type describes the type of data that goes in a feature. For instance, for our data, the feature spec will look like this:</p>
  <pre class="programlisting">{
  'DC': VarLenFeature(dtype=tf.float32), 
  'DMC': VarLenFeature(dtype=tf.float32),
  'RH': VarLenFeature(dtype=tf.int64), 
  ...
  'X': VarLenFeature(dtype=tf.int64), 
  'area': VarLenFeature(dtype=tf.float32), 
  'day': VarLenFeature(dtype=tf.string), 
  'month': VarLenFeature(dtype=tf.string)
}</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185409"></a>It can be observed that different data types are used (e.g., <span class="fm-code-in-text">float</span>, <span class="fm-code-in-text">int</span>, <span class="fm-code-in-text">string</span>) depending on the data found in that column. You can see a list of feature types at <span class="fm-hyperlink"><a class="url" href="https://www.tensorflow.org/api_docs/python/tf/io/">https://www.tensorflow.org/api_docs/python/tf/io/</a></span>. Next, we remove the feature having the <span class="fm-code-in-text">_LABEL_KEY</span> as it should not be a part of the input. We then use the <span class="fm-code-in-text">tf.io.parse_example()</span> function<a class="calibre8" id="marker-1185410"></a> to parse the serialized examples by passing the feature specification map. The results are passed to a <span class="fm-code-in-text">TransformFeaturesLayer</span> (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/nNRa">http://mng.bz/nNRa</a></span>) that knows how to convert a set of parsed examples to a batch of inputs, where each input has multiple features. Finally, the transformed features are passed to the model, which returns the final output (i.e., predicted forest burnt area). Let’s revisit the signature definition from listing 15.9:</p>
  <pre class="programlisting">signatures = {
      'serving_default':
          _get_serve_tf_examples_fn(
              model, tf_transform_output
          ).get_concrete_function(
              tf.TensorSpec(
                  shape=[None],
                  dtype=tf.string,
                  name='examples'
              )
          ),    
  }</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185423"></a>You can see that we are not simply passing the returning TensorFlow function of <span class="fm-code-in-text">_get_serve_tf_examples_fn()</span>. Instead, we call the <span class="fm-code-in-text">get_concrete_function()</span> on the return function (i.e., TensorFlow function). If you remember from our previous discussions, when you execute a function decorated with <span class="fm-code-in-text">@tf.function</span>, it does two things:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185425"></a>Traces the function and creates the data-flow graph to perform the work of the function</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185426"></a>Executes the graph to return outputs</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185427"></a><span class="fm-code-in-text">get_concrete_function()</span> does the first task only. In other words, it returns the traced function. You can read more about this at<a class="calibre8" id="marker-1185428"></a><a class="calibre8" id="marker-1185429"></a><a class="calibre8" id="marker-1185430"></a><a class="calibre8" id="marker-1185431"></a><a class="calibre8" id="marker-1185432"></a> <span class="fm-hyperlink"><a class="url" href="http://mng.bz/v6K7">http://mng.bz/v6K7</a></span>.</p>

  <h3 class="fm-head1" id="sigil_toc_id_199"><a id="pgfId-1185433"></a>15.2.4 Training the Keras model with TFX Trainer</h3>

  <p class="body"><a class="calibre8" id="pgfId-1185439"></a>We <a class="calibre8" id="marker-1185434"></a><a class="calibre8" id="marker-1185435"></a><a class="calibre8" id="marker-1185436"></a><a class="calibre8" id="marker-1185438"></a>now have all the bells and whistles to train the model. To reiterate, we first defined a Keras model, defined a function to run the model training, and finally defined signatures that instruct the model how to behave when an HTTP request is sent via the API. Now we will train the model as a part of the TFX pipeline. To train the model, we are going to use the TFX <span class="fm-code-in-text">Trainer</span> component<a class="calibre8" id="marker-1185440"></a>:</p>
  <pre class="programlisting">from tfx.components import Trainer
from tfx.proto import trainer_pb2
import tensorflow.keras.backend as K
 
K.clear_session()
 
n_dataset_size = df.shape[0]
batch_size = 40
 
n_train_steps_mod = 2*n_dataset_size % (3*batch_size)
n_train_steps = int(2*n_dataset_size/(3*batch_size))
if n_train_steps_mod != 0:
    n_train_steps += 1
 
n_eval_steps_mod = n_dataset_size % (3*batch_size)
n_eval_steps = int(n_dataset_size/(3*batch_size))
if n_eval_steps != 0:
    n_eval_steps += 1
 
trainer = Trainer(
    module_file=os.path.abspath("forest_fires_trainer.py"),
    transformed_examples=transform.outputs['transformed_examples'],
    schema=schema_gen.outputs['schema'],
    transform_graph=transform.outputs['transform_graph'],
    train_args=trainer_pb2.TrainArgs(num_steps=n_train_steps),
    eval_args=trainer_pb2.EvalArgs(num_steps=n_eval_steps))
 
context.run(trainer)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185469"></a>The code leading up to the <span class="fm-code-in-text">Trainer</span> component simply computes the correct number of iterations required in an epoch. To calculate that, we first get the total size of the data (remember that we stored our data set in the DataFrame df). We then used two hash buckets for training and one for evaluation. Therefore, we would have roughly two-thirds training data and one-third evaluation data. Finally, if the value is not fully divisible, we add +1 to incorporate the remainder of the data.</p>

  <p class="body"><a class="calibre8" id="pgfId-1185470"></a>Let’s investigate the instantiation of the <span class="fm-code-in-text">Trainer</span> component in more detail. There are several important arguments to pass to the constructor:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185471"></a><span class="fm-code-in-text">module_file</span>—Path to the Python module containing the <span class="fm-code-in-text">run_fn()</span>.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185472"></a><span class="fm-code-in-text">transformed_examples</span>—Output of the TFX <span class="fm-code-in-text">Transform</span> step, particularly the transformed examples.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185473"></a><span class="fm-code-in-text">schema</span>—Output of the TFX <span class="fm-code-in-text">SchemaGen</span> step.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185475"></a><span class="fm-code-in-text">train_args</span>—A <span class="fm-code-in-text">TrainArgs</span> object<a class="calibre8" id="marker-1185474"></a> specifying training-related arguments. (To see the proto message defined for this object, see <span class="fm-hyperlink"><a class="url" href="http://mng.bz/44aw">http://mng.bz/44aw</a></span>.)</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185477"></a><span class="fm-code-in-text">eval_args</span>—An <span class="fm-code-in-text">EvalArgs</span> object specifying evaluation-related arguments. (To see the proto message defined for this object, see <span class="fm-hyperlink"><a class="url" href="http://mng.bz/44aw">http://mng.bz/44aw</a></span>.)</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185478"></a>This will output the following log. Due to the length of the log output, we have truncated certain parts of the log messages:</p>
  <pre class="programlisting">INFO:absl:Generating ephemeral wheel package for 
<span class="fm-code-continuation-arrow">➥</span> '/home/thushv89/code/manning_tf2_in_action/Ch15-TFX-for-MLOps-in-
<span class="fm-code-continuation-arrow">➥</span> TF2/tfx/forest_fires_trainer.py' (including modules: 
<span class="fm-code-continuation-arrow">➥</span> ['forest_fires_constants', 'forest_fires_transform', 
<span class="fm-code-continuation-arrow">➥</span> 'forest_fires_trainer']).
 
...
 
INFO:absl:Training model.
 
...
 
43840.0703WARNING:tensorflow:11 out of the last 11 calls to &lt;function 
<span class="fm-code-continuation-arrow">➥</span> recreate_function.&lt;locals&gt;.restored_function_body at 0x7f53c000ea60&gt; 
<span class="fm-code-continuation-arrow">➥</span> triggered tf.function retracing. Tracing is expensive and the excessive 
<span class="fm-code-continuation-arrow">➥</span> number of tracings could be due to (1) creating @tf.function repeatedly 
<span class="fm-code-continuation-arrow">➥</span> in a loop, (2) passing tensors with different shapes, (3) passing 
<span class="fm-code-continuation-arrow">➥</span> Python objects instead of tensors. 
 
INFO:absl:____________________________________________________________________________
INFO:absl:Layer (type)                    Output Shape         Param #    
<span class="fm-code-continuation-arrow">➥</span> Connected to                     
INFO:absl:=================================================================
<span class="fm-code-continuation-arrow">➥</span> ===========
 
...
 
INFO:absl:dense_features (DenseFeatures)  (None, 31)           0           
<span class="fm-code-continuation-arrow">➥</span> DC_xf[0][0]                      
INFO:absl:                                                                
<span class="fm-code-continuation-arrow">➥</span> DMC_xf[0][0]                     
INFO:absl:                                                               
<span class="fm-code-continuation-arrow">➥</span> FFMC_xf[0][0]                    
...
INFO:absl:                                                               
<span class="fm-code-continuation-arrow">➥</span> temp_xf[0][0]                    
INFO:absl:                                                               
<span class="fm-code-continuation-arrow">➥</span> wind_xf[0][0]                    
INFO:absl:_________________________________________________________________
<span class="fm-code-continuation-arrow">➥</span> ___________
 
...
 
INFO:absl:Total params: 12,417
 
...
 
Epoch 1/10
9/9 [==============================] - ETA: 3s - loss: 43840.070 - 1s 
<span class="fm-code-continuation-arrow">➥</span> 32ms/step - loss: 13635.6658 - val_loss: 574.2498
Epoch 2/10
9/9 [==============================] - ETA: 0s - loss: 240.241 - 0s 
<span class="fm-code-continuation-arrow">➥</span> 10ms/step - loss: 3909.4543 - val_loss: 495.7877
...
Epoch 9/10
9/9 [==============================] - ETA: 0s - loss: 42774.250 - 0s 
<span class="fm-code-continuation-arrow">➥</span> 8ms/step - loss: 15405.1482 - val_loss: 481.4183
Epoch 10/10
9/9 [==============================] - 1s 104ms/step - loss: 1104.7073 - 
<span class="fm-code-continuation-arrow">➥</span> val_loss: 456.1211
...
 
INFO:tensorflow:Assets written to: 
<span class="fm-code-continuation-arrow">➥</span> /home/thushv89/code/manning_tf2_in_action/Ch15-TFX-for-MLOps-in-
<span class="fm-code-continuation-arrow">➥</span> TF2/tfx/pipeline/examples/forest_fires_pipeline/Trainer/model/5/Format-
<span class="fm-code-continuation-arrow">➥</span> Serving/assets
INFO:absl:Training complete. Model written to 
<span class="fm-code-continuation-arrow">➥</span> /home/thushv89/code/manning_tf2_in_action/Ch15-TFX-for-MLOps-in-
<span class="fm-code-continuation-arrow">➥</span> TF2/tfx/pipeline/examples/forest_fires_pipeline/Trainer/model/5/Format-
<span class="fm-code-continuation-arrow">➥</span> Serving. ModelRun written to 
<span class="fm-code-continuation-arrow">➥</span> /home/thushv89/code/manning_tf2_in_action/Ch15-TFX-for-MLOps-in-
<span class="fm-code-continuation-arrow">➥</span> TF2/tfx/pipeline/examples/forest_fires_pipeline/Trainer/model_run/5
INFO:absl:Running publisher for Trainer
INFO:absl:MetadataStore with DB connection initialized</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185524"></a>In the log message, we can see that the Trainer does a lot of heavy lifting. First, it creates a wheel package using the model training code defined in the forest_fires_trainer.py. wheel (extension <span class="fm-code-in-text">.whl</span>) is how Python would package a library. For instance, when you do <span class="fm-code-in-text">pip install tensorflow</span>, it will first download the wheel package with the latest version and install it locally. If you have a locally downloaded wheel package, you can use <span class="fm-code-in-text">pip install &lt;path to wheel&gt;</span>. You can find the resulting wheel package at the &lt;path to pipeline root&gt;/examples/forest_fires_pipeline/_wheels directory. Then it prints the model summary. It has an <span class="fm-code-in-text">Input</span> layer for every feature passed to the model. You can see that the <span class="fm-code-in-text">DenseFeatures</span> layer aggregates all these <span class="fm-code-in-text">Input</span> layers to produce a [<span class="fm-code-in-text">None</span>, 31]-sized tensor. As the final output, the model produces a [<span class="fm-code-in-text">None</span>, 1]-sized tensor. Then the model training takes place. You will see warnings such as</p>
  <pre class="programlisting">out of the last x calls to &lt;function 
<span class="fm-code-continuation-arrow">➥</span> recreate_function.&lt;locals&gt;.restored_function_body at 0x7f53c000ea60&gt; 
<span class="fm-code-continuation-arrow">➥</span> triggered tf.function retracing. Tracing is expensive and the excessive 
<span class="fm-code-continuation-arrow">➥</span> number of tracings could be due to</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185527"></a>This warning comes up when TensorFlow function tracing happens too many times. It can be a sign of poorly written code (e.g., the model getting recreated many times within a loop) and is sometimes unavoidable. In our case, it’s the latter. The behavior of the Trainer module is causing this behavior, and there’s not much we can do about that. Finally, the component writes the model as well as some utilities to a folder in the pipeline root. Here’s what our pipeline root directory looks like so far (figure 15.8).</p>

  <p class="fm-figure"><img alt="15-08" class="calibre10" src="../../OEBPS/Images/15-08.png" width="919" height="956"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1214349"></a>Figure 15.8 The complete directory/file structure after running the Trainer</p>

  <p class="body"><a class="calibre8" id="pgfId-1185534"></a>A major issue we can note in the Trainer’s output log is the training and validation losses. For this problem, they are quite large. We are using the mean-squared error that is computed as</p>

  <p class="fm-equation"><img alt="15_08a" class="calibre10" src="../../OEBPS/Images/15_08a.png" width="164" height="84"/><br class="calibre2"/>
  <a id="pgfId-1192963"></a></p>

  <p class="body"><a class="calibre8" id="pgfId-1185545"></a>where N is the number of examples, <i class="fm-timesitalic">y</i><sub class="fm-subscript">i</sub> is the <i class="fm-timesitalic">i</i><sup class="fm-superscript">th</sup> example, and <i class="fm-timesitalic">ŷ</i><sub class="fm-subscript">1</sub> is the predicted value for <i class="fm-timesitalic">i</i><sup class="fm-superscript">th</sup> example. At the end of the training, we have a squared loss of around 481, meaning an error of around 22 hectares (i.e., 0.22 km<sup class="fm-superscript">2</sup>) per example. This is not a small error. If you investigate this matter, you will realize this is largely caused by anomalies present in the data. Some anomalies are so large that they can skew the model heavily in the wrong direction. We will address this in an upcoming section in the chapter. You will be able to see the values in the <span class="fm-code-in-text">FnArgs</span> object passed to the <span class="fm-code-in-text">run_fn()</span>:</p>
  <pre class="programlisting">INFO:absl:==================================================
INFO:absl:Printing the tfx.components.FnArgs object
INFO:absl:FnArgs(
    working_dir=None, 
    train_files=['.../Transform/transformed_examples/16/Split-train/*'], 
    eval_files=['.../Transform/transformed_examples/16/Split-eval/*'], 
    train_steps=100, 
    eval_steps=100, 
    schema_path='.../SchemaGen/schema/15/schema.pbtxt', 
    schema_file='.../SchemaGen/schema/15/schema.pbtxt', 
    transform_graph_path='.../Transform/transform_graph/16', 
    transform_output='.../Transform/transform_graph/16', 
    data_accessor=DataAccessor(
        tf_dataset_factory=&lt;function 
<span class="fm-code-continuation-arrow">➥</span> get_tf_dataset_factory_from_artifact.&lt;locals&gt;.dataset_factory at 
<span class="fm-code-continuation-arrow">➥</span> 0x7f7a56329a60&gt;, 
        record_batch_factory=&lt;function 
<span class="fm-code-continuation-arrow">➥</span> get_record_batch_factory_from_artifact.&lt;locals&gt;.record_batch_factory at 
<span class="fm-code-continuation-arrow">➥</span> 0x7f7a563297b8&gt;, 
        data_view_decode_fn=None
    ), 
    serving_model_dir='.../Trainer/model/17/Format-Serving', 
    eval_model_dir='.../Trainer/model/17/Format-TFMA', 
    model_run_dir='.../Trainer/model_run/17', 
    base_model=None, 
    hyperparameters=None, 
    custom_config=None
)
INFO:absl:==================================================</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185572"></a>The following sidebar discusses how we can evaluate the model at this point in our discussion.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1185574"></a><a class="calibre8" id="aHlk94967956"></a>Evaluating the saved model</p>

    <p class="fm-sidebar-text"><a id="pgfId-1185575"></a>In the pipeline, our model will be served via an HTTP interface in the form of URLs. But rather than waiting to do that, let’s load the model manually and use it to predict data. Doing so will provide us with two advantages:</p>

    <ul class="calibre9">
      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1185576"></a>Verifying the model is working as intended</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1185577"></a>Providing a deeper understanding of the format of the inputs and outputs of the model</p>
      </li>
    </ul>

    <p class="fm-sidebar-text"><a id="pgfId-1185578"></a>We will not go into details about this in the book to keep our discussion focused on the pipeline. However, the code has been provided in the tfx/15.1_MLOps_with_ tensorflow.ipynb notebook so you can experiment with it.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1185580"></a>Next, we will discuss how we can detect anomalies present in the data and remove them to create a clean data set to train our model.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1185581"></a>Detecting and removing anomalies</p>

    <p class="fm-sidebar-text"><a id="pgfId-1185582"></a>Our model is currently showing a validation loss of around 568. The loss used here is the mean-squared error. We have already seen that this means every prediction is 24 hectares (i.e., 0.24 km<sup class="fm-superscript1">2</sup>) off. This is no negligible matter. There are lots of outliers in our data, which could be a key reason we’re seeing such large error margins. The following figure shows the statistics graph we created earlier.</p>

    <p class="fm-figure"><img alt="15-08-unnumb" class="calibre10" src="../../OEBPS/Images/15-08-unnumb.png" width="992" height="836"/><br class="calibre2"/></p>

    <p class="fm-figure-caption"><a id="pgfId-1185588"></a>The summary statistics graphs generated for the data by the <span class="fm-code-in-figurecaption">StatisticsGen</span> component</p>

    <p class="fm-sidebar-text"><a id="pgfId-1199455"></a> </p>

    <p class="fm-sidebar-text"><a id="pgfId-1185589"></a>You can see that some columns are heavily skewed. For example, the feature FFMC has the highest density, around 80-90, but has a range of 18.7-96.2.</p>

    <p class="fm-sidebar-text"><br class="calibre2"/></p>

    <p class="fm-sidebar-text"><a id="pgfId-1185591"></a>To tackle this issue, we will use the <span class="fm-code-in-text1">tensorflow_data_validation</span><a id="marker-1199414"></a> (abbreviated as <span class="fm-code-in-text1">tfdv</span>) library. It provides valuable functions like <span class="fm-code-in-text1">tfdv.validate_statistics</span><a id="marker-1199416"></a><span class="fm-code-in-text1">()</span>, which can be used to validate data against the data schema we generated earlier, as well as the <span class="fm-code-in-text1">tfdv.display_anomalies()</span> function<a id="marker-1199417"></a> to list the anomalous samples. Furthermore, we can edit the schema in order to modify the criteria for outliers. For example, to change the maximum value allowed for the ISI feature, you can do the following:</p>
    <pre class="programlisting">isi_feature = tfdv.get_feature(schema, 'ISI')
isi_feature.float_domain.max = 30.0</pre>

    <p class="fm-sidebar-text"><a id="pgfId-1185596"></a>Finally, you can visualize original data versus cleaned data using the <span class="fm-code-in-text1">tfdv.visualize_statistics()</span> function<a id="marker-1201047"></a>. Finally, you can use the <span class="fm-code-in-text1">ExampleValidator</span> object<a id="marker-1201048"></a> (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/XZxv">http://mng.bz/XZxv</a></span>) from the TFX pipeline to make sure there are no anomalies in your data set.</p>

    <p class="fm-sidebar-text"><br class="calibre2"/></p>

    <p class="fm-sidebar-text"><a id="pgfId-1185599"></a>Once you run this, you should get a smaller loss than previously. For example, in this experiment, a loss of ~150 on average was observed. This is a 75% reduction of the previous error. You can find the code for this in the tfx/15.1_MLOps_ with_tensorflow.ipynb notebook.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1185600"></a>Next, we’ll look at a technology called Docker that is used for deploying models in isolated and portable environments. We will see how we can deploy our model in what is known as a Docker container.</p>

  <p class="fm-head2"><a id="pgfId-1185601"></a>Exercise 2</p>

  <p class="body"><a class="calibre8" id="pgfId-1185602"></a>Instead of using one-hot encoding for day and month features and appending them to the <span class="fm-code-in-text">categorical_columns</span> variable<a class="calibre8" id="marker-1185603"></a>, let’s imagine you want to use embeddings to represent these features. You can use the feature column <span class="fm-code-in-text">tf.feature_column.embedding_column</span> for this. Assume an embedding dimensionality of 32. You have the feature names of day and month columns stored in <span class="fm-code-in-text">_VOCAB_FEATURE_KEYS</span> (contains <span class="fm-code-in-text">['day', 'month']</span>) and their dimensionality <a class="calibre8" id="marker-1185604"></a><a class="calibre8" id="marker-1185605"></a><a class="calibre8" id="marker-1185606"></a><a class="calibre8" id="marker-1185608"></a>in <span class="fm-code-in-text">_</span><a class="calibre8" id="marker-1185609"></a><a class="calibre8" id="marker-1185610"></a><a class="calibre8" id="marker-1185611"></a><a class="calibre8" id="marker-1185612"></a><span class="fm-code-in-text">MAX_CATEGORICAL_FEATURE_VALUES</span> (contains <span class="fm-code-in-text">[7, 12]</span>).</p>

  <h2 class="fm-head" id="sigil_toc_id_200"><a id="pgfId-1185613"></a>15.3 Setting up Docker to serve a trained model</h2>

  <p class="body"><a class="calibre8" id="pgfId-1185616"></a>You <a class="calibre8" id="marker-1201058"></a><a class="calibre8" id="marker-1201059"></a>have developed a data pipeline and a robust model that can be used to predict the severity of forest fires based on the weather data. Now you want to go a step further and offer this as a more accessible service by deploying the model on a machine and enabling access through a REST API. This process is also known as productionizing a machine learning model. To do that, you are first going to create an isolated environment dedicated to model serving. The technology you will use is Docker.</p>

  <p class="fm-callout"><a id="pgfId-1185617"></a><span class="fm-callout-head">CAUTION</span> It is vitally important that you have Docker installed on your machine before proceeding further. To install Docker, follow the guide: <span class="fm-hyperlink"><a class="url" href="https://docs.docker.com/engine/install/ubuntu/">https://docs.docker.com/engine/install/ubuntu/</a></span>.</p>

  <p class="body"><a class="calibre8" id="pgfId-1185618"></a>In TFX, you can deploy your model as a container, where the container is provisioned by Docker. According to the official Docker website, a Docker container is</p>

  <p class="fm-quote1"><a id="pgfId-1185619"></a>a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another.</p>

  <p class="fm-quote-source"><a class="calibre8" id="pgfId-1185620"></a>Source: <span class="fm-hyperlink"><a class="url" href="https://www.docker.com/resources/what-container">https://www.docker.com/resources/what-container</a></span></p>

  <p class="body"><a class="calibre8" id="pgfId-1185621"></a>Docker is a containerization technology that helps you run a software (or a microservice) isolated from the host. In Docker, you can create an image, which will instruct Docker with various specifications (e.g., OS, libraries, dependencies) that you need in the container for it to run the software correctly. Then a container is simply a run time instance of that image. This means you enjoy a higher portability as you can create a container on one computer and run it on another computer easily (as long as Docker is installed on two computers). Virtual machines (VMs) also try to achieve a similar goal. There are many resources out there comparing and contrasting Docker containers and VMs (e.g., <span class="fm-hyperlink"><a class="url" href="http://mng.bz/yvNB">http://mng.bz/yvNB</a></span>).</p>

  <p class="body"><a class="calibre8" id="pgfId-1185622"></a>As we have said, to run a Docker container, you first need a Docker image. Docker has a public image registry (known as Docker Hub) available at <span class="fm-hyperlink"><a class="url" href="https://hub.docker.com/">https://hub.docker.com/</a></span>. The Docker image we are looking for is the TensorFlow serving image. This image has everything installed to serve a TensorFlow model, using the TensorFlow serving (<span class="fm-hyperlink"><a class="url" href="https://github.com/tensorflow/serving">https://github.com/tensorflow/serving</a></span>), a sub-library in TensorFlow that can create a REST API around a given model so that you can send HTTP requests to use the model. You can download this image simply by running the following command:</p>
  <pre class="programlisting">docker pull tensorflow/serving:2.6.3-gpu</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185625"></a>Let’s break down the anatomy of this command. <span class="fm-code-in-text">docker pull</span> is the command for downloading an image. <span class="fm-code-in-text">tensorflow/serving</span> is the image name. Docker images are version controlled, meaning every Docker image has a version tag (it defaults to the latest if you don’t provide one). <span class="fm-code-in-text">2.6.3-gpu</span> is the image’s version. This image is quite large because it supports GPU execution. If you don’t have a GPU, you can use <span class="fm-code-in-text">docker pull tensorflow/serving:2.6.3</span>, which is more lightweight. Once the command successfully executes, you can run</p>
  <pre class="programlisting">docker images </pre>

  <p class="body"><a class="calibre8" id="pgfId-1185628"></a>to list all the images you have downloaded. With the image downloaded, you can use the <span class="fm-code-in-text">docker run &lt;options&gt; &lt;Image&gt;</span> command to stand up a container using a given image. The command <span class="fm-code-in-text">docker run</span> is a very flexible command and comes with lots of parameters that you can set and change. We are using several of those:</p>
  <pre class="programlisting">docker run \
  --rm \
  -it \
  --gpus all \
  -p 8501:8501 \
  --user $(id -u):$(id -g) \
  -v ${PWD}/tfx/forest-fires-pushed:/models/forest_fires_model \
  -e MODEL_NAME=forest_fires_model \
  tensorflow/serving:2.6.3-gpu</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185640"></a>It’s important to understand the arguments provided here. Typically, when defining arguments in a shell environment, a single-dash prefix is used for single character-based arguments (e.g., -p) and a double-dash prefix is used for more verbose arguments (e.g., <span class="fm-code-in-text">--gpus</span>):</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185642"></a><span class="fm-code-in-text">--rm</span>—Containers are temporary runtimes that can be removed after the service has run. <span class="fm-code-in-text">--rm</span> implies that the container will be removed after exiting it.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185644"></a><span class="fm-code-in-text">-it</span> (short for <span class="fm-code-in-text">-i</span> and <span class="fm-code-in-text">-t</span>)—This means that you can go into the container and interactively run commands in a shell within the container.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185646"></a><span class="fm-code-in-text">--gpus all</span>—This tells the container to ensure that GPU devices (if they exist) are visible inside the container.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185648"></a><span class="fm-code-in-text">-p</span>—This maps a network port in the container to the host. This is important if you want to expose some service (e.g., the API that will be up to serve the model) to the outside. For instance, TensorFlow serving runs on 8501 by default. Therefore, we are mapping the container’s 8501 port to the host’s 8501 port.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185650"></a><span class="fm-code-in-text">--user $(id -u):$(id -g)</span>—This means the commands will be run as the same user you’re logged in as on the host. Each user is identified by a user ID and is assigned to one or more groups (identified by the group ID). You can pass the user and the group following the syntax <span class="fm-code-in-text">--user &lt;user ID&gt;:&lt;group ID&gt;</span>. For example, your current user ID is given by the command <span class="fm-code-in-text">id -u</span>, and the group is given by <span class="fm-code-in-text">id -g</span>. By default, containers run commands as <span class="fm-code-in-text">root</span> user (i.e., running via <span class="fm-code-in-text">sudo</span>), which can make your services more vulnerable to outside attacks. So, we use a less-privileged user to execute commands in the container.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185652"></a><span class="fm-code-in-text">-v</span>—This mounts a directory on the host to a location inside the container. By default, things you store within a container are not visible to the outside. This is because the container has its own storage space/volume. If you need to make the container see something on the host or vice versa, you need to mount a directory on the host to a path inside the container. This is known as <i class="fm-italics">bind mounting</i>. For instance, here we expose our pushed model (which will be at <span class="fm-code-in-text">./tfx/forest-fires-pushed</span>) to the path <span class="fm-code-in-text">/models/forest_fires_model</span> inside the container.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185654"></a><span class="fm-code-in-text">-e</span>—This option can be used to pass special environment variables to the container. For example, the TensorFlow serving service expects a model name (which will be a part of the URL you need to hit in order to get results from the model).</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185655"></a>This command is provided to you in the <span class="fm-code-in-text">tfx/run_server.sh</span> script in the Ch15-TFX-for-MLOps-in-TF2 directory. Let’s run the <span class="fm-code-in-text">run_server.sh</span> script to see what we will get. To run the script</p>

  <ol class="calibre11">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185656"></a>Open a terminal.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185657"></a>Move cd into the Ch15-TFX-for-MLOps-in-TF2/tfx directory.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185658"></a>Run <span class="fm-code-in-text">./run_server.sh</span>.</p>
    </li>
  </ol>

  <p class="body"><a class="calibre8" id="pgfId-1185659"></a>It will show an output similar to the following:</p>
  <pre class="programlisting">2.6.3-gpu: Pulling from tensorflow/serving
Digest: 
<span class="fm-code-continuation-arrow">➥</span> sha256:e55c44c088f6b3896a8f66d8736f38b56a8c5687c105af65a58f2bfb0bf90812
Status: Image is up to date for tensorflow/serving:2.6.3-gpu
docker.io/tensorflow/serving:2.6.3-gpu
2021-07-16 05:59:37.786770: I
tensorflow_serving/model_servers/server.cc:88] Building single TensorFlow 
<span class="fm-code-continuation-arrow">➥</span> model file config: model_name: forest_fires_model model_base_path: 
<span class="fm-code-continuation-arrow">➥</span> /models/forest_fires_model
2021-07-16 05:59:37.786895: I
tensorflow_serving/model_servers/server_core.cc:464] Adding/updating 
<span class="fm-code-continuation-arrow">➥</span> models.
2021-07-16 05:59:37.786915: I
tensorflow_serving/model_servers/server_core.cc:587]  (Re-)adding model: 
<span class="fm-code-continuation-arrow">➥</span> forest_fires_model
2021-07-16 05:59:37.787498: W
tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:
<span class="fm-code-continuation-arrow">➥</span> 267] No versions of servable forest_fires_model found under base path 
<span class="fm-code-continuation-arrow">➥</span> /models/forest_fires_model. Did you forget to name your leaf directory 
<span class="fm-code-continuation-arrow">➥</span> as a number (eg. '/1/')?
...</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185673"></a>Of course, it will not work fully, as the directory we provided as model’s location is not populated. We still need to do a few things to have the final model in the right location.</p>

  <p class="body"><a class="calibre8" id="pgfId-1185674"></a>In the next section, we will complete the rest of our pipeline. We will see how we can automatically evaluate as new models are trained in the pipeline, deploy the model if the performance is good, and enable prediction from the model using a REST API (i.e., a web-based API).</p>

  <p class="fm-head2"><a id="pgfId-1185675"></a>Exercise 3</p>

  <p class="body"><a class="calibre8" id="pgfId-1185676"></a>Say you want to download the TensorFlow Docker image (it has the name <span class="fm-code-in-text">tensorflow/ tensorflow</span>) with version 2.5.0 and stand up a container that mounts the /tmp/inputs directory on your computer to /data volume within the container. Additionally, you would like to map the 5000 port in the container to 5000 on your computer. How would you do this using Docker commands? You can assume you’re running the commands as the root within the <a class="calibre8" id="marker-1202926"></a><a class="calibre8" id="marker-1202927"></a>container.</p>

  <h2 class="fm-head" id="sigil_toc_id_201"><a id="pgfId-1185679"></a>15.4 Deploying the model and serving it through an API</h2>

  <p class="body"><a class="calibre8" id="pgfId-1185682"></a>You <a class="calibre8" id="marker-1185680"></a><a class="calibre8" id="marker-1185681"></a>now have a data pipeline, a trained model, and a shell script that can run a Docker container with everything needed to run the model and the API to access the model. Now, using some services provided in TFX, you will deploy the model within a Docker container and make it available to be used through an API. In this process, you will run steps to validate the infrastructure (e.g., the container can be run and is healthy) and the model (i.e., when a new version of the model comes out, check if it is better than the last one), and finally, if everything is good, deploy the model on the infrastructure.</p>

  <p class="body"><a class="calibre8" id="pgfId-1185683"></a>It has been a long journey. Let’s look back and see what we’ve accomplished so far. We have used the following TFX components:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185684"></a><span class="fm-code-in-text">CsvExampleGen</span>—Load data as <span class="fm-code-in-text">TFRecord</span> objects from CSV files.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185685"></a><span class="fm-code-in-text">StatisticsGen</span>—Basic statistics and visualizations about the distribution of various columns in the CSV data.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185686"></a><span class="fm-code-in-text">SchemaGen</span>—Generate the schema/template of the data (e.g., data types, domains, minimum/maximum values allowed, etc.).</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185687"></a><span class="fm-code-in-text">Transform</span>—Transform the raw columns to features using the operations available in the <span class="fm-code-in-text">tensorflow_transform</span> library (e.g., one-hot encoding, bucketizing).</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185688"></a><span class="fm-code-in-text">Trainer</span>—Define a Keras model, train it using the transformed data, and save to the disk. This model has a signature called serving default, which instructs the model what to do for an incoming request.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185689"></a><span class="fm-code-in-text">ExampleValidator</span>—This is used to validate that training and evaluation examples used adhere to the defined schema and can be used to detect anomalies.</p>
    </li>
  </ul>

  <h3 class="fm-head1" id="sigil_toc_id_202"><a id="pgfId-1185690"></a>15.4.1 Validating the infrastructure</h3>

  <p class="body"><a class="calibre8" id="pgfId-1185694"></a>Using <a class="calibre8" id="marker-1185691"></a><a class="calibre8" id="marker-1185692"></a><a class="calibre8" id="marker-1185693"></a>TFX, you can ensure almost everything works well when you have a fully automated pipeline. We will discuss one such step here: the infrastructure validation step. In this, <span class="fm-code-in-text">tfx.components.InfraValidator</span> will automatically</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185695"></a>Create a container using a specific version of the TensorFlow serving image provided</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185696"></a>Load and run the model in it</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185697"></a>Send several requests to make sure the model responds</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185698"></a>Stand down the container</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185699"></a>Let’s look at how we can use this component to validate the local Docker configuration we set up in the previous section (see the next listing).</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1185701"></a>Listing 15.11 Defining the <span class="fm-code-in-listingcaption">InfraValidator</span></p>
  <pre class="programlisting">from tfx.components import InfraValidator
from tfx.proto import infra_validator_pb2
 
infra_validator = InfraValidator(
    model=trainer.outputs['model'],                                        <span class="fm-combinumeral">❶</span>
    
    examples=example_gen.outputs['examples'],                              <span class="fm-combinumeral">❷</span>
    serving_spec=infra_validator_pb2.ServingSpec(                          <span class="fm-combinumeral">❸</span>
        tensorflow_serving=infra_validator_pb2.TensorFlowServing(          <span class="fm-combinumeral">❹</span>
            tags=['2.6.3-gpu']
        ),
        local_docker=infra_validator_pb2.LocalDockerConfig(),              <span class="fm-combinumeral">❺</span>
    ),
    request_spec=infra_validator_pb2.RequestSpec(                          <span class="fm-combinumeral">❻</span>
        tensorflow_serving=infra_validator_pb2.TensorFlowServingRequestSpec(<span class="fm-combinumeral">❼</span>
            signature_names=['serving_default']
        ),
        num_examples=5                                                     <span class="fm-combinumeral">❽</span>
    )
)
 
context.run(infra_validator)</pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206308"></a><span class="fm-combinumeral">❶</span> InfraValidator needs the location of the model it’s going to validate.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206329"></a><span class="fm-combinumeral">❷</span> Source for the data that will be used to build API calls to the model</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206346"></a><span class="fm-combinumeral">❸</span> Holds a collection of model serving-related specifications</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206363"></a><span class="fm-combinumeral">❹</span> Defines the version/tag of the TensorFlow serving Docker Image to be used</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206380"></a><span class="fm-combinumeral">❺</span> Says to the InfraValidator that we are going to use the local Docker service to test</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206397"></a><span class="fm-combinumeral">❻</span> Holds a collection of specifications related to the specific call made to the model</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1206414"></a><span class="fm-combinumeral">❼</span> Defines which model signature to use</p>

  <p class="fm-code-annotation-mob"><a class="calibre8" id="pgfId-1206431"></a><span class="fm-combinumeral">❽</span> Defines how many requests to make to the model</p>

  <p class="body"><a class="calibre8" id="pgfId-1185733"></a>The <span class="fm-code-in-text">InfraValidator</span>, just like any other TFX component, expects several arguments to run accurately:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185734"></a><span class="fm-code-in-text">model</span>—The Keras model returned by the <span class="fm-code-in-text">Trainer</span> component.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185735"></a><span class="fm-code-in-text">examples</span>—Loaded raw examples given by the <span class="fm-code-in-text">CSVExampleGen</span>.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185736"></a><span class="fm-code-in-text">serving_spec</span>—Expects a <span class="fm-code-in-text">ServingSpec</span> protobuf message. It will specify the version of the TensorFlow serving Docker image and whether to use local Docker installation (which is done here).</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185737"></a><span class="fm-code-in-text">request_spec</span>—A <span class="fm-code-in-text">RequestSpec</span> protobuf message that will specify the signature that needs to be reached to verify the model is working.</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185738"></a>If this step completes error-free, you will see the files shown in figure 15.9 in the pipeline root.</p>

  <p class="fm-figure"><img alt="15-09" class="calibre10" src="../../OEBPS/Images/15-09.png" width="828" height="467"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1214383"></a>Figure 15.9 The directory/file structure after running the <span class="fm-code-in-figurecaption">InfraValidator</span></p>

  <p class="body"><a class="calibre8" id="pgfId-1185744"></a>You can see a file called INFRA_BLESSED appearing in the <span class="fm-code-in-text">InfraValidator</span> sub-directory. This brings us to the concept of <i class="fm-italics">blessing</i>. TFX will bless certain elements in the pipeline when they run successfully. Once blessed, it will create a file with the suffix BLESSED. If the step fails, then a file with the suffix NOT_BLESSED will be created. Blessing helps to discriminate between things that ran fine and things that failed. For examples, once blessed, we can be sure that the infrastructure is working as expected. This means that things like</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185745"></a>Standing up a container</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185746"></a>Loading the model</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185747"></a>Reaching a defined API endpoint</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185751"></a>can be performed without <a class="calibre8" id="marker-1185748"></a><a class="calibre8" id="marker-1185749"></a><a class="calibre8" id="marker-1185750"></a>issues.</p>

  <h3 class="fm-head1" id="sigil_toc_id_203"><a id="pgfId-1185752"></a>15.4.2 Resolving the correct model</h3>

  <p class="body"><a class="calibre8" id="pgfId-1185756"></a>Moving <a class="calibre8" id="marker-1185753"></a><a class="calibre8" id="marker-1185754"></a><a class="calibre8" id="marker-1185755"></a>forward, we will define a resolver. The purpose of the resolver is to resolve a special artifact (like a model) that can evolve over time using a well-defined strategy (e.g., the model with the lowest validation error). Then the resolver informs subsequent components (e.g., the model Evaluator component we will be defining next) which artifact version to use. As you might have guessed, we will use the resolver to resolve the trained Keras model in the pipeline. So, if you run the pipeline multiple times, the resolver will make sure the latest and greatest model is used in the downstream components:</p>
  <pre class="programlisting">from tfx import v1 as tfx
 
model_resolver = tfx.dsl.Resolver(
      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,
      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),
      model_blessing=tfx.dsl.Channel(
          type=tfx.types.standard_artifacts.ModelBlessing
      )
).with_id('latest_blessed_model_resolver')
 
context.run(model_resolver)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185769"></a>When defining the resolver to validate a model, we will define three things:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185770"></a><span class="fm-code-in-text">strategy_class</span> (a class from the <span class="fm-code-in-text">tfx.dsl.components.common.resolver.ResolverStrategy</span> namespace)—Defines the resolution strategy. There are two strategies supported currently: the latest blessed model (i.e., the model that has passed a set of defined evaluation checks) and the latest model.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185771"></a><span class="fm-code-in-text">model</span> (<span class="fm-code-in-text">tfx.dsl.Channel</span>)—Wraps a TFX artifact-type model in a <span class="fm-code-in-text">tfx.dsl.Channel</span> object<a class="calibre8" id="marker-1193082"></a>. A <span class="fm-code-in-text">tfx.dsl.Channel</span> is an TFX-specific abstract concept that connects data consumers and data producers. For example, a channel is required to choose the correct model from a pool of models available in the pipeline.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185773"></a><span class="fm-code-in-text">model_blessing</span> (<span class="fm-code-in-text">tfx.dsl.Channel</span>)—Wraps a TFX artifact of type <span class="fm-code-in-text">ModelBlessing</span> in a <span class="fm-code-in-text">tfx.dsl.Channel</span> object.</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185777"></a>You can look at various artifacts that you can wrap in a <span class="fm-code-in-text">tfx.dsl.Channel</span> object at<a class="calibre8" id="marker-1204292"></a><a class="calibre8" id="marker-1204293"></a><a class="calibre8" id="marker-1204294"></a> <span class="fm-hyperlink"><a class="url" href="http://mng.bz/2nQX">http://mng.bz/2nQX</a></span>.</p>

  <h3 class="fm-head1" id="sigil_toc_id_204"><a id="pgfId-1185778"></a>15.4.3 Evaluating the model</h3>

  <p class="body"><a class="calibre8" id="pgfId-1185782"></a>We <a class="calibre8" id="marker-1204298"></a><a class="calibre8" id="marker-1204299"></a><a class="calibre8" id="marker-1204300"></a>will evaluate the model as the last step before pushing it to a designated production environment. Essentially, we will define several evaluation checks that the model needs to pass. When a model is passed, TFX will bless the model. Otherwise, TFX will leave the model unblessed. We will learn later how to check if the model was blessed. To define the evaluation checks, we are going to use the <span class="fm-code-in-text">tensorflow_model_analysis</span> library<a class="calibre8" id="marker-1204302"></a>. The first step is to define an evaluation configuration that specifies the checks:</p>
  <pre class="programlisting">import tensorflow_model_analysis as tfma
 
eval_config = tfma.EvalConfig(
    model_specs=[
        tfma.ModelSpec(label_key='area')                                  <span class="fm-combinumeral">❶</span>
    ],
    metrics_specs=[
        tfma.MetricsSpec(
            metrics=[                                                     <span class="fm-combinumeral">❷</span>
                tfma.MetricConfig(class_name='ExampleCount'),             <span class="fm-combinumeral">❸</span>
                tfma.MetricConfig(
                    class_name='MeanSquaredError',                        <span class="fm-combinumeral">❹</span>
                    threshold=tfma.MetricThreshold(                       <span class="fm-combinumeral">❺</span>
                       value_threshold=tfma.GenericValueThreshold(
                           upper_bound={'value': 200.0}
                       ),
                       change_threshold=tfma.GenericChangeThreshold(      <span class="fm-combinumeral">❻</span>
                           direction=tfma.MetricDirection.LOWER_IS_BETTER,
                           absolute={'value': 1e-10}
                       )
                   )
               )
           ]
        )
    ],
    slicing_specs=[                                                       <span class="fm-combinumeral">❼</span>
        tfma.SlicingSpec(),                                               <span class="fm-combinumeral">❽</span>
        tfma.SlicingSpec(feature_keys=['month'])                          <span class="fm-combinumeral">❾</span>
    ])</pre>

  <p class="fm-code-annotation-mob"><a id="pgfId-1205640"></a><span class="fm-combinumeral">❶</span> Define a model spec containing the label feature name.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1205676"></a><span class="fm-combinumeral">❷</span> Define a list of metric specifications.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1205693"></a><span class="fm-combinumeral">❸</span> Get the number of examples evaluated on.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1205710"></a><span class="fm-combinumeral">❹</span> Define the mean-squared error as a metric.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1205727"></a><span class="fm-combinumeral">❺</span> Define a threshold upper bound as a check.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1205744"></a><span class="fm-combinumeral">❻</span> Define Change in error (compared to previous models) as a check (i.e., the lower the error the better).</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1205761"></a><span class="fm-combinumeral">❼</span> Slicing specs define how data needs to be partitioned when evaluating.</p>

  <p class="fm-code-annotation-mob"><a id="pgfId-1205778"></a><span class="fm-combinumeral">❽</span> Evaluate on the whole data set without slicing (i.e., an empty slice).</p>

  <p class="fm-code-annotation-mob"><a class="calibre8" id="pgfId-1205641"></a><span class="fm-combinumeral">❾</span> Evaluate on partitioned data, where data is partitioned based on the month field.</p>

  <p class="body"><a class="calibre8" id="pgfId-1185823"></a>The <span class="fm-code-in-text">EvalConfig</span> is quite a mouthful. Let’s go through it slowly. We have to define three things: model specifications (as a <span class="fm-code-in-text">ModelSpec</span> object), metric specifications (as a list of <span class="fm-code-in-text">MetricsSpec</span> objects), and slicing specifications (as a list of <span class="fm-code-in-text">SlicingSpec</span> objects). The <span class="fm-code-in-text">ModelSpec</span> object can be used to define the following:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185824"></a><span class="fm-code-in-text">name</span>—An alias model name that can be used to identify the model in this step.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185825"></a><span class="fm-code-in-text">model_type</span>—A string identifying the type of model. Allowed values include <span class="fm-code-in-text">tf_keras</span>, <span class="fm-code-in-text">tf_estimator</span>, <span class="fm-code-in-text">tf_lite</span>, and <span class="fm-code-in-text">tf_js</span>, <span class="fm-code-in-text">tf_generic</span>. For Keras models like ours, type is automatically derived.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185826"></a><span class="fm-code-in-text">signature_name</span>—The model signature to be used for inference. By default, <span class="fm-code-in-text">serving_default</span> is used.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185827"></a><span class="fm-code-in-text">label_key</span>—The name of the label feature in the examples.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1185828"></a><span class="fm-code-in-text">label_keys</span>—For multi-output models, a list of label keys is used.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185829"></a><span class="fm-code-in-text">example_weight_key</span>—An optional key (or feature name) to retrieve example weights if present.</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185830"></a>For more information about the <span class="fm-code-in-text">ModelSpec</span> object, refer to <span class="fm-hyperlink"><a class="url" href="http://mng.bz/M5wW">http://mng.bz/M5wW</a></span>. In a <span class="fm-code-in-text">MetricsSpec</span> object<a class="calibre8" id="marker-1203247"></a>, the following attributes can be set:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185832"></a><span class="fm-code-in-text">metrics</span>—A list of <span class="fm-code-in-text">MetricConfig</span> objects. Each <span class="fm-code-in-text">MetricConfig</span> object takes a <span class="fm-code-in-text">class_name</span> as an input. You can choose any class defined in <span class="fm-code-in-text">tfma.metrics.Metric</span> (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/aJ97">http://mng.bz/aJ97</a></span>) or <span class="fm-code-in-text">tf.keras.metrics.Metric</span> (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/gwmV">http://mng.bz/gwmV</a></span>) namespaces.</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185833"></a>The <span class="fm-code-in-text">SlicingSpec</span> defines how the data needs to be partitioned during evaluation. For example, for time series problems, you will need to see how the model performs across different months or days. For that, <span class="fm-code-in-text">SlicingSpec</span> is a handy config. <span class="fm-code-in-text">SlicingSpec</span> has the following arguments:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185834"></a><span class="fm-code-in-text">feature_keys</span>—Can be used to define a feature key on which you can partition the data. For example, for feature key month, it will create a partition of data for each month by selecting data having a specific month. If not passed, it will return the whole data set.</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185835"></a>Note that TFX uses the evaluation split you defined at the very beginning of the pipeline (i.e., when implementing the <span class="fm-code-in-text">CsvExampleGen</span> component) if not provided. In other words, all the metrics are evaluated on the evaluation split of the data set. Next, it defines two criteria for the evaluation to pass:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1185836"></a>The mean squared error is smaller than 200.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1185837"></a>The mean squared loss has improved by 1e - 10.</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1185838"></a>A model will be blessed (i.e., marked as passed) if these two conditions are satisfied for a newly trained model. Remember that we have seen a loss of around 150 in our better model, so let’s set the threshold to 200. The metrics added here are in addition to those saved when using the <span class="fm-code-in-text">model.compile()</span> step. For example, since the mean-squared error is used as the loss, it will already be a part of the metrics (even without defining it in <span class="fm-code-in-text">eval_config</span>).</p>

  <p class="body"><a class="calibre8" id="pgfId-1185839"></a>Finally, we define the Evaluator (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/e7BQ">http://mng.bz/e7BQ</a></span>) that will take in a model and run the evaluation checks defined in <span class="fm-code-in-text">eval_config</span>. You can define a TFX Evaluator as follows by passing in values for <span class="fm-code-in-text">examples</span>, <span class="fm-code-in-text">model</span>, <span class="fm-code-in-text">baseline_model</span>, and <span class="fm-code-in-text">eval_ config</span> arguments. <span class="fm-code-in-text">baseline_model</span> is resolved by the Resolver:</p>
  <pre class="programlisting">from tfx.components import Evaluator
 
evaluator = Evaluator(
    examples=example_gen.outputs['examples'],
    model=trainer.outputs['model'],
    baseline_model=model_resolver.outputs['model'],
    eval_config=eval_config)
context.run(evaluator)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185850"></a>Unfortunately, running the Evaluator will not provide the results you need. It will, in fact, fail the evaluation. At the bottom of the log, you will see an output like this</p>
  <pre class="programlisting">INFO:absl:Evaluation complete. Results written to 
<span class="fm-code-continuation-arrow">➥</span> .../pipeline/examples/forest_fires_pipeline/Evaluator/evaluation/14.
INFO:absl:Checking validation results.
INFO:absl:Blessing result False written to 
<span class="fm-code-continuation-arrow">➥</span> .../pipeline/examples/forest_fires_pipeline/Evaluator/blessing/14.</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185856"></a>which says <span class="fm-code-in-text">Blessing</span> resulted <span class="fm-code-in-text">False</span>. It’s still a mystery why the model failed, given it showed only a loss of around 150 and we set the threshold to 200. To understand what happened, we need to look at the results written to the disk. If you look inside the &lt;pipeline root&gt;/ examples\forest_fires_pipeline\Evaluator\&lt;execution ID&gt; directory, you will see files like validation, metrics, and so forth. Along with the <span class="fm-code-in-text">tensorflow_model_analysis</span> library, these can provide invaluable insights to understand what when wrong. The <span class="fm-code-in-text">tensorflow_model_analysis</span> library provides several convenient functions to load the results stored in these files:</p>
  <pre class="programlisting">import tensorflow_model_analysis as tfma
 
validation_path = os.path.join(
    evaluator.outputs['evaluation']._artifacts[0].uri, "validations"
)
validation_res = tfma.load_validation_result(validation_path)
 
print('='*20, " Output stored in validations file ", '='*20)
print(validation_res)
print("="*75)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185867"></a>This will print out</p>
  <pre class="programlisting">metric_validations_per_slice {
  slice_key {
    single_slice_keys {
      column: "month"
      bytes_value: "sep"
    }
  }
  failures {
    metric_key {
      name: "mean_squared_error"
    }
    metric_threshold {
      value_threshold {
        upper_bound {
          value: 200.0
        }
      }
    }
    metric_value {
      double_value {
        value: 269.11712646484375
      }
    }
  }
}
validation_details {
  slicing_details {
    slicing_spec {
    }
    num_matching_slices: 12
  }
}</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185901"></a>You can clearly see what happened. It says that the slice created for the month <span class="fm-code-in-text">"sep"</span> resulted in an error of <span class="fm-code-in-text">269</span>, which is why our evaluation failed. If you want details about all of the slices used and their results, you can inspect the metrics file:</p>
  <pre class="programlisting">metrics_path = os.path.join(
    evaluator.outputs['evaluation']._artifacts[0].uri, "metrics"
)
metrics_res = tfma.load_metrics(metrics_path)
 
print('='*20, " Output stored in metrics file ", '='*20)
for r in metrics_res:
    print(r)
    print('-'*75)
print("="*75)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185914"></a>This would output the following. You will only see a small snippet of the full output here to save space:</p>
  <pre class="programlisting">slice_key {
  single_slice_keys {
    column: "month"
    bytes_value: "sep"
  }
}
metric_keys_and_values {
  key {
    name: "loss"
  }
  value {
    double_value {
      value: 269.11712646484375
    }
  }
}
metric_keys_and_values {
  key {
    name: "mean_squared_error"
  }
  value {
    double_value {
      value: 269.11712646484375
    }
  }
}
metric_keys_and_values {
  key {
    name: "example_count"
  }
  value {
    double_value {
      value: 52.0
    }
  }
}
 
---------------------------------------------------------------------------
slice_key {
}
metric_keys_and_values {
  key {
    name: "loss"
  }
  value {
    double_value {
      value: 160.19691467285156
    }
  }
}
metric_keys_and_values {
  key {
    name: "mean_squared_error"
  }
  value {
    double_value {
      value: 160.19691467285156
    }
  }
}
metric_keys_and_values {
  key {
    name: "example_count"
  }
  value {
    double_value {
      value: 153.0
    }
  }
}
...</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185988"></a>This output sheds more light on what happened. Since we used the example count as one of the metrics, we can see the number of examples in each slice. For example, in month May, there’s only one example present in the evaluation split, which is most probably an outlier. To fix this, we will bump up the threshold to 300. Once you do that, you need to rerun the Evaluator, and you will see from the Evaluator’s logs that our model passes the checks:</p>
  <pre class="programlisting">INFO:absl:Evaluation complete. Results written to 
<span class="fm-code-continuation-arrow">➥</span> .../pipeline/examples/forest_fires_pipeline/Evaluator/evaluation/15.
INFO:absl:Checking validation results.
INFO:absl:Blessing result True written to 
<span class="fm-code-continuation-arrow">➥</span> .../pipeline/examples/forest_fires_pipeline/Evaluator/blessing/15.</pre>

  <p class="body"><a class="calibre8" id="pgfId-1185992"></a>The best way to address this is to identify why the month of <span class="fm-code-in-text">"sep"</span> is giving such a large value while other months are on par with or below the overall loss value. After identifying the issue, we should identify remediation steps to correct this (e.g., reconsidering outlier definitions). On that note, we will move on to the next part of our <a class="calibre8" id="marker-1185993"></a><a class="calibre8" id="marker-1185994"></a><a class="calibre8" id="marker-1185995"></a>pipeline.</p>

  <h3 class="fm-head1" id="sigil_toc_id_205"><a id="pgfId-1185996"></a>15.4.4 Pushing the final model</h3>

  <p class="body"><a class="calibre8" id="pgfId-1186000"></a>We <a class="calibre8" id="marker-1185997"></a><a class="calibre8" id="marker-1185999"></a>have reached the last steps in our pipeline. We need to define a Pusher. The Pusher (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/pOZz">http://mng.bz/pOZz</a></span>) is responsible for pushing a blessed model (i.e., a model that passes the evaluation checks) to a defined production environment. The production environment can simply be a local location in your file system:</p>
  <pre class="programlisting">from tfx.components import Pusher
from tfx.proto import pusher_pb2
 
pusher = Pusher(
  model=trainer.outputs['model'],
  model_blessing=evaluator.outputs['blessing'],
  infra_blessing=infra_validator.outputs['blessing'],
  push_destination=pusher_pb2.PushDestination(
    filesystem=pusher_pb2.PushDestination.Filesystem(
        base_directory=os.path.join('forestfires-model-pushed'))
  )
)
context.run(pusher)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1186014"></a>The Pusher takes the following elements as arguments:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1186015"></a><span class="fm-code-in-text">model</span>—The Keras model returned by the Trainer component</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1186016"></a><span class="fm-code-in-text">model_blessing</span>—Evaluator component’s blessed state</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1186017"></a><span class="fm-code-in-text">infra_blessing</span>—InfraValidator’s blessed state</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1186018"></a><span class="fm-code-in-text">push_destination</span>—A destination to be pushed to as a <span class="fm-code-in-text">PushDestination</span> protobuf message</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1186019"></a>If the step runs successfully, you will have a model saved in a directory called forestfires-model-pushed in our pipeline <a class="calibre8" id="marker-1186020"></a><a class="calibre8" id="marker-1186022"></a>root.</p>

  <h3 class="fm-head1" id="sigil_toc_id_206"><a id="pgfId-1186023"></a>15.4.5 Predicting with the TensorFlow serving API</h3>

  <p class="body"><a class="calibre8" id="pgfId-1186026"></a>The <a class="calibre8" id="marker-1186024"></a><a class="calibre8" id="marker-1186025"></a>very last step is to retrieve the model from the pushed destination and start a Docker container based on the TensorFlow serving image we downloaded. The Docker container will provide an API that we can ping with various requests.</p>

  <p class="body"><a class="calibre8" id="pgfId-1186027"></a>Let’s look at how the API fits into the big picture in more detail (figure 15.10). The machine learning model sits behind an API. The API defines various HTTP endpoints you can ping (through Python or a package like curl). These endpoints will be in the form of a URL and can expect parameters in the URL or data embedded in the request body. The API is served via a server. The server exposes a network port in which clients can communicate with the server. The client can send requests to the server using the format &lt;host name&gt;:&lt;port&gt;/&lt;end point&gt;. We will discuss what the request actually looks like in more detail.</p>

  <p class="fm-figure"><img alt="15-10" class="calibre10" src="../../OEBPS/Images/15-10.png" width="1081" height="842"/><br class="calibre2"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1214417"></a>Figure 15.10 How the model interacts with the API, the TensorFlow server, and the client</p>

  <p class="body"><a class="calibre8" id="pgfId-1186033"></a>To start the container, simply</p>

  <ol class="calibre11">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1186034"></a>Open a terminal</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1186035"></a>Move the cd into the Ch15-TFX-for-MLOps-in-TF2/tfx directory</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1186036"></a>Run <span class="fm-code-in-text">./run_server.sh</span></p>
    </li>
  </ol>

  <p class="body"><a class="calibre8" id="pgfId-1186037"></a>Next, in the Jupyter notebook, we will send a HTTP POST request. There are two main types of HTTP requests: GET and POST. Refer the sidebar if you’re interested in the differences. An HTTP POST request is a request that not only contains a URL to reach and header information, but also contains a payload, which is necessary for the API to complete the request. For example, if we are hitting the API endpoint corresponding to the <span class="fm-code-in-text">serving_default</span> signature, we have to send an input to predict with.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre8" id="pgfId-1186038"></a>GET vs. POST requests</p>

    <p class="fm-sidebar-text"><a id="pgfId-1186039"></a>GET and POST are HTTP methods. HTTP is a protocol that defines how a client and a server should communicate. A client will send requests, and the server will listen for requests on a specific network port. The client and the server don’t necessarily need to be two separate machines. In our case, the client and the server are both on the same machine.</p>

    <p class="fm-sidebar-text"><br class="calibre2"/></p>

    <p class="fm-sidebar-text"><a id="pgfId-1186040"></a>Every time you visit a website by typing a URL, you are making a request to that specific website. A request has the following anatomy (<span class="fm-hyperlink"><a class="url" href="http://mng.bz/OowE">http://mng.bz/OowE</a></span>):</p>

    <ul class="calibre9">
      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1186041"></a><i class="fm-italics">A method type</i>—GET or POST</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1186042"></a><i class="fm-italics">A path</i>—The URL to reach the endpoint of the server you want to reach</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1186043"></a><i class="fm-italics">A body</i>—Any large payload that needs the client to complete the request (e.g., the input for a machine learning prediction service)</p>
      </li>

      <li class="fm-sidebar-number">
        <p class="list1"><a id="pgfId-1186044"></a><i class="fm-italics">A header</i>—Additional information needed for the server (e.g., the type of data sent in the body)</p>
      </li>
    </ul>

    <p class="fm-sidebar-text"><a id="pgfId-1186045"></a>The main difference is that GET is used to request data, as opposed to a POST request, which is used to post or send data to the server (which can optionally return something). A GET request will not have a request body, whereas a POST request will have a request body. Another difference is that GET requests can be cached, whereas POST requests will not be cached, making them more secure for sensitive data. You can read more about this at <span class="fm-hyperlink"><a class="url" href="http://mng.bz/YGZA">http://mng.bz/YGZA</a></span>.</p>
  </div>

  <p class="body"><a class="calibre8" id="pgfId-1186047"></a>We will define a request body, which contains the signature name we want to hit and the input we want to predict for. Next, we will use the <span class="fm-code-in-text">requests</span> library in Python to send a request to our TensorFlow model server (i.e., Docker container). In this request, we will define the URL to reach (automatically generated by the TensorFlow model server) and the payload to carry. If the request is successful, we should get a valid prediction as the output:</p>
  <pre class="programlisting">import base64
import json
import requests
 
req_body = {
  "signature_name": "serving_default",
 
  "instances": 
    [
            str(base64.b64encode(
                b"{\"X\": 7,\"Y\": 
<span class="fm-code-continuation-arrow">➥</span> 4,\"month\":\"oct\",\"day\":\"fri\",\"FFMC\":60,\"DMC\":30,\"DC\":200,\
<span class="fm-code-continuation-arrow">➥</span> "ISI\":9,\"temp\":30,\"RH\":50,\"wind\":10,\"rain\":0}]")
               )
    ]
    
}
 
data = json.dumps(req_body)
 
json_response = requests.post(
    'http:/ /localhost:8501/v1/models/forest_fires_model:predict', 
    data=data, 
    headers={"content-type": "application/json"}
)
predictions = json.loads(json_response.text)</pre>

  <p class="body"><a class="calibre8" id="pgfId-1186072"></a>The first thing we do is define a request with a specific request body. The requirements for the request body are defined at <span class="fm-hyperlink"><a class="url" href="https://www.tensorflow.org/tfx/serving/api_rest">https://www.tensorflow.org/tfx/serving/api_rest</a></span>. It is a dictionary of key-value pairs that should have two keys: <span class="fm-code-in-text">signature_name</span> and <span class="fm-code-in-text">instances</span>. <span class="fm-code-in-text">signature_name</span> defines which signature to invoke in the model, and <span class="fm-code-in-text">instances</span> will contain the input data. Note that we’re not passing input data in its raw form. Rather, we use base64 encoding. It encodes a byte stream (i.e., a binary input) to an ASCII text string. You can read more about this at <span class="fm-hyperlink"><a class="url" href="http://mng.bz/1o4g">http://mng.bz/1o4g</a></span>. You can see that we are first converting our dictionary to a byte-stream (i.e., with a <span class="fm-code-in-text">b"&lt;data&gt;"</span> format) and then using base64 encoding on that. If you remember from our previous discussion on writing the model serve function (which had the signature <span class="fm-code-in-text">def serve_tf_examples_fn(serialized_tf_examples):</span> ), it expects a serialized set of examples. Serialization is done by converting the data to a byte stream.</p>

  <p class="body"><a class="calibre8" id="pgfId-1186073"></a>When the data is ready, we use the <span class="fm-code-in-text">requests</span> library to create a POST request for the API. First, we define a header to say that the content or payload we’re passing is JSON. Next, we send a POST request via <span class="fm-code-in-text">requests.post()</span> giving the URL, which is in <span class="fm-hyperlink"><a class="url" href="http://&lt;server%E2%80%99s%20hostname%3E:&lt;port%3E/v1/models/&lt;model%20name%3E:predict">http://&lt;server’s hostname&gt;:&lt;port&gt;/v1/models/&lt;model name&gt;:predict</a></span> format, data (i.e., the JSON payload), and the header. This is not the only API endpoint available to us. There are other endpoints as well (<span class="fm-hyperlink"><a class="url" href="https://www.tensorflow.org/tfx/serving/api_rest">https://www.tensorflow.org/tfx/serving/api_rest</a></span>). There are four main endpoints that are available:</p>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1186074"></a><i class="fm-italics">http:/ /&lt;server’s hostname&gt;:&lt;port&gt;/v1/models/&lt;model name&gt;:predict</i>—Predicts the output value using the model and the data passed in the request. Does not require a target to be available for the provided input.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1186075"></a><i class="fm-italics">http:</i><span class="fm-hyperlink">/ /</span><i class="fm-italics">&lt;server’s hostname&gt;:&lt;port&gt;/v1/models/&lt;model name&gt;:regress</i> —Used in regression problems. Used when both inputs and target are available (i.e., an error can be calculated).</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1186076"></a><i class="fm-italics">http:</i><span class="fm-hyperlink">/ /</span><i class="fm-italics">&lt;server’s hostname&gt;:&lt;port&gt;/v1/models/&lt;model name&gt;:classify</i>—Used in classification problems. Used when both inputs and target are available (i.e., an error can be calculated).</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1186077"></a><i class="fm-italics">http:</i><span class="fm-hyperlink">/ /</span><i class="fm-italics">&lt;server’s hostname&gt;:&lt;port&gt;/v1/models/&lt;model name&gt;/metadata</i>—Provides metadata about available endpoints/model signatures.</p>
    </li>
  </ul>

  <p class="body"><a class="calibre8" id="pgfId-1186078"></a>This will return some response. If the request was successful, it will have the response; otherwise, it will contain an HTTP error. You can see various HTTP status/error codes at <span class="fm-hyperlink"><a class="url" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status">http://mng.bz/Pn2P</a></span>. In our case, we should get something like</p>
  <pre class="programlisting">{'predictions': [[2.77522683]]}</pre>

  <p class="body"><a class="calibre8" id="pgfId-1186082"></a>This means our model has successfully processed the input and produced a valid prediction. We can see that the model has returned a prediction that is well within the possible range of values we saw during our data exploration. This concludes our discussion of TensorFlow Extended (TFX).</p>

  <p class="fm-head2"><a id="pgfId-1186083"></a>Exercise 4</p>

  <p class="body"><a class="calibre8" id="pgfId-1186084"></a>How would you send multiple inputs in your HTTP request to the model? Assume you have the following two inputs that you want to predict for using the model.</p>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre12">
      <col class="calibre13" span="1" width="33.33%"/>
      <col class="calibre13" span="1" width="33.33%"/>
      <col class="calibre13" span="1" width="33.33%"/>
    </colgroup>

    <tr class="calibre14">
      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1193186"></a> </p>
      </th>

      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1193188"></a><b class="fm-bold">Example 1</b></p>
      </th>

      <th class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1193190"></a><b class="fm-bold">Example 2</b></p>
      </th>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193192"></a>X</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193194"></a>9</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193196"></a>7</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193198"></a>Y</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193200"></a>6</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193202"></a>4</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193204"></a>month</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193206"></a>aug</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193208"></a>aug</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193210"></a>day</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193212"></a>fri</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193214"></a>fri</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193216"></a>FFMC</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193218"></a>91</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193220"></a>91</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193222"></a>DMC</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193224"></a>248</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193226"></a>248</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193228"></a>DC</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193230"></a>553</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193232"></a>553</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193234"></a>ISI</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193236"></a>6</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193238"></a>6</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193240"></a>temp</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193242"></a>20.5</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193244"></a>20.5</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193246"></a>RH</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193248"></a>58</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193250"></a>20</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193252"></a>wind</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193254"></a>3</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193256"></a>0</p>
      </td>
    </tr>

    <tr class="calibre14">
      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193258"></a>rain</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193260"></a>0</p>
      </td>

      <td class="fm-contenttable2" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1193262"></a>0</p>
      </td>
    </tr>
  </table>

  <p class="body"><a class="calibre8" id="pgfId-1186166"></a>To pass multiple values for that input in an HTTP request, you can append more examples to the instances list in the <a class="calibre8" id="marker-1186167"></a><a class="calibre8" id="marker-1186168"></a>JSON <a class="calibre8" id="marker-1186169"></a><a class="calibre8" id="marker-1186170"></a>data.</p>

  <h2 class="fm-head" id="sigil_toc_id_207"><a id="pgfId-1186171"></a>Summary</h2>

  <ul class="calibre9">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre8" id="pgfId-1186172"></a>MLOps defines a workflow that will automate most of the steps, from collecting data to delivering a model trained on that data.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1186173"></a>Productionization involves deploying a trained model with a robust API to access the model, enabling customers to use the model for its designed purpose. The API provides several HTTP endpoints, which are in the form of URLs, which clients can use to communicate with the server.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1186174"></a>In TFX, you define a MLOps pipeline as a series of TFX components.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1186175"></a>TFX has components to load data (<span class="fm-code-in-text">CsvExampleGen</span>), generate basic statistics and visualizations (<span class="fm-code-in-text">StatisticsGen</span>), infer the schema (<span class="fm-code-in-text">SchemaGen</span>), and convert raw columns to features (<span class="fm-code-in-text">Transform</span>).</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1186176"></a>For a Keras model to be served via HTTP requests, signatures are required.</p>

      <ul class="calibre18">
        <li class="fm-sidebar-bullet-sub">
          <p class="list"><a class="calibre8" id="pgfId-1186177"></a>Signatures define the data format of inputs and outputs as well as the steps that need to happen in order to produce the output via a TensorFlow function (e.g., a function decorated with <span class="fm-code-in-text">@tf.function</span>).</p>
        </li>
      </ul>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1186178"></a>Docker is a containerization technology that can be used to encapsulate a unit of software as a single container and can be ported easily between different environments (or computers).</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1186179"></a>Docker runs a unit of software in a container.</p>
    </li>

    <li class="fm-list-bullet1">
      <p class="list"><a class="calibre8" id="pgfId-1186180"></a>TFX provides validation components for validating infrastructure and the model. TFX can stand up a container and make sure it’s running as expected, as well as make sure the model passes various evaluation criteria (e.g., loss being smaller than a threshold), ensuring a high-quality model.</p>
    </li>

    <li class="fm-list-bullet-last">
      <p class="list"><a class="calibre8" id="pgfId-1186181"></a>Once the model is pushed to a production environment, we start a Docker container (based on the TensorFlow serving image) that will mount the model into the container and serve it via an API. We can make HTTP requests (with the inputs embedded) to generate predictions.</p>
    </li>
  </ul>

  <h2 class="fm-head" id="sigil_toc_id_208"><a id="pgfId-1186182"></a>Answers to exercises</h2>

  <p class="body"><a class="calibre8" id="pgfId-1186183"></a><b class="fm-bold">Exercise 1</b></p>
  <pre class="programlisting">  outputs = {}
    
  # Treating dense features
  outputs[_transformed_name('DC')] = tft.scale_to_0_1(
        sparse_to_dense(inputs['DC'])
    )
 
 
  # Treating bucketized features
  outputs[_transformed_name('temp')] = tft.apply_buckets(
        sparse_to_dense(inputs['temp']), bucket_boundaries=[(20, 30)])</pre>

  <p class="body"><a class="calibre8" id="pgfId-1186196"></a><b class="fm-bold">Exercise 2</b></p>
  <pre class="programlisting">categorical_columns = [
      tf.feature_column.embedding_column(
          tf.feature_column.categorical_column_with_identity( 
              key,
              num_buckets=num_buckets,
              default_value=0
          ),
          dimension=32
      ) for key, num_buckets in zip(
              _transformed_names(_VOCAB_FEATURE_KEYS),
              _MAX_CATEGORICAL_FEATURE_VALUES
      )</pre>

  <p class="body"><a class="calibre8" id="pgfId-1186209"></a><b class="fm-bold">Exercise 3</b></p>
  <pre class="programlisting">docker run -v /tmp/inputs:/data -p 5000:5000 tensorflow/tensorflow:2.5.0</pre>

  <p class="body"><a class="calibre8" id="pgfId-1186212"></a><b class="fm-bold">Exercise 4</b><a class="calibre8" id="marker-1186211"></a></p>
  <pre class="programlisting">req_body = {
  "signature_name": "serving_default",
 
  "instances": 
    [
        str(base64.b64encode(
            b"{\"X\": 9,\"Y\": 
<span class="fm-code-continuation-arrow">➥</span> 6,\"month\":\"aug\",\"day\":\"fri\",\"FFMC\":91,\"DMC\":248,\"DC\":553,
<span class="fm-code-continuation-arrow">➥</span> \"ISI\":6,\"temp\":20.5,\"RH\":58,\"wind\":3,\"rain\":0}]")
        ),
        str(base64.b64encode(
            b"{\"X\": 7,\"Y\": 
<span class="fm-code-continuation-arrow">➥</span> 4,\"month\":\"aug\",\"day\":\"fri\",\"FFMC\":91,\"DMC\":248,\"DC\":553,
<span class="fm-code-continuation-arrow">➥</span> \"ISI\":6,\"temp\":20.5,\"RH\":20,\"wind\":0,\"rain\":0}]")
        ),
        
    ]
    
}</pre>
</div>
</div>
</body>
</html>